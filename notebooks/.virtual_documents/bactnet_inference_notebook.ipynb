import tensorflow as tf
from tensorflow import keras




if tf.test.gpu_device_name()=='':
    print('You do not have GPU access.')
    !nvidia-smi

else:
  print('You have GPU access')
  !nvidia-smi


# print the tensorflow version
print('TensorFlow {}; Keras {}'.format(tf.__version__, keras.__version__))
tf.test.gpu_device_name()



from tensorflow.keras import layers
import os
import tifffile as tiff
import numpy as np
from matplotlib import pyplot as plt
from keras.models import load_model
from preprocessing import get_model_memory_usage, unpatch_stack

#load pretrained model

model = load_model("models/bactunet_V4_3frame.hdf5", compile=False)

batch_size = 6
print("Model uses {} GB of memory at a batch size of {}".format(get_model_memory_usage(batch_size, model), batch_size))


model.summary()
for l in model.weights:
    print(l.name, l.shape)


from preprocessing import patch_image, patch_stack, normalizePercentile, normalizeMinMax
from patchify import patchify

source_path = r"Bactnet/Training data/stacks/"
SIZE = 288




def prepare_data(source_path, PATCH_SIZE, validation=True):
    pred_dict = {}
    if validation:
        prefix = "validation"
    else:
        prefix = "training"
    stacks = os.listdir(os.path.join(source_path, prefix+"_source"))
    image_dataset = None
    mask_dataset = None
    for stack in stacks:
        if (stack.split(".")[-1]=="tif"):
            pred_dict[stack]={}
            img = tiff.imread(os.path.join(source_path, prefix+"_source",stack))
            pred_dict[stack]["image"]=img
            mask = tiff.imread(os.path.join(source_path, prefix+"_target", stack))
            pred_dict[stack]["y_true"]=mask
            print(stack, img.shape, mask.shape)
            
            img_patch = patch_stack(img, PATCH_SIZE)
            if len(mask.shape)==2:
                mask_patch = patch_image(mask, PATCH_SIZE)
            else:    
                mask_patch = patch_stack(mask, SIZE=PATCH_SIZE, DEPTH=1)
            
            print(stack, img_patch.shape, mask_patch.shape)
            mask_patch = normalizeMinMax(mask_patch)
            img_patch = normalizePercentile(img_patch, 0.1, 99.9, clip=True)
            pred_dict[stack]["image_patch"] = img_patch
            pred_dict[stack]["mask_patch"] = mask_patch


            #print(image_dataset.shape, mask_dataset.shape)

    return pred_dict

#pred_dict[file]=[image_stack, mask, patch, y_true, y_pred]
image_dict = prepare_data(source_path, SIZE, validation=True)
image_dict.update(prepare_data(source_path, SIZE, validation=False))
print(image_dict.keys())




keras.backend.clear_session()
stride = 2

# #IOU
for stack in image_dict.keys():
    y_pred = None
    img_stack = image_dict[stack]
    for i in range(0, len(img_stack["image_patch"]), stride):
        pred = model.predict(img_stack["image_patch"][i:i+stride])
        if y_pred is not None:
            y_pred = np.concatenate((y_pred, pred))

        if y_pred is None:
            y_pred = pred
    
    image_dict[stack]["y_pred"] = unpatch_stack(y_pred, 8, 8, 1)
    print(stack, y_pred.shape, image_dict[stack]["y_pred"].shape)
    


for stack in image_dict.keys():
    saveme = np.concatenate(((image_dict[stack]["y_pred"]>0.5)*255, np.expand_dims(image_dict[stack]["y_true"],axis=1)), axis=1)
    saveme = saveme.astype('uint8')
    prefix="V4_3frame"
    dic = unpatch_stack(image_dict[stack]["image_patch"], 8, 8, 3)
    dic = dic[:,1,:,:] * 255
    dic = np.expand_dims(dic, axis=1).astype('uint8')
    print(dic.shape, image_dict[stack]["image_patch"].max())
    saveme = np.concatenate((dic, saveme), axis=1)
    tiff.imwrite(os.path.join(r"C:\Users\Jens\Documents\Code\BactUnet\Bactnet\Training data\stacks\predict", prefix+stack), saveme, imagej=True,
                      metadata={'unit': 'um', 'finterval': 15,
                                'axes': 'TCYX'})


y_tru = None
y_pre = None

for stack in image_dict.keys():
    if y_tru is None:
        y_tru = image_dict[stack]["y_true"]
        y_pre = image_dict[stack]["y_pred"]
    else:
        y_tru = np.concatenate((y_tru, image_dict[stack]["y_true"]))
        y_pre = np.concatenate((y_pre, image_dict[stack]["y_pred"]))
        
dices = []
IOUs = []
frames = []
threshold = 0.5

y_pred_thresholded = (y_pre > threshold) * 255
y_pred_thresholded = y_pred_thresholded.astype('uint8')

for i in range(len(y_tru)):
    intersection = np.logical_and(y_tru[i], y_pred_thresholded[i])
    union = np.logical_or(y_tru[i], y_pred_thresholded[i])
    iou_score = np.sum(intersection) / np.sum(union)
    IOUs.append(iou_score)

frames =  list(range(len(y_tru)))

    
#plt.plot(frames, dices)
plt.plot(frames, IOUs)
plt.show()



def dice_score(mask1, mask2):
    intersect = np.sum(mask1*mask2)
    fsum = np.sum(mask1)
    ssum = np.sum(mask2)
    dice = (2 * intersect ) / (fsum + ssum)
    dice = np.mean(dice)
    dice = round(dice, 3) # for easy reading
    return dice    

def iou_score(mask1, mask2):
    intersection = np.logical_and(mask1, mask1)
    union = np.logical_or(mask1, mask2)
    iou_score = np.sum(intersection) / np.sum(union)
    

for stack in image_dict.keys():
    image_dict[stack]
    image_dict[stack]['y_pred']



from preprocessing import pad_stack, crop_stack, predict_stack


def crop_stack(arr, SIZE):
    """
    Undoes the padding from pad_stack, crops out the center, removing a 1/2 SIZE broder from around the stack
    """
    pad_SIZE = int(SIZE / 2)

    if len(arr.shape) == 3:
        t, y, x = arr.shape
        stopY = y - pad_SIZE
        stopX = x - pad_SIZE
        return arr[:, pad_SIZE:stopY, pad_SIZE:stopX]

    if len(arr.shape) == 4:
        t, c, y, x = arr.shape
        stopY = y - pad_SIZE
        stopX = x - pad_SIZE
        return arr[:, :, pad_SIZE:stopY, pad_SIZE:stopX]

#Lets enlarge and see if patch edge regions are affecting the results

source_path = r"Bactnet/Training data/stacks/validation_source"
stacks = os.listdir(os.path.join(source_path))
        

ypred_2 = None
    
for i, image_name in enumerate(stacks):  # Remember enumerate method adds a counter and returns the enumerate object
    if (image_name.split('.')[1] == 'tif'):
        image = tiff.imread(os.path.join(source_path, image_name))
        image = normalizePercentile(image, 0.1, 99.9, clip=True)
        expanded_image = pad_stack(image, SIZE)
        expanded_patch = patch_stack(expanded_image, SIZE)
        pred = predict_stack(expanded_patch, 2, model)
        pred = unpatch_stack(pred, 9, 9, 1)
        pred = crop_stack(pred, SIZE)
        if ypred_2 is None:
            ypred_2 = pred 
        else:
            ypred_2 = np.concatenate((ypred_2, pred))

        print(image_name, expanded_image.shape, pred.shape, ypred_2.shape)








print(y_tru.shape, y_pre.shape, ypred_2.shape)



#length of each dataset
l_BT0398_210 = 11
l_BT402_168 = 3
l_BT403_000 = 11
l_BT403_228 = 11
l_BT404_199 = 1



image_dataset = unpatch_stack(image_dataset[:,1,:,:], 8, 8, 1)


print(image_dataset.shape, y_pre.shape, y_tru.shape)
saveme = np.concatenate((image_dataset, y_tru, y_pre, ypred_2), axis=1)
saveme = saveme * 65535
saveme = saveme.astype('uint16')
print(saveme.shape)


results_folder = r"_results"
tiff.imwrite(os.path.join(results_folder, "all_masked_stacks_V3b.tif"), saveme, imagej=True, resolution=(1./2.6755, 1./2.6755),
                      metadata={'unit': 'um', 'finterval': 15,
                                'axes': 'TCYX'})


#Viktors data
source_path = r"Bactnet/viktor"
stacks = os.listdir(os.path.join(source_path))
print(stacks)
vikt = None

def predict_stack(arr, batch_size, model):
    """
    Performs prediction on all images in arr using model in increments of batch_size
    Assumes patches of a ahpe where N is 0th axis.
    """
    keras.backend.clear_session()
    y_pred = None
    for i in range(0, len(arr), batch_size):
        subset = arr[i:i + batch_size]
        
        pred = model.predict(subset)
        if y_pred is not None:
            y_pred = np.concatenate((y_pred, pred))

        else:
            y_pred = pred

    return y_pred

for i, image_name in enumerate(stacks):  # Remember enumerate method adds a counter and returns the enumerate object
    if (image_name.split('.')[-1] == 'tif'):
        image = tiff.imread(os.path.join(source_path, image_name))
        image = image[0:100]
        image = normalizePercentile(image, 0.1, 99.9, clip=True)
        patch = patch_stack(image, SIZE)
        print(image.shape, patch.shape)
        pred = predict_stack(patch, 2, model)
        pred = unpatch_stack(pred, 8, 8, 1)
        
        if vikt is None:
            vikt = pred 
        else:
            vikt = np.concatenate((vikt, pred))
        




saveme = vikt * 65535
saveme = saveme.astype('uint16')
img = np.expand_dims(image[0:-2], axis = 1)
img = img * 65535
img = img.astype('uint16')
print(saveme.shape, img.shape)
saveme = np.concatenate((img,saveme), axis = 1)
print(saveme.shape)
tiff.imwrite(os.path.join(source_path, "pred.tif"), saveme, imagej=True, resolution=(1./0.109, 1./0.109),
                      metadata={'unit': 'um', 'finterval': 15,
                                'axes': 'TCYX'})









#load unseen data

validation_image_directory = r"C:\Users\analyst\Documents\Python Scripts\BactUnet\Bactnet\Training data\stacks\predict"
result_folder = r"C:\Users\analyst\Documents\Python Scripts\BactUnet\_results"

val_image_dataset = []
val_mask_dataset = []
pred_mask_dataset = []

images = os.listdir(validation_image_directory)

for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object
    if (image_name.split('.')[1] == 'tif'):
        
        image = tiff.imread(os.path.join(validation_image_directory, image_name))
        original_shape = image.shape
        patch = patch_stack(image, SIZE)
        
        patch = normalizePercentile(patch, 0.1, 99.9, clip=True)
        pred_mask_patch = model.predict(patch)
        print(image_name, original_shape, patch.shape, pred_mask_patch.shape)
        #pred_mask_patch = pred_mask_patch[:, 0, :,:]
        image = np.expand_dims(patch[:, 1, :,:], axis=1)
        patch = np.concatenate((image, pred_mask_patch), axis=1)
        unpatched = unpatcher(patch, 8, 8, 2)
        print(patch.shape)
        tiff.imwrite(os.path.join(result_folder, image_name), unpatched, imagej=True, resolution=(1./2.6755, 1./2.6755),
                      metadata={'unit': 'um', 'finterval': 15,
                                'axes': 'TCYX'})
        
        #pred_mask = unpatch_stack(pred_mask_patch, original_shape)
        #tiff.imsave(os.path.join(result_folder, image_name), pred_mask_patch)
        #val_image_dataset.append(image)
        #pred_mask_dataset.append(pred_mask)


for i in range(len(pred_mask_dataset)):
    img = val_image_dataset[i][3]
    msk = pred_mask_dataset[i][3]
    plt.figure(figsize=(16, 8))
    plt.subplot(121)
    plt.title('Testing Image')
    plt.imshow(img)
    plt.subplot(122)
    plt.title('Prediction on test image')
    plt.imshow(msk)
    plt.show()


all_weights = []

for i, layer in enumerate(model.layers):
  if "onv" in layer.name:
    all_weights.append
    print(i, layer.name, model.layers[i].get_weights()[0].shape)

weights, biases =  model.layers[1].get_weights()
fig1=plt.figure(figsize=(12, 12))


columns = 8 
rows = 8 
n_filters = columns*rows
for i in range(1, n_filters +1):
    f = weights[:, :, (i-1), 0]
    fig1 =plt.subplot(rows, columns, i)
    fig1.set_xticks([])  #Turn off axis
    fig1.set_yticks([])

    #plt.imshow(f[i%3, :, :], cmap='gray')
    plt.imshow(f[:, :], cmap='gray')
    #plt.imshow(f[2, :, :], cmap='gray') #Show only the filters from 0th channel (R)
    #ix += 1
plt.show() 
