{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b37971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jens\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have GPU access\n",
      "Fri Oct 21 08:55:15 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.72       Driver Version: 512.72       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   55C    P0    16W /  N/A |    168MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     23228      C   ...nvs\\tensorflow\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     35044      C   ...nvs\\tensorflow\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "TensorFlow 2.6.0; Keras 2.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if tf.test.gpu_device_name()=='':\n",
    "    print('You do not have GPU access.')\n",
    "    !nvidia-smi\n",
    "\n",
    "else:\n",
    "  print('You have GPU access')\n",
    "  !nvidia-smi\n",
    "\n",
    "\n",
    "# print the tensorflow version\n",
    "print('TensorFlow {}; Keras {}'.format(tf.__version__, keras.__version__))\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac04cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uses 3.557 GB of memory at a batch size of 6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from preprocessing import get_model_memory_usage, unpatch_stack\n",
    "\n",
    "#load pretrained model\n",
    "\n",
    "model = load_model(\"models/bactunet_V4_single_frame.hdf5\", compile=False)\n",
    "\n",
    "batch_size = 6\n",
    "print(\"Model uses {} GB of memory at a batch size of {}\".format(get_model_memory_usage(batch_size, model), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04714372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BactUnet_single_frame_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1, 288, 288) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 288, 288) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 288, 288) 1152        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 288, 288) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 288, 288) 36928       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 288, 288) 1152        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 288, 288) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 144, 144) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 144, 144 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 144, 144 576         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 144, 144 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 144, 144 147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 144, 144 576         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 144, 144 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 72, 72)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 72, 72)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 72, 72)  288         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 72, 72)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 72, 72)  590080      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 72, 72)  288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 72, 72)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 256, 36, 36)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 36, 36)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512, 36, 36)  144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512, 36, 36)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 36, 36)  2359808     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512, 36, 36)  144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512, 36, 36)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 512, 18, 18)  0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1024, 18, 18) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1024, 18, 18) 72          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024, 18, 18) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1024, 18, 18) 9438208     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1024, 18, 18) 72          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024, 18, 18) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 512, 36, 36)  2097664     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024, 36, 36) 0           conv2d_transpose[0][0]           \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 512, 36, 36)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 512, 36, 36)  144         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 512, 36, 36)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 512, 36, 36)  2359808     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 512, 36, 36)  144         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 512, 36, 36)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 72, 72)  524544      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512, 72, 72)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 72, 72)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256, 72, 72)  288         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256, 72, 72)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 72, 72)  590080      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256, 72, 72)  288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256, 72, 72)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 144, 144 131200      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 144, 144 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 144, 144 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 144, 144 576         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128, 144, 144 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 144, 144 147584      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 144, 144 576         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128, 144, 144 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 288, 288) 32832       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 288, 288 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 288, 288) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 288, 288) 1152        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64, 288, 288) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 288, 288) 36928       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 288, 288) 1152        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 64, 288, 288) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1, 288, 288)  65          dropout_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,039,377\n",
      "Trainable params: 31,034,985\n",
      "Non-trainable params: 4,392\n",
      "__________________________________________________________________________________________________\n",
      "conv2d/kernel:0 (3, 3, 1, 64)\n",
      "conv2d/bias:0 (64,)\n",
      "batch_normalization/gamma:0 (288,)\n",
      "batch_normalization/beta:0 (288,)\n",
      "batch_normalization/moving_mean:0 (288,)\n",
      "batch_normalization/moving_variance:0 (288,)\n",
      "conv2d_1/kernel:0 (3, 3, 64, 64)\n",
      "conv2d_1/bias:0 (64,)\n",
      "batch_normalization_1/gamma:0 (288,)\n",
      "batch_normalization_1/beta:0 (288,)\n",
      "batch_normalization_1/moving_mean:0 (288,)\n",
      "batch_normalization_1/moving_variance:0 (288,)\n",
      "conv2d_2/kernel:0 (3, 3, 64, 128)\n",
      "conv2d_2/bias:0 (128,)\n",
      "batch_normalization_2/gamma:0 (144,)\n",
      "batch_normalization_2/beta:0 (144,)\n",
      "batch_normalization_2/moving_mean:0 (144,)\n",
      "batch_normalization_2/moving_variance:0 (144,)\n",
      "conv2d_3/kernel:0 (3, 3, 128, 128)\n",
      "conv2d_3/bias:0 (128,)\n",
      "batch_normalization_3/gamma:0 (144,)\n",
      "batch_normalization_3/beta:0 (144,)\n",
      "batch_normalization_3/moving_mean:0 (144,)\n",
      "batch_normalization_3/moving_variance:0 (144,)\n",
      "conv2d_4/kernel:0 (3, 3, 128, 256)\n",
      "conv2d_4/bias:0 (256,)\n",
      "batch_normalization_4/gamma:0 (72,)\n",
      "batch_normalization_4/beta:0 (72,)\n",
      "batch_normalization_4/moving_mean:0 (72,)\n",
      "batch_normalization_4/moving_variance:0 (72,)\n",
      "conv2d_5/kernel:0 (3, 3, 256, 256)\n",
      "conv2d_5/bias:0 (256,)\n",
      "batch_normalization_5/gamma:0 (72,)\n",
      "batch_normalization_5/beta:0 (72,)\n",
      "batch_normalization_5/moving_mean:0 (72,)\n",
      "batch_normalization_5/moving_variance:0 (72,)\n",
      "conv2d_6/kernel:0 (3, 3, 256, 512)\n",
      "conv2d_6/bias:0 (512,)\n",
      "batch_normalization_6/gamma:0 (36,)\n",
      "batch_normalization_6/beta:0 (36,)\n",
      "batch_normalization_6/moving_mean:0 (36,)\n",
      "batch_normalization_6/moving_variance:0 (36,)\n",
      "conv2d_7/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_7/bias:0 (512,)\n",
      "batch_normalization_7/gamma:0 (36,)\n",
      "batch_normalization_7/beta:0 (36,)\n",
      "batch_normalization_7/moving_mean:0 (36,)\n",
      "batch_normalization_7/moving_variance:0 (36,)\n",
      "conv2d_8/kernel:0 (3, 3, 512, 1024)\n",
      "conv2d_8/bias:0 (1024,)\n",
      "batch_normalization_8/gamma:0 (18,)\n",
      "batch_normalization_8/beta:0 (18,)\n",
      "batch_normalization_8/moving_mean:0 (18,)\n",
      "batch_normalization_8/moving_variance:0 (18,)\n",
      "conv2d_9/kernel:0 (3, 3, 1024, 1024)\n",
      "conv2d_9/bias:0 (1024,)\n",
      "batch_normalization_9/gamma:0 (18,)\n",
      "batch_normalization_9/beta:0 (18,)\n",
      "batch_normalization_9/moving_mean:0 (18,)\n",
      "batch_normalization_9/moving_variance:0 (18,)\n",
      "conv2d_transpose/kernel:0 (2, 2, 512, 1024)\n",
      "conv2d_transpose/bias:0 (512,)\n",
      "conv2d_10/kernel:0 (3, 3, 1024, 512)\n",
      "conv2d_10/bias:0 (512,)\n",
      "batch_normalization_10/gamma:0 (36,)\n",
      "batch_normalization_10/beta:0 (36,)\n",
      "batch_normalization_10/moving_mean:0 (36,)\n",
      "batch_normalization_10/moving_variance:0 (36,)\n",
      "conv2d_11/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_11/bias:0 (512,)\n",
      "batch_normalization_11/gamma:0 (36,)\n",
      "batch_normalization_11/beta:0 (36,)\n",
      "batch_normalization_11/moving_mean:0 (36,)\n",
      "batch_normalization_11/moving_variance:0 (36,)\n",
      "conv2d_transpose_1/kernel:0 (2, 2, 256, 512)\n",
      "conv2d_transpose_1/bias:0 (256,)\n",
      "conv2d_12/kernel:0 (3, 3, 512, 256)\n",
      "conv2d_12/bias:0 (256,)\n",
      "batch_normalization_12/gamma:0 (72,)\n",
      "batch_normalization_12/beta:0 (72,)\n",
      "batch_normalization_12/moving_mean:0 (72,)\n",
      "batch_normalization_12/moving_variance:0 (72,)\n",
      "conv2d_13/kernel:0 (3, 3, 256, 256)\n",
      "conv2d_13/bias:0 (256,)\n",
      "batch_normalization_13/gamma:0 (72,)\n",
      "batch_normalization_13/beta:0 (72,)\n",
      "batch_normalization_13/moving_mean:0 (72,)\n",
      "batch_normalization_13/moving_variance:0 (72,)\n",
      "conv2d_transpose_2/kernel:0 (2, 2, 128, 256)\n",
      "conv2d_transpose_2/bias:0 (128,)\n",
      "conv2d_14/kernel:0 (3, 3, 256, 128)\n",
      "conv2d_14/bias:0 (128,)\n",
      "batch_normalization_14/gamma:0 (144,)\n",
      "batch_normalization_14/beta:0 (144,)\n",
      "batch_normalization_14/moving_mean:0 (144,)\n",
      "batch_normalization_14/moving_variance:0 (144,)\n",
      "conv2d_15/kernel:0 (3, 3, 128, 128)\n",
      "conv2d_15/bias:0 (128,)\n",
      "batch_normalization_15/gamma:0 (144,)\n",
      "batch_normalization_15/beta:0 (144,)\n",
      "batch_normalization_15/moving_mean:0 (144,)\n",
      "batch_normalization_15/moving_variance:0 (144,)\n",
      "conv2d_transpose_3/kernel:0 (2, 2, 64, 128)\n",
      "conv2d_transpose_3/bias:0 (64,)\n",
      "conv2d_16/kernel:0 (3, 3, 128, 64)\n",
      "conv2d_16/bias:0 (64,)\n",
      "batch_normalization_16/gamma:0 (288,)\n",
      "batch_normalization_16/beta:0 (288,)\n",
      "batch_normalization_16/moving_mean:0 (288,)\n",
      "batch_normalization_16/moving_variance:0 (288,)\n",
      "conv2d_17/kernel:0 (3, 3, 64, 64)\n",
      "conv2d_17/bias:0 (64,)\n",
      "batch_normalization_17/gamma:0 (288,)\n",
      "batch_normalization_17/beta:0 (288,)\n",
      "batch_normalization_17/moving_mean:0 (288,)\n",
      "batch_normalization_17/moving_variance:0 (288,)\n",
      "conv2d_18/kernel:0 (1, 1, 64, 1)\n",
      "conv2d_18/bias:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "for l in model.weights:\n",
    "    print(l.name, l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7566fae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0403_229.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT0403_229.tif (704, 1, 288, 288) (704, 1, 288, 288)\n",
      "BT0407_110.tif (7, 2304, 2304) (5, 2304, 2304)\n",
      "BT0407_110.tif (320, 1, 288, 288) (320, 1, 288, 288)\n",
      "BT0398_210.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT0398_210.tif (704, 1, 288, 288) (704, 1, 288, 288)\n",
      "BT402_169.tif (5, 2304, 2304) (3, 2304, 2304)\n",
      "BT402_169.tif (192, 1, 288, 288) (192, 1, 288, 288)\n",
      "BT403_002.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT403_002.tif (704, 1, 288, 288) (704, 1, 288, 288)\n",
      "BT404_199.tif (5, 2304, 2304) (3, 2304, 2304)\n",
      "BT404_199.tif (192, 1, 288, 288) (192, 1, 288, 288)\n",
      "dict_keys(['BT0403_229.tif', 'BT0407_110.tif', 'BT0398_210.tif', 'BT402_169.tif', 'BT403_002.tif', 'BT404_199.tif'])\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import patch_image, patch_stack, normalizePercentile, normalizeMinMax\n",
    "from patchify import patchify\n",
    "\n",
    "source_path = r\"Bactnet/Training data/stacks/\"\n",
    "SIZE = 288\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(source_path, PATCH_SIZE, validation=True):\n",
    "    pred_dict = {}\n",
    "    if validation:\n",
    "        prefix = \"validation\"\n",
    "    else:\n",
    "        prefix = \"training\"\n",
    "    stacks = os.listdir(os.path.join(source_path, prefix+\"_source\"))\n",
    "    image_dataset = None\n",
    "    mask_dataset = None\n",
    "    for stack in stacks:\n",
    "        if (stack.split(\".\")[-1]==\"tif\"):\n",
    "            pred_dict[stack]={}\n",
    "            img = tiff.imread(os.path.join(source_path, prefix+\"_source\",stack))\n",
    "            pred_dict[stack][\"image\"]=img\n",
    "            mask = tiff.imread(os.path.join(source_path, prefix+\"_target\", stack))\n",
    "            pred_dict[stack][\"y_true\"]=mask\n",
    "            print(stack, img.shape, mask.shape)\n",
    "            \n",
    "            img_patch = patch_stack(img[1:-1], PATCH_SIZE, DEPTH=1)\n",
    "            if len(mask.shape)==2:\n",
    "                mask_patch = patch_image(mask, PATCH_SIZE)\n",
    "            else:    \n",
    "                mask_patch = patch_stack(mask, SIZE=PATCH_SIZE, DEPTH=1)\n",
    "            \n",
    "            print(stack, img_patch.shape, mask_patch.shape)\n",
    "            mask_patch = normalizeMinMax(mask_patch)\n",
    "            img_patch = normalizePercentile(img_patch, 0.1, 99.9, clip=True)\n",
    "            pred_dict[stack][\"image_patch\"] = img_patch\n",
    "            pred_dict[stack][\"mask_patch\"] = mask_patch\n",
    "\n",
    "\n",
    "            #print(image_dataset.shape, mask_dataset.shape)\n",
    "\n",
    "    return pred_dict\n",
    "\n",
    "#pred_dict[file]=[image_stack, mask, patch, y_true, y_pred]\n",
    "image_dict = prepare_data(source_path, SIZE, validation=True)\n",
    "image_dict.update(prepare_data(source_path, SIZE, validation=False))\n",
    "print(image_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed33048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0403_229.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT0407_110.tif (320, 1, 288, 288) (5, 1, 2304, 2304)\n",
      "BT0398_210.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT402_169.tif (192, 1, 288, 288) (3, 1, 2304, 2304)\n",
      "BT403_002.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT404_199.tif (192, 1, 288, 288) (3, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "stride = 2\n",
    "\n",
    "# #IOU\n",
    "for stack in image_dict.keys():\n",
    "    y_pred = None\n",
    "    img_stack = image_dict[stack]\n",
    "    for i in range(0, len(img_stack[\"image_patch\"]), stride):\n",
    "        pred = model.predict(img_stack[\"image_patch\"][i:i+stride])\n",
    "        if y_pred is not None:\n",
    "            y_pred = np.concatenate((y_pred, pred))\n",
    "\n",
    "        if y_pred is None:\n",
    "            y_pred = pred\n",
    "    \n",
    "    image_dict[stack][\"y_pred\"] = unpatch_stack(y_pred, 8, 8, 1)\n",
    "    print(stack, y_pred.shape, image_dict[stack][\"y_pred\"].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c8ddc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1, 2304, 2304) 1.0\n",
      "(5, 1, 2304, 2304) 1.0\n",
      "(11, 1, 2304, 2304) 1.0\n",
      "(3, 1, 2304, 2304) 1.0\n",
      "(11, 1, 2304, 2304) 1.0\n",
      "(3, 1, 2304, 2304) 1.0\n"
     ]
    }
   ],
   "source": [
    "prefix = \"single_60ep_\"\n",
    "for stack in image_dict.keys():\n",
    "    saveme = np.concatenate(((image_dict[stack][\"y_pred\"]>0.5)*255, np.expand_dims(image_dict[stack][\"y_true\"],axis=1)), axis=1)\n",
    "    saveme = saveme.astype('uint8')\n",
    "    \n",
    "    dic = unpatch_stack(image_dict[stack][\"image_patch\"], 8, 8, 1)\n",
    "    dic = dic[:,0,:,:] * 255\n",
    "    dic = np.expand_dims(dic, axis=1).astype('uint8')\n",
    "    print(dic.shape, image_dict[stack][\"image_patch\"].max())\n",
    "    saveme = np.concatenate((dic, saveme), axis=1)\n",
    "    tiff.imwrite(os.path.join(r\"C:\\Users\\Jens\\Documents\\Code\\BactUnet\\Bactnet\\Training data\\stacks\\predict\", prefix+stack), saveme, imagej=True,\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc652211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_tru = None\n",
    "y_pre = None\n",
    "\n",
    "for stack in image_dict.keys():\n",
    "    if y_tru is None:\n",
    "        y_tru = image_dict[stack][\"y_true\"]\n",
    "        y_pre = image_dict[stack][\"y_pred\"]\n",
    "    else:\n",
    "        y_tru = np.concatenate((y_tru, image_dict[stack][\"y_true\"]))\n",
    "        y_pre = np.concatenate((y_pre, image_dict[stack][\"y_pred\"]))\n",
    "        \n",
    "dices = []\n",
    "IOUs = []\n",
    "frames = []\n",
    "threshold = 0.5\n",
    "\n",
    "y_pred_thresholded = (y_pre > threshold) * 255\n",
    "y_pred_thresholded = y_pred_thresholded.astype('uint8')\n",
    "\n",
    "for i in range(len(y_tru)):\n",
    "    intersection = np.logical_and(y_tru[i], y_pred_thresholded[i])\n",
    "    union = np.logical_or(y_tru[i], y_pred_thresholded[i])\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    IOUs.append(iou_score)\n",
    "\n",
    "frames =  list(range(len(y_tru)))\n",
    "\n",
    "    \n",
    "#plt.plot(frames, dices)\n",
    "plt.plot(frames, IOUs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997b4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(mask1, mask2):\n",
    "    intersect = np.sum(mask1*mask2)\n",
    "    fsum = np.sum(mask1)\n",
    "    ssum = np.sum(mask2)\n",
    "    dice = (2 * intersect ) / (fsum + ssum)\n",
    "    dice = np.mean(dice)\n",
    "    dice = round(dice, 3) # for easy reading\n",
    "    return dice    \n",
    "\n",
    "def iou_score(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask1)\n",
    "    union = np.logical_or(mask1, mask2)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "\n",
    "for stack in image_dict.keys():\n",
    "    image_dict[stack]\n",
    "    image_dict[stack]['y_pred']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd59a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction frames: 0-2 of 891\n",
      "Prediction frames: 2-4 of 891\n",
      "Prediction frames: 4-6 of 891\n",
      "Prediction frames: 6-8 of 891\n",
      "Prediction frames: 8-10 of 891\n",
      "Prediction frames: 10-12 of 891\n",
      "Prediction frames: 12-14 of 891\n",
      "Prediction frames: 14-16 of 891\n",
      "Prediction frames: 16-18 of 891\n",
      "Prediction frames: 18-20 of 891\n",
      "Prediction frames: 20-22 of 891\n",
      "Prediction frames: 22-24 of 891\n",
      "Prediction frames: 24-26 of 891\n",
      "Prediction frames: 26-28 of 891\n",
      "Prediction frames: 28-30 of 891\n",
      "Prediction frames: 30-32 of 891\n",
      "Prediction frames: 32-34 of 891\n",
      "Prediction frames: 34-36 of 891\n",
      "Prediction frames: 36-38 of 891\n",
      "Prediction frames: 38-40 of 891\n",
      "Prediction frames: 40-42 of 891\n",
      "Prediction frames: 42-44 of 891\n",
      "Prediction frames: 44-46 of 891\n",
      "Prediction frames: 46-48 of 891\n",
      "Prediction frames: 48-50 of 891\n",
      "Prediction frames: 50-52 of 891\n",
      "Prediction frames: 52-54 of 891\n",
      "Prediction frames: 54-56 of 891\n",
      "Prediction frames: 56-58 of 891\n",
      "Prediction frames: 58-60 of 891\n",
      "Prediction frames: 60-62 of 891\n",
      "Prediction frames: 62-64 of 891\n",
      "Prediction frames: 64-66 of 891\n",
      "Prediction frames: 66-68 of 891\n",
      "Prediction frames: 68-70 of 891\n",
      "Prediction frames: 70-72 of 891\n",
      "Prediction frames: 72-74 of 891\n",
      "Prediction frames: 74-76 of 891\n",
      "Prediction frames: 76-78 of 891\n",
      "Prediction frames: 78-80 of 891\n",
      "Prediction frames: 80-82 of 891\n",
      "Prediction frames: 82-84 of 891\n",
      "Prediction frames: 84-86 of 891\n",
      "Prediction frames: 86-88 of 891\n",
      "Prediction frames: 88-90 of 891\n",
      "Prediction frames: 90-92 of 891\n",
      "Prediction frames: 92-94 of 891\n",
      "Prediction frames: 94-96 of 891\n",
      "Prediction frames: 96-98 of 891\n",
      "Prediction frames: 98-100 of 891\n",
      "Prediction frames: 100-102 of 891\n",
      "Prediction frames: 102-104 of 891\n",
      "Prediction frames: 104-106 of 891\n",
      "Prediction frames: 106-108 of 891\n",
      "Prediction frames: 108-110 of 891\n",
      "Prediction frames: 110-112 of 891\n",
      "Prediction frames: 112-114 of 891\n",
      "Prediction frames: 114-116 of 891\n",
      "Prediction frames: 116-118 of 891\n",
      "Prediction frames: 118-120 of 891\n",
      "Prediction frames: 120-122 of 891\n",
      "Prediction frames: 122-124 of 891\n",
      "Prediction frames: 124-126 of 891\n",
      "Prediction frames: 126-128 of 891\n",
      "Prediction frames: 128-130 of 891\n",
      "Prediction frames: 130-132 of 891\n",
      "Prediction frames: 132-134 of 891\n",
      "Prediction frames: 134-136 of 891\n",
      "Prediction frames: 136-138 of 891\n",
      "Prediction frames: 138-140 of 891\n",
      "Prediction frames: 140-142 of 891\n",
      "Prediction frames: 142-144 of 891\n",
      "Prediction frames: 144-146 of 891\n",
      "Prediction frames: 146-148 of 891\n",
      "Prediction frames: 148-150 of 891\n",
      "Prediction frames: 150-152 of 891\n",
      "Prediction frames: 152-154 of 891\n",
      "Prediction frames: 154-156 of 891\n",
      "Prediction frames: 156-158 of 891\n",
      "Prediction frames: 158-160 of 891\n",
      "Prediction frames: 160-162 of 891\n",
      "Prediction frames: 162-164 of 891\n",
      "Prediction frames: 164-166 of 891\n",
      "Prediction frames: 166-168 of 891\n",
      "Prediction frames: 168-170 of 891\n",
      "Prediction frames: 170-172 of 891\n",
      "Prediction frames: 172-174 of 891\n",
      "Prediction frames: 174-176 of 891\n",
      "Prediction frames: 176-178 of 891\n",
      "Prediction frames: 178-180 of 891\n",
      "Prediction frames: 180-182 of 891\n",
      "Prediction frames: 182-184 of 891\n",
      "Prediction frames: 184-186 of 891\n",
      "Prediction frames: 186-188 of 891\n",
      "Prediction frames: 188-190 of 891\n",
      "Prediction frames: 190-192 of 891\n",
      "Prediction frames: 192-194 of 891\n",
      "Prediction frames: 194-196 of 891\n",
      "Prediction frames: 196-198 of 891\n",
      "Prediction frames: 198-200 of 891\n",
      "Prediction frames: 200-202 of 891\n",
      "Prediction frames: 202-204 of 891\n",
      "Prediction frames: 204-206 of 891\n",
      "Prediction frames: 206-208 of 891\n",
      "Prediction frames: 208-210 of 891\n",
      "Prediction frames: 210-212 of 891\n",
      "Prediction frames: 212-214 of 891\n",
      "Prediction frames: 214-216 of 891\n",
      "Prediction frames: 216-218 of 891\n",
      "Prediction frames: 218-220 of 891\n",
      "Prediction frames: 220-222 of 891\n",
      "Prediction frames: 222-224 of 891\n",
      "Prediction frames: 224-226 of 891\n",
      "Prediction frames: 226-228 of 891\n",
      "Prediction frames: 228-230 of 891\n",
      "Prediction frames: 230-232 of 891\n",
      "Prediction frames: 232-234 of 891\n",
      "Prediction frames: 234-236 of 891\n",
      "Prediction frames: 236-238 of 891\n",
      "Prediction frames: 238-240 of 891\n",
      "Prediction frames: 240-242 of 891\n",
      "Prediction frames: 242-244 of 891\n",
      "Prediction frames: 244-246 of 891\n",
      "Prediction frames: 246-248 of 891\n",
      "Prediction frames: 248-250 of 891\n",
      "Prediction frames: 250-252 of 891\n",
      "Prediction frames: 252-254 of 891\n",
      "Prediction frames: 254-256 of 891\n",
      "Prediction frames: 256-258 of 891\n",
      "Prediction frames: 258-260 of 891\n",
      "Prediction frames: 260-262 of 891\n",
      "Prediction frames: 262-264 of 891\n",
      "Prediction frames: 264-266 of 891\n",
      "Prediction frames: 266-268 of 891\n",
      "Prediction frames: 268-270 of 891\n",
      "Prediction frames: 270-272 of 891\n",
      "Prediction frames: 272-274 of 891\n",
      "Prediction frames: 274-276 of 891\n",
      "Prediction frames: 276-278 of 891\n",
      "Prediction frames: 278-280 of 891\n",
      "Prediction frames: 280-282 of 891\n",
      "Prediction frames: 282-284 of 891\n",
      "Prediction frames: 284-286 of 891\n",
      "Prediction frames: 286-288 of 891\n",
      "Prediction frames: 288-290 of 891\n",
      "Prediction frames: 290-292 of 891\n",
      "Prediction frames: 292-294 of 891\n",
      "Prediction frames: 294-296 of 891\n",
      "Prediction frames: 296-298 of 891\n",
      "Prediction frames: 298-300 of 891\n",
      "Prediction frames: 300-302 of 891\n",
      "Prediction frames: 302-304 of 891\n",
      "Prediction frames: 304-306 of 891\n",
      "Prediction frames: 306-308 of 891\n",
      "Prediction frames: 308-310 of 891\n",
      "Prediction frames: 310-312 of 891\n",
      "Prediction frames: 312-314 of 891\n",
      "Prediction frames: 314-316 of 891\n",
      "Prediction frames: 316-318 of 891\n",
      "Prediction frames: 318-320 of 891\n",
      "Prediction frames: 320-322 of 891\n",
      "Prediction frames: 322-324 of 891\n",
      "Prediction frames: 324-326 of 891\n",
      "Prediction frames: 326-328 of 891\n",
      "Prediction frames: 328-330 of 891\n",
      "Prediction frames: 330-332 of 891\n",
      "Prediction frames: 332-334 of 891\n",
      "Prediction frames: 334-336 of 891\n",
      "Prediction frames: 336-338 of 891\n",
      "Prediction frames: 338-340 of 891\n",
      "Prediction frames: 340-342 of 891\n",
      "Prediction frames: 342-344 of 891\n",
      "Prediction frames: 344-346 of 891\n",
      "Prediction frames: 346-348 of 891\n",
      "Prediction frames: 348-350 of 891\n",
      "Prediction frames: 350-352 of 891\n",
      "Prediction frames: 352-354 of 891\n",
      "Prediction frames: 354-356 of 891\n",
      "Prediction frames: 356-358 of 891\n",
      "Prediction frames: 358-360 of 891\n",
      "Prediction frames: 360-362 of 891\n",
      "Prediction frames: 362-364 of 891\n",
      "Prediction frames: 364-366 of 891\n",
      "Prediction frames: 366-368 of 891\n",
      "Prediction frames: 368-370 of 891\n",
      "Prediction frames: 370-372 of 891\n",
      "Prediction frames: 372-374 of 891\n",
      "Prediction frames: 374-376 of 891\n",
      "Prediction frames: 376-378 of 891\n",
      "Prediction frames: 378-380 of 891\n",
      "Prediction frames: 380-382 of 891\n",
      "Prediction frames: 382-384 of 891\n",
      "Prediction frames: 384-386 of 891\n",
      "Prediction frames: 386-388 of 891\n",
      "Prediction frames: 388-390 of 891\n",
      "Prediction frames: 390-392 of 891\n",
      "Prediction frames: 392-394 of 891\n",
      "Prediction frames: 394-396 of 891\n",
      "Prediction frames: 396-398 of 891\n",
      "Prediction frames: 398-400 of 891\n",
      "Prediction frames: 400-402 of 891\n",
      "Prediction frames: 402-404 of 891\n",
      "Prediction frames: 404-406 of 891\n",
      "Prediction frames: 406-408 of 891\n",
      "Prediction frames: 408-410 of 891\n",
      "Prediction frames: 410-412 of 891\n",
      "Prediction frames: 412-414 of 891\n",
      "Prediction frames: 414-416 of 891\n",
      "Prediction frames: 416-418 of 891\n",
      "Prediction frames: 418-420 of 891\n",
      "Prediction frames: 420-422 of 891\n",
      "Prediction frames: 422-424 of 891\n",
      "Prediction frames: 424-426 of 891\n",
      "Prediction frames: 426-428 of 891\n",
      "Prediction frames: 428-430 of 891\n",
      "Prediction frames: 430-432 of 891\n",
      "Prediction frames: 432-434 of 891\n",
      "Prediction frames: 434-436 of 891\n",
      "Prediction frames: 436-438 of 891\n",
      "Prediction frames: 438-440 of 891\n",
      "Prediction frames: 440-442 of 891\n",
      "Prediction frames: 442-444 of 891\n",
      "Prediction frames: 444-446 of 891\n",
      "Prediction frames: 446-448 of 891\n",
      "Prediction frames: 448-450 of 891\n",
      "Prediction frames: 450-452 of 891\n",
      "Prediction frames: 452-454 of 891\n",
      "Prediction frames: 454-456 of 891\n",
      "Prediction frames: 456-458 of 891\n",
      "Prediction frames: 458-460 of 891\n",
      "Prediction frames: 460-462 of 891\n",
      "Prediction frames: 462-464 of 891\n",
      "Prediction frames: 464-466 of 891\n",
      "Prediction frames: 466-468 of 891\n",
      "Prediction frames: 468-470 of 891\n",
      "Prediction frames: 470-472 of 891\n",
      "Prediction frames: 472-474 of 891\n",
      "Prediction frames: 474-476 of 891\n",
      "Prediction frames: 476-478 of 891\n",
      "Prediction frames: 478-480 of 891\n",
      "Prediction frames: 480-482 of 891\n",
      "Prediction frames: 482-484 of 891\n",
      "Prediction frames: 484-486 of 891\n",
      "Prediction frames: 486-488 of 891\n",
      "Prediction frames: 488-490 of 891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction frames: 490-492 of 891\n",
      "Prediction frames: 492-494 of 891\n",
      "Prediction frames: 494-496 of 891\n",
      "Prediction frames: 496-498 of 891\n",
      "Prediction frames: 498-500 of 891\n",
      "Prediction frames: 500-502 of 891\n",
      "Prediction frames: 502-504 of 891\n",
      "Prediction frames: 504-506 of 891\n",
      "Prediction frames: 506-508 of 891\n",
      "Prediction frames: 508-510 of 891\n",
      "Prediction frames: 510-512 of 891\n",
      "Prediction frames: 512-514 of 891\n",
      "Prediction frames: 514-516 of 891\n",
      "Prediction frames: 516-518 of 891\n",
      "Prediction frames: 518-520 of 891\n",
      "Prediction frames: 520-522 of 891\n",
      "Prediction frames: 522-524 of 891\n",
      "Prediction frames: 524-526 of 891\n",
      "Prediction frames: 526-528 of 891\n",
      "Prediction frames: 528-530 of 891\n",
      "Prediction frames: 530-532 of 891\n",
      "Prediction frames: 532-534 of 891\n",
      "Prediction frames: 534-536 of 891\n",
      "Prediction frames: 536-538 of 891\n",
      "Prediction frames: 538-540 of 891\n",
      "Prediction frames: 540-542 of 891\n",
      "Prediction frames: 542-544 of 891\n",
      "Prediction frames: 544-546 of 891\n",
      "Prediction frames: 546-548 of 891\n",
      "Prediction frames: 548-550 of 891\n",
      "Prediction frames: 550-552 of 891\n",
      "Prediction frames: 552-554 of 891\n",
      "Prediction frames: 554-556 of 891\n",
      "Prediction frames: 556-558 of 891\n",
      "Prediction frames: 558-560 of 891\n",
      "Prediction frames: 560-562 of 891\n",
      "Prediction frames: 562-564 of 891\n",
      "Prediction frames: 564-566 of 891\n",
      "Prediction frames: 566-568 of 891\n",
      "Prediction frames: 568-570 of 891\n",
      "Prediction frames: 570-572 of 891\n",
      "Prediction frames: 572-574 of 891\n",
      "Prediction frames: 574-576 of 891\n",
      "Prediction frames: 576-578 of 891\n",
      "Prediction frames: 578-580 of 891\n",
      "Prediction frames: 580-582 of 891\n",
      "Prediction frames: 582-584 of 891\n",
      "Prediction frames: 584-586 of 891\n",
      "Prediction frames: 586-588 of 891\n",
      "Prediction frames: 588-590 of 891\n",
      "Prediction frames: 590-592 of 891\n",
      "Prediction frames: 592-594 of 891\n",
      "Prediction frames: 594-596 of 891\n",
      "Prediction frames: 596-598 of 891\n",
      "Prediction frames: 598-600 of 891\n",
      "Prediction frames: 600-602 of 891\n",
      "Prediction frames: 602-604 of 891\n",
      "Prediction frames: 604-606 of 891\n",
      "Prediction frames: 606-608 of 891\n",
      "Prediction frames: 608-610 of 891\n",
      "Prediction frames: 610-612 of 891\n",
      "Prediction frames: 612-614 of 891\n",
      "Prediction frames: 614-616 of 891\n",
      "Prediction frames: 616-618 of 891\n",
      "Prediction frames: 618-620 of 891\n",
      "Prediction frames: 620-622 of 891\n",
      "Prediction frames: 622-624 of 891\n",
      "Prediction frames: 624-626 of 891\n",
      "Prediction frames: 626-628 of 891\n",
      "Prediction frames: 628-630 of 891\n",
      "Prediction frames: 630-632 of 891\n",
      "Prediction frames: 632-634 of 891\n",
      "Prediction frames: 634-636 of 891\n",
      "Prediction frames: 636-638 of 891\n",
      "Prediction frames: 638-640 of 891\n",
      "Prediction frames: 640-642 of 891\n",
      "Prediction frames: 642-644 of 891\n",
      "Prediction frames: 644-646 of 891\n",
      "Prediction frames: 646-648 of 891\n",
      "Prediction frames: 648-650 of 891\n",
      "Prediction frames: 650-652 of 891\n",
      "Prediction frames: 652-654 of 891\n",
      "Prediction frames: 654-656 of 891\n",
      "Prediction frames: 656-658 of 891\n",
      "Prediction frames: 658-660 of 891\n",
      "Prediction frames: 660-662 of 891\n",
      "Prediction frames: 662-664 of 891\n",
      "Prediction frames: 664-666 of 891\n",
      "Prediction frames: 666-668 of 891\n",
      "Prediction frames: 668-670 of 891\n",
      "Prediction frames: 670-672 of 891\n",
      "Prediction frames: 672-674 of 891\n",
      "Prediction frames: 674-676 of 891\n",
      "Prediction frames: 676-678 of 891\n",
      "Prediction frames: 678-680 of 891\n",
      "Prediction frames: 680-682 of 891\n",
      "Prediction frames: 682-684 of 891\n",
      "Prediction frames: 684-686 of 891\n",
      "Prediction frames: 686-688 of 891\n",
      "Prediction frames: 688-690 of 891\n",
      "Prediction frames: 690-692 of 891\n",
      "Prediction frames: 692-694 of 891\n",
      "Prediction frames: 694-696 of 891\n",
      "Prediction frames: 696-698 of 891\n",
      "Prediction frames: 698-700 of 891\n",
      "Prediction frames: 700-702 of 891\n",
      "Prediction frames: 702-704 of 891\n",
      "Prediction frames: 704-706 of 891\n",
      "Prediction frames: 706-708 of 891\n",
      "Prediction frames: 708-710 of 891\n",
      "Prediction frames: 710-712 of 891\n",
      "Prediction frames: 712-714 of 891\n",
      "Prediction frames: 714-716 of 891\n",
      "Prediction frames: 716-718 of 891\n",
      "Prediction frames: 718-720 of 891\n",
      "Prediction frames: 720-722 of 891\n",
      "Prediction frames: 722-724 of 891\n",
      "Prediction frames: 724-726 of 891\n",
      "Prediction frames: 726-728 of 891\n",
      "Prediction frames: 728-730 of 891\n",
      "Prediction frames: 730-732 of 891\n",
      "Prediction frames: 732-734 of 891\n",
      "Prediction frames: 734-736 of 891\n",
      "Prediction frames: 736-738 of 891\n",
      "Prediction frames: 738-740 of 891\n",
      "Prediction frames: 740-742 of 891\n",
      "Prediction frames: 742-744 of 891\n",
      "Prediction frames: 744-746 of 891\n",
      "Prediction frames: 746-748 of 891\n",
      "Prediction frames: 748-750 of 891\n",
      "Prediction frames: 750-752 of 891\n",
      "Prediction frames: 752-754 of 891\n",
      "Prediction frames: 754-756 of 891\n",
      "Prediction frames: 756-758 of 891\n",
      "Prediction frames: 758-760 of 891\n",
      "Prediction frames: 760-762 of 891\n",
      "Prediction frames: 762-764 of 891\n",
      "Prediction frames: 764-766 of 891\n",
      "Prediction frames: 766-768 of 891\n",
      "Prediction frames: 768-770 of 891\n",
      "Prediction frames: 770-772 of 891\n",
      "Prediction frames: 772-774 of 891\n",
      "Prediction frames: 774-776 of 891\n",
      "Prediction frames: 776-778 of 891\n",
      "Prediction frames: 778-780 of 891\n",
      "Prediction frames: 780-782 of 891\n",
      "Prediction frames: 782-784 of 891\n",
      "Prediction frames: 784-786 of 891\n",
      "Prediction frames: 786-788 of 891\n",
      "Prediction frames: 788-790 of 891\n",
      "Prediction frames: 790-792 of 891\n",
      "Prediction frames: 792-794 of 891\n",
      "Prediction frames: 794-796 of 891\n",
      "Prediction frames: 796-798 of 891\n",
      "Prediction frames: 798-800 of 891\n",
      "Prediction frames: 800-802 of 891\n",
      "Prediction frames: 802-804 of 891\n",
      "Prediction frames: 804-806 of 891\n",
      "Prediction frames: 806-808 of 891\n",
      "Prediction frames: 808-810 of 891\n",
      "Prediction frames: 810-812 of 891\n",
      "Prediction frames: 812-814 of 891\n",
      "Prediction frames: 814-816 of 891\n",
      "Prediction frames: 816-818 of 891\n",
      "Prediction frames: 818-820 of 891\n",
      "Prediction frames: 820-822 of 891\n",
      "Prediction frames: 822-824 of 891\n",
      "Prediction frames: 824-826 of 891\n",
      "Prediction frames: 826-828 of 891\n",
      "Prediction frames: 828-830 of 891\n",
      "Prediction frames: 830-832 of 891\n",
      "Prediction frames: 832-834 of 891\n",
      "Prediction frames: 834-836 of 891\n",
      "Prediction frames: 836-838 of 891\n",
      "Prediction frames: 838-840 of 891\n",
      "Prediction frames: 840-842 of 891\n",
      "Prediction frames: 842-844 of 891\n",
      "Prediction frames: 844-846 of 891\n",
      "Prediction frames: 846-848 of 891\n",
      "Prediction frames: 848-850 of 891\n",
      "Prediction frames: 850-852 of 891\n",
      "Prediction frames: 852-854 of 891\n",
      "Prediction frames: 854-856 of 891\n",
      "Prediction frames: 856-858 of 891\n",
      "Prediction frames: 858-860 of 891\n",
      "Prediction frames: 860-862 of 891\n",
      "Prediction frames: 862-864 of 891\n",
      "Prediction frames: 864-866 of 891\n",
      "Prediction frames: 866-868 of 891\n",
      "Prediction frames: 868-870 of 891\n",
      "Prediction frames: 870-872 of 891\n",
      "Prediction frames: 872-874 of 891\n",
      "Prediction frames: 874-876 of 891\n",
      "Prediction frames: 876-878 of 891\n",
      "Prediction frames: 878-880 of 891\n",
      "Prediction frames: 880-882 of 891\n",
      "Prediction frames: 882-884 of 891\n",
      "Prediction frames: 884-886 of 891\n",
      "Prediction frames: 886-888 of 891\n",
      "Prediction frames: 888-890 of 891\n",
      "Prediction frames: 890-892 of 891\n",
      "BT0403_229.tif (13, 2592, 2592) (11, 1, 2304, 2304) (11, 1, 2304, 2304)\n",
      "Prediction frames: 0-2 of 405\n",
      "Prediction frames: 2-4 of 405\n",
      "Prediction frames: 4-6 of 405\n",
      "Prediction frames: 6-8 of 405\n",
      "Prediction frames: 8-10 of 405\n",
      "Prediction frames: 10-12 of 405\n",
      "Prediction frames: 12-14 of 405\n",
      "Prediction frames: 14-16 of 405\n",
      "Prediction frames: 16-18 of 405\n",
      "Prediction frames: 18-20 of 405\n",
      "Prediction frames: 20-22 of 405\n",
      "Prediction frames: 22-24 of 405\n",
      "Prediction frames: 24-26 of 405\n",
      "Prediction frames: 26-28 of 405\n",
      "Prediction frames: 28-30 of 405\n",
      "Prediction frames: 30-32 of 405\n",
      "Prediction frames: 32-34 of 405\n",
      "Prediction frames: 34-36 of 405\n",
      "Prediction frames: 36-38 of 405\n",
      "Prediction frames: 38-40 of 405\n",
      "Prediction frames: 40-42 of 405\n",
      "Prediction frames: 42-44 of 405\n",
      "Prediction frames: 44-46 of 405\n",
      "Prediction frames: 46-48 of 405\n",
      "Prediction frames: 48-50 of 405\n",
      "Prediction frames: 50-52 of 405\n",
      "Prediction frames: 52-54 of 405\n",
      "Prediction frames: 54-56 of 405\n",
      "Prediction frames: 56-58 of 405\n",
      "Prediction frames: 58-60 of 405\n",
      "Prediction frames: 60-62 of 405\n",
      "Prediction frames: 62-64 of 405\n",
      "Prediction frames: 64-66 of 405\n",
      "Prediction frames: 66-68 of 405\n",
      "Prediction frames: 68-70 of 405\n",
      "Prediction frames: 70-72 of 405\n",
      "Prediction frames: 72-74 of 405\n",
      "Prediction frames: 74-76 of 405\n",
      "Prediction frames: 76-78 of 405\n",
      "Prediction frames: 78-80 of 405\n",
      "Prediction frames: 80-82 of 405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction frames: 82-84 of 405\n",
      "Prediction frames: 84-86 of 405\n",
      "Prediction frames: 86-88 of 405\n",
      "Prediction frames: 88-90 of 405\n",
      "Prediction frames: 90-92 of 405\n",
      "Prediction frames: 92-94 of 405\n",
      "Prediction frames: 94-96 of 405\n",
      "Prediction frames: 96-98 of 405\n",
      "Prediction frames: 98-100 of 405\n",
      "Prediction frames: 100-102 of 405\n",
      "Prediction frames: 102-104 of 405\n",
      "Prediction frames: 104-106 of 405\n",
      "Prediction frames: 106-108 of 405\n",
      "Prediction frames: 108-110 of 405\n",
      "Prediction frames: 110-112 of 405\n",
      "Prediction frames: 112-114 of 405\n",
      "Prediction frames: 114-116 of 405\n",
      "Prediction frames: 116-118 of 405\n",
      "Prediction frames: 118-120 of 405\n",
      "Prediction frames: 120-122 of 405\n",
      "Prediction frames: 122-124 of 405\n",
      "Prediction frames: 124-126 of 405\n",
      "Prediction frames: 126-128 of 405\n",
      "Prediction frames: 128-130 of 405\n",
      "Prediction frames: 130-132 of 405\n",
      "Prediction frames: 132-134 of 405\n",
      "Prediction frames: 134-136 of 405\n",
      "Prediction frames: 136-138 of 405\n",
      "Prediction frames: 138-140 of 405\n",
      "Prediction frames: 140-142 of 405\n",
      "Prediction frames: 142-144 of 405\n",
      "Prediction frames: 144-146 of 405\n",
      "Prediction frames: 146-148 of 405\n",
      "Prediction frames: 148-150 of 405\n",
      "Prediction frames: 150-152 of 405\n",
      "Prediction frames: 152-154 of 405\n",
      "Prediction frames: 154-156 of 405\n",
      "Prediction frames: 156-158 of 405\n",
      "Prediction frames: 158-160 of 405\n",
      "Prediction frames: 160-162 of 405\n",
      "Prediction frames: 162-164 of 405\n",
      "Prediction frames: 164-166 of 405\n",
      "Prediction frames: 166-168 of 405\n",
      "Prediction frames: 168-170 of 405\n",
      "Prediction frames: 170-172 of 405\n",
      "Prediction frames: 172-174 of 405\n",
      "Prediction frames: 174-176 of 405\n",
      "Prediction frames: 176-178 of 405\n",
      "Prediction frames: 178-180 of 405\n",
      "Prediction frames: 180-182 of 405\n",
      "Prediction frames: 182-184 of 405\n",
      "Prediction frames: 184-186 of 405\n",
      "Prediction frames: 186-188 of 405\n",
      "Prediction frames: 188-190 of 405\n",
      "Prediction frames: 190-192 of 405\n",
      "Prediction frames: 192-194 of 405\n",
      "Prediction frames: 194-196 of 405\n",
      "Prediction frames: 196-198 of 405\n",
      "Prediction frames: 198-200 of 405\n",
      "Prediction frames: 200-202 of 405\n",
      "Prediction frames: 202-204 of 405\n",
      "Prediction frames: 204-206 of 405\n",
      "Prediction frames: 206-208 of 405\n",
      "Prediction frames: 208-210 of 405\n",
      "Prediction frames: 210-212 of 405\n",
      "Prediction frames: 212-214 of 405\n",
      "Prediction frames: 214-216 of 405\n",
      "Prediction frames: 216-218 of 405\n",
      "Prediction frames: 218-220 of 405\n",
      "Prediction frames: 220-222 of 405\n",
      "Prediction frames: 222-224 of 405\n",
      "Prediction frames: 224-226 of 405\n",
      "Prediction frames: 226-228 of 405\n",
      "Prediction frames: 228-230 of 405\n",
      "Prediction frames: 230-232 of 405\n",
      "Prediction frames: 232-234 of 405\n",
      "Prediction frames: 234-236 of 405\n",
      "Prediction frames: 236-238 of 405\n",
      "Prediction frames: 238-240 of 405\n",
      "Prediction frames: 240-242 of 405\n",
      "Prediction frames: 242-244 of 405\n",
      "Prediction frames: 244-246 of 405\n",
      "Prediction frames: 246-248 of 405\n",
      "Prediction frames: 248-250 of 405\n",
      "Prediction frames: 250-252 of 405\n",
      "Prediction frames: 252-254 of 405\n",
      "Prediction frames: 254-256 of 405\n",
      "Prediction frames: 256-258 of 405\n",
      "Prediction frames: 258-260 of 405\n",
      "Prediction frames: 260-262 of 405\n",
      "Prediction frames: 262-264 of 405\n",
      "Prediction frames: 264-266 of 405\n",
      "Prediction frames: 266-268 of 405\n",
      "Prediction frames: 268-270 of 405\n",
      "Prediction frames: 270-272 of 405\n",
      "Prediction frames: 272-274 of 405\n",
      "Prediction frames: 274-276 of 405\n",
      "Prediction frames: 276-278 of 405\n",
      "Prediction frames: 278-280 of 405\n",
      "Prediction frames: 280-282 of 405\n",
      "Prediction frames: 282-284 of 405\n",
      "Prediction frames: 284-286 of 405\n",
      "Prediction frames: 286-288 of 405\n",
      "Prediction frames: 288-290 of 405\n",
      "Prediction frames: 290-292 of 405\n",
      "Prediction frames: 292-294 of 405\n",
      "Prediction frames: 294-296 of 405\n",
      "Prediction frames: 296-298 of 405\n",
      "Prediction frames: 298-300 of 405\n",
      "Prediction frames: 300-302 of 405\n",
      "Prediction frames: 302-304 of 405\n",
      "Prediction frames: 304-306 of 405\n",
      "Prediction frames: 306-308 of 405\n",
      "Prediction frames: 308-310 of 405\n",
      "Prediction frames: 310-312 of 405\n",
      "Prediction frames: 312-314 of 405\n",
      "Prediction frames: 314-316 of 405\n",
      "Prediction frames: 316-318 of 405\n",
      "Prediction frames: 318-320 of 405\n",
      "Prediction frames: 320-322 of 405\n",
      "Prediction frames: 322-324 of 405\n",
      "Prediction frames: 324-326 of 405\n",
      "Prediction frames: 326-328 of 405\n",
      "Prediction frames: 328-330 of 405\n",
      "Prediction frames: 330-332 of 405\n",
      "Prediction frames: 332-334 of 405\n",
      "Prediction frames: 334-336 of 405\n",
      "Prediction frames: 336-338 of 405\n",
      "Prediction frames: 338-340 of 405\n",
      "Prediction frames: 340-342 of 405\n",
      "Prediction frames: 342-344 of 405\n",
      "Prediction frames: 344-346 of 405\n",
      "Prediction frames: 346-348 of 405\n",
      "Prediction frames: 348-350 of 405\n",
      "Prediction frames: 350-352 of 405\n",
      "Prediction frames: 352-354 of 405\n",
      "Prediction frames: 354-356 of 405\n",
      "Prediction frames: 356-358 of 405\n",
      "Prediction frames: 358-360 of 405\n",
      "Prediction frames: 360-362 of 405\n",
      "Prediction frames: 362-364 of 405\n",
      "Prediction frames: 364-366 of 405\n",
      "Prediction frames: 366-368 of 405\n",
      "Prediction frames: 368-370 of 405\n",
      "Prediction frames: 370-372 of 405\n",
      "Prediction frames: 372-374 of 405\n",
      "Prediction frames: 374-376 of 405\n",
      "Prediction frames: 376-378 of 405\n",
      "Prediction frames: 378-380 of 405\n",
      "Prediction frames: 380-382 of 405\n",
      "Prediction frames: 382-384 of 405\n",
      "Prediction frames: 384-386 of 405\n",
      "Prediction frames: 386-388 of 405\n",
      "Prediction frames: 388-390 of 405\n",
      "Prediction frames: 390-392 of 405\n",
      "Prediction frames: 392-394 of 405\n",
      "Prediction frames: 394-396 of 405\n",
      "Prediction frames: 396-398 of 405\n",
      "Prediction frames: 398-400 of 405\n",
      "Prediction frames: 400-402 of 405\n",
      "Prediction frames: 402-404 of 405\n",
      "Prediction frames: 404-406 of 405\n",
      "BT0407_110.tif (7, 2592, 2592) (5, 1, 2304, 2304) (16, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import pad_stack, crop_stack, predict_stack\n",
    "\n",
    "\n",
    "def crop_stack(arr, SIZE):\n",
    "    \"\"\"\n",
    "    Undoes the padding from pad_stack, crops out the center, removing a 1/2 SIZE broder from around the stack\n",
    "    \"\"\"\n",
    "    pad_SIZE = int(SIZE / 2)\n",
    "\n",
    "    if len(arr.shape) == 3:\n",
    "        t, y, x = arr.shape\n",
    "        stopY = y - pad_SIZE\n",
    "        stopX = x - pad_SIZE\n",
    "        return arr[:, pad_SIZE:stopY, pad_SIZE:stopX]\n",
    "\n",
    "    if len(arr.shape) == 4:\n",
    "        t, c, y, x = arr.shape\n",
    "        stopY = y - pad_SIZE\n",
    "        stopX = x - pad_SIZE\n",
    "        return arr[:, :, pad_SIZE:stopY, pad_SIZE:stopX]\n",
    "\n",
    "#Lets enlarge and see if patch edge regions are affecting the results\n",
    "\n",
    "source_path = r\"Bactnet/Training data/stacks/validation_source\"\n",
    "stacks = os.listdir(os.path.join(source_path))\n",
    "        \n",
    "\n",
    "ypred_2 = None\n",
    "    \n",
    "for i, image_name in enumerate(stacks):  # Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = tiff.imread(os.path.join(source_path, image_name))\n",
    "        image = normalizePercentile(image, 0.1, 99.9, clip=True)\n",
    "        expanded_image = pad_stack(image, SIZE)\n",
    "        expanded_patch = patch_stack(expanded_image, SIZE)\n",
    "        pred = predict_stack(expanded_patch, 2, model)\n",
    "        pred = unpatch_stack(pred, 9, 9, 1)\n",
    "        pred = crop_stack(pred, SIZE)\n",
    "        if ypred_2 is None:\n",
    "            ypred_2 = pred \n",
    "        else:\n",
    "            ypred_2 = np.concatenate((ypred_2, pred))\n",
    "\n",
    "        print(image_name, expanded_image.shape, pred.shape, ypred_2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cce9eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 2304, 2304) (44, 1, 2304, 2304) (16, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "print(y_tru.shape, y_pre.shape, ypred_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "236917c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of each dataset\n",
    "l_BT0398_210 = 11\n",
    "l_BT402_168 = 3\n",
    "l_BT403_000 = 11\n",
    "l_BT403_228 = 11\n",
    "l_BT404_199 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0aa3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dataset = unpatch_stack(image_dataset[:,1,:,:], 8, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb3228e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 1, 2304, 2304) (37, 1, 2304, 2304) (37, 1, 2304, 2304)\n",
      "(37, 4, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset.shape, y_pre.shape, y_tru.shape)\n",
    "saveme = np.concatenate((image_dataset, y_tru, y_pre, ypred_2), axis=1)\n",
    "saveme = saveme * 65535\n",
    "saveme = saveme.astype('uint16')\n",
    "print(saveme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5abebc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = r\"_results\"\n",
    "tiff.imwrite(os.path.join(results_folder, \"all_masked_stacks_V3b.tif\"), saveme, imagej=True, resolution=(1./2.6755, 1./2.6755),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c521a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['210218_murine-ML-hydrogel_60k-cells_A_2_inf_1_MMStack_Default.ome.tif']\n",
      "(100, 2304, 2304) (6272, 3, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "#Viktors data\n",
    "source_path = r\"Bactnet/viktor\"\n",
    "stacks = os.listdir(os.path.join(source_path))\n",
    "print(stacks)\n",
    "vikt = None\n",
    "\n",
    "def predict_stack(arr, batch_size, model):\n",
    "    \"\"\"\n",
    "    Performs prediction on all images in arr using model in increments of batch_size\n",
    "    Assumes patches of a ahpe where N is 0th axis.\n",
    "    \"\"\"\n",
    "    keras.backend.clear_session()\n",
    "    y_pred = None\n",
    "    for i in range(0, len(arr), batch_size):\n",
    "        subset = arr[i:i + batch_size]\n",
    "        \n",
    "        pred = model.predict(subset)\n",
    "        if y_pred is not None:\n",
    "            y_pred = np.concatenate((y_pred, pred))\n",
    "\n",
    "        else:\n",
    "            y_pred = pred\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "for i, image_name in enumerate(stacks):  # Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[-1] == 'tif'):\n",
    "        image = tiff.imread(os.path.join(source_path, image_name))\n",
    "        image = image[0:100]\n",
    "        image = normalizePercentile(image, 0.1, 99.9, clip=True)\n",
    "        patch = patch_stack(image, SIZE)\n",
    "        print(image.shape, patch.shape)\n",
    "        pred = predict_stack(patch, 2, model)\n",
    "        pred = unpatch_stack(pred, 8, 8, 1)\n",
    "        \n",
    "        if vikt is None:\n",
    "            vikt = pred \n",
    "        else:\n",
    "            vikt = np.concatenate((vikt, pred))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f46baa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1, 2304, 2304) (98, 1, 2304, 2304)\n",
      "(98, 2, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "saveme = vikt * 65535\n",
    "saveme = saveme.astype('uint16')\n",
    "img = np.expand_dims(image[0:-2], axis = 1)\n",
    "img = img * 65535\n",
    "img = img.astype('uint16')\n",
    "print(saveme.shape, img.shape)\n",
    "saveme = np.concatenate((img,saveme), axis = 1)\n",
    "print(saveme.shape)\n",
    "tiff.imwrite(os.path.join(source_path, \"pred.tif\"), saveme, imagej=True, resolution=(1./0.109, 1./0.109),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec7f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4637761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0398_210.tif (11, 2304, 2304) (576, 3, 288, 288) (576, 1, 288, 288)\n",
      "(576, 2, 288, 288)\n",
      "BT403_013.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n",
      "BT403_216.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n",
      "BT404_001.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load unseen data\n",
    "\n",
    "validation_image_directory = r\"C:\\Users\\analyst\\Documents\\Python Scripts\\BactUnet\\Bactnet\\Training data\\stacks\\predict\"\n",
    "result_folder = r\"C:\\Users\\analyst\\Documents\\Python Scripts\\BactUnet\\_results\"\n",
    "\n",
    "val_image_dataset = []\n",
    "val_mask_dataset = []\n",
    "pred_mask_dataset = []\n",
    "\n",
    "images = os.listdir(validation_image_directory)\n",
    "\n",
    "for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        \n",
    "        image = tiff.imread(os.path.join(validation_image_directory, image_name))\n",
    "        original_shape = image.shape\n",
    "        patch = patch_stack(image, SIZE)\n",
    "        \n",
    "        patch = normalizePercentile(patch, 0.1, 99.9, clip=True)\n",
    "        pred_mask_patch = model.predict(patch)\n",
    "        print(image_name, original_shape, patch.shape, pred_mask_patch.shape)\n",
    "        #pred_mask_patch = pred_mask_patch[:, 0, :,:]\n",
    "        image = np.expand_dims(patch[:, 1, :,:], axis=1)\n",
    "        patch = np.concatenate((image, pred_mask_patch), axis=1)\n",
    "        unpatched = unpatcher(patch, 8, 8, 2)\n",
    "        print(patch.shape)\n",
    "        tiff.imwrite(os.path.join(result_folder, image_name), unpatched, imagej=True, resolution=(1./2.6755, 1./2.6755),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})\n",
    "        \n",
    "        #pred_mask = unpatch_stack(pred_mask_patch, original_shape)\n",
    "        #tiff.imsave(os.path.join(result_folder, image_name), pred_mask_patch)\n",
    "        #val_image_dataset.append(image)\n",
    "        #pred_mask_dataset.append(pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7a69bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_mask_dataset)):\n",
    "    img = val_image_dataset[i][3]\n",
    "    msk = pred_mask_dataset[i][3]\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(121)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(122)\n",
    "    plt.title('Prediction on test image')\n",
    "    plt.imshow(msk)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c2554c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 conv2d (3, 3, 3, 64)\n",
      "4 conv2d_1 (3, 3, 64, 64)\n",
      "8 conv2d_2 (3, 3, 64, 128)\n",
      "11 conv2d_3 (3, 3, 128, 128)\n",
      "15 conv2d_4 (3, 3, 128, 256)\n",
      "18 conv2d_5 (3, 3, 256, 256)\n",
      "22 conv2d_6 (3, 3, 256, 512)\n",
      "25 conv2d_7 (3, 3, 512, 512)\n",
      "29 conv2d_8 (3, 3, 512, 1024)\n",
      "32 conv2d_9 (3, 3, 1024, 1024)\n",
      "35 conv2d_transpose (2, 2, 512, 1024)\n",
      "37 conv2d_10 (3, 3, 1024, 512)\n",
      "40 conv2d_11 (3, 3, 512, 512)\n",
      "43 conv2d_transpose_1 (2, 2, 256, 512)\n",
      "45 conv2d_12 (3, 3, 512, 256)\n",
      "48 conv2d_13 (3, 3, 256, 256)\n",
      "51 conv2d_transpose_2 (2, 2, 128, 256)\n",
      "53 conv2d_14 (3, 3, 256, 128)\n",
      "56 conv2d_15 (3, 3, 128, 128)\n",
      "59 conv2d_transpose_3 (2, 2, 64, 128)\n",
      "61 conv2d_16 (3, 3, 128, 64)\n",
      "64 conv2d_17 (3, 3, 64, 64)\n",
      "67 conv2d_18 (1, 1, 64, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11188/590165685.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mn_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_filters\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mfig1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mfig1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#Turn off axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 2 with size 3"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAABXCAYAAADve0ugAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAClklEQVR4nO3dsUpbYRjH4f8pdYhITpbGLFLwDoROegNeguAFCO6u4hUIbt6At6CrLm5egC7SxaVFHARFkK/TESwVmng+StvnWZPv5eWc8EuyJE0pJcD/7cOfXgD484QAEAJACIAIARAhAJJ8nObJ8/PzZTQaVVmkbdsqczs3NzdV5j48POTp6amZ9XzbtmUymfS50ouFhYUqcztXV1fVZt/f338vpXya9fxgMCjD4bDPlV4sLS1Vmdu5uLioNruU8svX6lQhGI1G2dra6mejn6yvr1eZ29nb26sy9/z8/F3nJ5NJDg8Pe9rmtdXV1SpzOzXv2enp6df3nB8Oh9nY2OhrnVcODg6qzO00zczvKzPz1QAQAkAIgAgBECEAIgRAhACIEAARAiBCAEQIgAgBECEAIgRAhACIEAARAiBCAEQIgAgBkCl/vHQ8Hmd7e7vKIicnJ1XmdsbjcZW5c3Nz7zp/e3ubo6OjnrZ5bXl5ucrczuXlZdX57/H8/Jy7u7sqs3d2dqrM7QwGgypzHx8f33zMJwJACAAhACIEQIQAiBAAEQIgQgBECIAIARAhACIEQIQAiBAAEQIgQgBECIAIARAhACIEQIQAiBAAEQIgSVNK+e0nLy4uls3NzSqL7O/vV5nbaZqm2uxSyszD27Yta2trfa7z4vj4uMrcTs1rmuSilPJl1sMrKyvl7Oysz31e1JrbqfV/DLu7u7m+vv7lTfOJABACQAiACAEQIQAiBECEAIgQABECIEIARAiACAEQIQAiBECEAIgQABECIEIARAiACAEQIQAiBECm/Dnzpmm+Jflab52/0udSyqdZD7umb3Jd+/fmNZ0qBMC/yVcDQAgAIQAiBECEAIgQABECIEIARAiAJD8Af8R5HAwU3/AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_weights = []\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "  if \"onv\" in layer.name:\n",
    "    all_weights.append\n",
    "    print(i, layer.name, model.layers[i].get_weights()[0].shape)\n",
    "\n",
    "weights, biases =  model.layers[1].get_weights()\n",
    "fig1=plt.figure(figsize=(12, 12))\n",
    "\n",
    "\n",
    "columns = 8 \n",
    "rows = 8 \n",
    "n_filters = columns*rows\n",
    "for i in range(1, n_filters +1):\n",
    "    f = weights[:, :, (i-1), 0]\n",
    "    fig1 =plt.subplot(rows, columns, i)\n",
    "    fig1.set_xticks([])  #Turn off axis\n",
    "    fig1.set_yticks([])\n",
    "\n",
    "    #plt.imshow(f[i%3, :, :], cmap='gray')\n",
    "    plt.imshow(f[:, :], cmap='gray')\n",
    "    #plt.imshow(f[2, :, :], cmap='gray') #Show only the filters from 0th channel (R)\n",
    "    #ix += 1\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
