{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b37971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jens\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have GPU access\n",
      "Fri Oct 21 13:16:33 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.72       Driver Version: 512.72       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   63C    P0    17W /  N/A |    168MiB /  4096MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     20972      C   ...nvs\\tensorflow\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     35044      C   ...nvs\\tensorflow\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "TensorFlow 2.6.0; Keras 2.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if tf.test.gpu_device_name()=='':\n",
    "    print('You do not have GPU access.')\n",
    "    !nvidia-smi\n",
    "\n",
    "else:\n",
    "  print('You have GPU access')\n",
    "  !nvidia-smi\n",
    "\n",
    "\n",
    "# print the tensorflow version\n",
    "print('TensorFlow {}; Keras {}'.format(tf.__version__, keras.__version__))\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac04cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uses 3.56 GB of memory at a batch size of 6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from preprocessing import get_model_memory_usage, unpatch_stack\n",
    "\n",
    "#load pretrained model\n",
    "\n",
    "model = load_model(\"models/bactunet_V4_3frame.hdf5\", compile=False)\n",
    "\n",
    "batch_size = 6\n",
    "print(\"Model uses {} GB of memory at a batch size of {}\".format(get_model_memory_usage(batch_size, model), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04714372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BactUnet_single_frame_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 288, 288) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 288, 288) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 288, 288) 1152        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 288, 288) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 288, 288) 36928       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 288, 288) 1152        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 288, 288) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 144, 144) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 144, 144 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 144, 144 576         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 144, 144 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 144, 144 147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 144, 144 576         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 144, 144 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 72, 72)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 72, 72)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 72, 72)  288         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 72, 72)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 72, 72)  590080      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 72, 72)  288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 72, 72)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 256, 36, 36)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 36, 36)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512, 36, 36)  144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512, 36, 36)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 36, 36)  2359808     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512, 36, 36)  144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512, 36, 36)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 512, 18, 18)  0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1024, 18, 18) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1024, 18, 18) 72          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024, 18, 18) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1024, 18, 18) 9438208     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1024, 18, 18) 72          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024, 18, 18) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 512, 36, 36)  2097664     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024, 36, 36) 0           conv2d_transpose[0][0]           \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 512, 36, 36)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 512, 36, 36)  144         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 512, 36, 36)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 512, 36, 36)  2359808     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 512, 36, 36)  144         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 512, 36, 36)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 72, 72)  524544      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512, 72, 72)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 72, 72)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256, 72, 72)  288         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256, 72, 72)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 72, 72)  590080      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256, 72, 72)  288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256, 72, 72)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 144, 144 131200      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 144, 144 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 144, 144 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 144, 144 576         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128, 144, 144 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 144, 144 147584      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 144, 144 576         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128, 144, 144 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 288, 288) 32832       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 288, 288 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 288, 288) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 288, 288) 1152        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64, 288, 288) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 288, 288) 36928       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 288, 288) 1152        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 64, 288, 288) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1, 288, 288)  65          dropout_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,040,529\n",
      "Trainable params: 31,036,137\n",
      "Non-trainable params: 4,392\n",
      "__________________________________________________________________________________________________\n",
      "conv2d/kernel:0 (3, 3, 3, 64)\n",
      "conv2d/bias:0 (64,)\n",
      "batch_normalization/gamma:0 (288,)\n",
      "batch_normalization/beta:0 (288,)\n",
      "batch_normalization/moving_mean:0 (288,)\n",
      "batch_normalization/moving_variance:0 (288,)\n",
      "conv2d_1/kernel:0 (3, 3, 64, 64)\n",
      "conv2d_1/bias:0 (64,)\n",
      "batch_normalization_1/gamma:0 (288,)\n",
      "batch_normalization_1/beta:0 (288,)\n",
      "batch_normalization_1/moving_mean:0 (288,)\n",
      "batch_normalization_1/moving_variance:0 (288,)\n",
      "conv2d_2/kernel:0 (3, 3, 64, 128)\n",
      "conv2d_2/bias:0 (128,)\n",
      "batch_normalization_2/gamma:0 (144,)\n",
      "batch_normalization_2/beta:0 (144,)\n",
      "batch_normalization_2/moving_mean:0 (144,)\n",
      "batch_normalization_2/moving_variance:0 (144,)\n",
      "conv2d_3/kernel:0 (3, 3, 128, 128)\n",
      "conv2d_3/bias:0 (128,)\n",
      "batch_normalization_3/gamma:0 (144,)\n",
      "batch_normalization_3/beta:0 (144,)\n",
      "batch_normalization_3/moving_mean:0 (144,)\n",
      "batch_normalization_3/moving_variance:0 (144,)\n",
      "conv2d_4/kernel:0 (3, 3, 128, 256)\n",
      "conv2d_4/bias:0 (256,)\n",
      "batch_normalization_4/gamma:0 (72,)\n",
      "batch_normalization_4/beta:0 (72,)\n",
      "batch_normalization_4/moving_mean:0 (72,)\n",
      "batch_normalization_4/moving_variance:0 (72,)\n",
      "conv2d_5/kernel:0 (3, 3, 256, 256)\n",
      "conv2d_5/bias:0 (256,)\n",
      "batch_normalization_5/gamma:0 (72,)\n",
      "batch_normalization_5/beta:0 (72,)\n",
      "batch_normalization_5/moving_mean:0 (72,)\n",
      "batch_normalization_5/moving_variance:0 (72,)\n",
      "conv2d_6/kernel:0 (3, 3, 256, 512)\n",
      "conv2d_6/bias:0 (512,)\n",
      "batch_normalization_6/gamma:0 (36,)\n",
      "batch_normalization_6/beta:0 (36,)\n",
      "batch_normalization_6/moving_mean:0 (36,)\n",
      "batch_normalization_6/moving_variance:0 (36,)\n",
      "conv2d_7/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_7/bias:0 (512,)\n",
      "batch_normalization_7/gamma:0 (36,)\n",
      "batch_normalization_7/beta:0 (36,)\n",
      "batch_normalization_7/moving_mean:0 (36,)\n",
      "batch_normalization_7/moving_variance:0 (36,)\n",
      "conv2d_8/kernel:0 (3, 3, 512, 1024)\n",
      "conv2d_8/bias:0 (1024,)\n",
      "batch_normalization_8/gamma:0 (18,)\n",
      "batch_normalization_8/beta:0 (18,)\n",
      "batch_normalization_8/moving_mean:0 (18,)\n",
      "batch_normalization_8/moving_variance:0 (18,)\n",
      "conv2d_9/kernel:0 (3, 3, 1024, 1024)\n",
      "conv2d_9/bias:0 (1024,)\n",
      "batch_normalization_9/gamma:0 (18,)\n",
      "batch_normalization_9/beta:0 (18,)\n",
      "batch_normalization_9/moving_mean:0 (18,)\n",
      "batch_normalization_9/moving_variance:0 (18,)\n",
      "conv2d_transpose/kernel:0 (2, 2, 512, 1024)\n",
      "conv2d_transpose/bias:0 (512,)\n",
      "conv2d_10/kernel:0 (3, 3, 1024, 512)\n",
      "conv2d_10/bias:0 (512,)\n",
      "batch_normalization_10/gamma:0 (36,)\n",
      "batch_normalization_10/beta:0 (36,)\n",
      "batch_normalization_10/moving_mean:0 (36,)\n",
      "batch_normalization_10/moving_variance:0 (36,)\n",
      "conv2d_11/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_11/bias:0 (512,)\n",
      "batch_normalization_11/gamma:0 (36,)\n",
      "batch_normalization_11/beta:0 (36,)\n",
      "batch_normalization_11/moving_mean:0 (36,)\n",
      "batch_normalization_11/moving_variance:0 (36,)\n",
      "conv2d_transpose_1/kernel:0 (2, 2, 256, 512)\n",
      "conv2d_transpose_1/bias:0 (256,)\n",
      "conv2d_12/kernel:0 (3, 3, 512, 256)\n",
      "conv2d_12/bias:0 (256,)\n",
      "batch_normalization_12/gamma:0 (72,)\n",
      "batch_normalization_12/beta:0 (72,)\n",
      "batch_normalization_12/moving_mean:0 (72,)\n",
      "batch_normalization_12/moving_variance:0 (72,)\n",
      "conv2d_13/kernel:0 (3, 3, 256, 256)\n",
      "conv2d_13/bias:0 (256,)\n",
      "batch_normalization_13/gamma:0 (72,)\n",
      "batch_normalization_13/beta:0 (72,)\n",
      "batch_normalization_13/moving_mean:0 (72,)\n",
      "batch_normalization_13/moving_variance:0 (72,)\n",
      "conv2d_transpose_2/kernel:0 (2, 2, 128, 256)\n",
      "conv2d_transpose_2/bias:0 (128,)\n",
      "conv2d_14/kernel:0 (3, 3, 256, 128)\n",
      "conv2d_14/bias:0 (128,)\n",
      "batch_normalization_14/gamma:0 (144,)\n",
      "batch_normalization_14/beta:0 (144,)\n",
      "batch_normalization_14/moving_mean:0 (144,)\n",
      "batch_normalization_14/moving_variance:0 (144,)\n",
      "conv2d_15/kernel:0 (3, 3, 128, 128)\n",
      "conv2d_15/bias:0 (128,)\n",
      "batch_normalization_15/gamma:0 (144,)\n",
      "batch_normalization_15/beta:0 (144,)\n",
      "batch_normalization_15/moving_mean:0 (144,)\n",
      "batch_normalization_15/moving_variance:0 (144,)\n",
      "conv2d_transpose_3/kernel:0 (2, 2, 64, 128)\n",
      "conv2d_transpose_3/bias:0 (64,)\n",
      "conv2d_16/kernel:0 (3, 3, 128, 64)\n",
      "conv2d_16/bias:0 (64,)\n",
      "batch_normalization_16/gamma:0 (288,)\n",
      "batch_normalization_16/beta:0 (288,)\n",
      "batch_normalization_16/moving_mean:0 (288,)\n",
      "batch_normalization_16/moving_variance:0 (288,)\n",
      "conv2d_17/kernel:0 (3, 3, 64, 64)\n",
      "conv2d_17/bias:0 (64,)\n",
      "batch_normalization_17/gamma:0 (288,)\n",
      "batch_normalization_17/beta:0 (288,)\n",
      "batch_normalization_17/moving_mean:0 (288,)\n",
      "batch_normalization_17/moving_variance:0 (288,)\n",
      "conv2d_18/kernel:0 (1, 1, 64, 1)\n",
      "conv2d_18/bias:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "for l in model.weights:\n",
    "    print(l.name, l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7566fae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0403_229.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT0403_229.tif (704, 3, 288, 288) (704, 1, 288, 288)\n",
      "BT0407_110.tif (7, 2304, 2304) (5, 2304, 2304)\n",
      "BT0407_110.tif (320, 3, 288, 288) (320, 1, 288, 288)\n",
      "BT0398_210.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT0398_210.tif (704, 3, 288, 288) (704, 1, 288, 288)\n",
      "BT402_169.tif (5, 2304, 2304) (3, 2304, 2304)\n",
      "BT402_169.tif (192, 3, 288, 288) (192, 1, 288, 288)\n",
      "BT403_002.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT403_002.tif (704, 3, 288, 288) (704, 1, 288, 288)\n",
      "BT404_199.tif (5, 2304, 2304) (3, 2304, 2304)\n",
      "BT404_199.tif (192, 3, 288, 288) (192, 1, 288, 288)\n",
      "dict_keys(['BT0403_229.tif', 'BT0407_110.tif', 'BT0398_210.tif', 'BT402_169.tif', 'BT403_002.tif', 'BT404_199.tif'])\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import patch_image, patch_stack, normalizePercentile, normalizeMinMax\n",
    "from patchify import patchify\n",
    "\n",
    "source_path = r\"Bactnet/Training data/stacks/\"\n",
    "SIZE = 288\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(source_path, PATCH_SIZE, validation=True):\n",
    "    pred_dict = {}\n",
    "    if validation:\n",
    "        prefix = \"validation\"\n",
    "    else:\n",
    "        prefix = \"training\"\n",
    "    stacks = os.listdir(os.path.join(source_path, prefix+\"_source\"))\n",
    "    image_dataset = None\n",
    "    mask_dataset = None\n",
    "    for stack in stacks:\n",
    "        if (stack.split(\".\")[-1]==\"tif\"):\n",
    "            pred_dict[stack]={}\n",
    "            img = tiff.imread(os.path.join(source_path, prefix+\"_source\",stack))\n",
    "            pred_dict[stack][\"image\"]=img\n",
    "            mask = tiff.imread(os.path.join(source_path, prefix+\"_target\", stack))\n",
    "            pred_dict[stack][\"y_true\"]=mask\n",
    "            print(stack, img.shape, mask.shape)\n",
    "            \n",
    "            img_patch = patch_stack(img, PATCH_SIZE)\n",
    "            if len(mask.shape)==2:\n",
    "                mask_patch = patch_image(mask, PATCH_SIZE)\n",
    "            else:    \n",
    "                mask_patch = patch_stack(mask, SIZE=PATCH_SIZE, DEPTH=1)\n",
    "            \n",
    "            print(stack, img_patch.shape, mask_patch.shape)\n",
    "            mask_patch = normalizeMinMax(mask_patch)\n",
    "            img_patch = normalizePercentile(img_patch, 0.1, 99.9, clip=True)\n",
    "            pred_dict[stack][\"image_patch\"] = img_patch\n",
    "            pred_dict[stack][\"mask_patch\"] = mask_patch\n",
    "\n",
    "\n",
    "            #print(image_dataset.shape, mask_dataset.shape)\n",
    "\n",
    "    return pred_dict\n",
    "\n",
    "#pred_dict[file]=[image_stack, mask, patch, y_true, y_pred]\n",
    "image_dict = prepare_data(source_path, SIZE, validation=True)\n",
    "image_dict.update(prepare_data(source_path, SIZE, validation=False))\n",
    "print(image_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed33048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0403_229.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT0407_110.tif (320, 1, 288, 288) (5, 1, 2304, 2304)\n",
      "BT0398_210.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT402_169.tif (192, 1, 288, 288) (3, 1, 2304, 2304)\n",
      "BT403_002.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT404_199.tif (192, 1, 288, 288) (3, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "stride = 2\n",
    "\n",
    "# #IOU\n",
    "for stack in image_dict.keys():\n",
    "    y_pred = None\n",
    "    img_stack = image_dict[stack]\n",
    "    for i in range(0, len(img_stack[\"image_patch\"]), stride):\n",
    "        pred = model.predict(img_stack[\"image_patch\"][i:i+stride])\n",
    "        if y_pred is not None:\n",
    "            y_pred = np.concatenate((y_pred, pred))\n",
    "\n",
    "        if y_pred is None:\n",
    "            y_pred = pred\n",
    "    \n",
    "    image_dict[stack][\"y_pred\"] = unpatch_stack(y_pred, 8, 8, 1)\n",
    "    print(stack, y_pred.shape, image_dict[stack][\"y_pred\"].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c8ddc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1, 2304, 2304) 1.0\n",
      "(5, 1, 2304, 2304) 1.0\n",
      "(11, 1, 2304, 2304) 1.0\n",
      "(3, 1, 2304, 2304) 1.0\n",
      "(11, 1, 2304, 2304) 1.0\n",
      "(3, 1, 2304, 2304) 1.0\n"
     ]
    }
   ],
   "source": [
    "for stack in image_dict.keys():\n",
    "    saveme = np.concatenate(((image_dict[stack][\"y_pred\"]>0.5)*255, np.expand_dims(image_dict[stack][\"y_true\"],axis=1)), axis=1)\n",
    "    saveme = saveme.astype('uint8')\n",
    "    prefix=\"V4_3frame\"\n",
    "    dic = unpatch_stack(image_dict[stack][\"image_patch\"], 8, 8, 3)\n",
    "    dic = dic[:,1,:,:] * 255\n",
    "    dic = np.expand_dims(dic, axis=1).astype('uint8')\n",
    "    print(dic.shape, image_dict[stack][\"image_patch\"].max())\n",
    "    saveme = np.concatenate((dic, saveme), axis=1)\n",
    "    tiff.imwrite(os.path.join(r\"C:\\Users\\Jens\\Documents\\Code\\BactUnet\\Bactnet\\Training data\\stacks\\predict\", prefix+stack), saveme, imagej=True,\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc652211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_tru = None\n",
    "y_pre = None\n",
    "\n",
    "for stack in image_dict.keys():\n",
    "    if y_tru is None:\n",
    "        y_tru = image_dict[stack][\"y_true\"]\n",
    "        y_pre = image_dict[stack][\"y_pred\"]\n",
    "    else:\n",
    "        y_tru = np.concatenate((y_tru, image_dict[stack][\"y_true\"]))\n",
    "        y_pre = np.concatenate((y_pre, image_dict[stack][\"y_pred\"]))\n",
    "        \n",
    "dices = []\n",
    "IOUs = []\n",
    "frames = []\n",
    "threshold = 0.5\n",
    "\n",
    "y_pred_thresholded = (y_pre > threshold) * 255\n",
    "y_pred_thresholded = y_pred_thresholded.astype('uint8')\n",
    "\n",
    "for i in range(len(y_tru)):\n",
    "    intersection = np.logical_and(y_tru[i], y_pred_thresholded[i])\n",
    "    union = np.logical_or(y_tru[i], y_pred_thresholded[i])\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    IOUs.append(iou_score)\n",
    "\n",
    "frames =  list(range(len(y_tru)))\n",
    "\n",
    "    \n",
    "#plt.plot(frames, dices)\n",
    "plt.plot(frames, IOUs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997b4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(mask1, mask2):\n",
    "    intersect = np.sum(mask1*mask2)\n",
    "    fsum = np.sum(mask1)\n",
    "    ssum = np.sum(mask2)\n",
    "    dice = (2 * intersect ) / (fsum + ssum)\n",
    "    dice = np.mean(dice)\n",
    "    dice = round(dice, 3) # for easy reading\n",
    "    return dice    \n",
    "\n",
    "def iou_score(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask1)\n",
    "    union = np.logical_or(mask1, mask2)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "\n",
    "for stack in image_dict.keys():\n",
    "    image_dict[stack]\n",
    "    image_dict[stack]['y_pred']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd59a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction frames: 0-2 of 891\n",
      "Prediction frames: 2-4 of 891\n",
      "Prediction frames: 4-6 of 891\n",
      "Prediction frames: 6-8 of 891\n",
      "Prediction frames: 8-10 of 891\n",
      "Prediction frames: 10-12 of 891\n",
      "Prediction frames: 12-14 of 891\n",
      "Prediction frames: 14-16 of 891\n",
      "Prediction frames: 16-18 of 891\n",
      "Prediction frames: 18-20 of 891\n",
      "Prediction frames: 20-22 of 891\n",
      "Prediction frames: 22-24 of 891\n",
      "Prediction frames: 24-26 of 891\n",
      "Prediction frames: 26-28 of 891\n",
      "Prediction frames: 28-30 of 891\n",
      "Prediction frames: 30-32 of 891\n",
      "Prediction frames: 32-34 of 891\n",
      "Prediction frames: 34-36 of 891\n",
      "Prediction frames: 36-38 of 891\n",
      "Prediction frames: 38-40 of 891\n",
      "Prediction frames: 40-42 of 891\n",
      "Prediction frames: 42-44 of 891\n",
      "Prediction frames: 44-46 of 891\n",
      "Prediction frames: 46-48 of 891\n",
      "Prediction frames: 48-50 of 891\n",
      "Prediction frames: 50-52 of 891\n",
      "Prediction frames: 52-54 of 891\n",
      "Prediction frames: 54-56 of 891\n",
      "Prediction frames: 56-58 of 891\n",
      "Prediction frames: 58-60 of 891\n",
      "Prediction frames: 60-62 of 891\n",
      "Prediction frames: 62-64 of 891\n",
      "Prediction frames: 64-66 of 891\n",
      "Prediction frames: 66-68 of 891\n",
      "Prediction frames: 68-70 of 891\n",
      "Prediction frames: 70-72 of 891\n",
      "Prediction frames: 72-74 of 891\n",
      "Prediction frames: 74-76 of 891\n",
      "Prediction frames: 76-78 of 891\n",
      "Prediction frames: 78-80 of 891\n",
      "Prediction frames: 80-82 of 891\n",
      "Prediction frames: 82-84 of 891\n",
      "Prediction frames: 84-86 of 891\n",
      "Prediction frames: 86-88 of 891\n",
      "Prediction frames: 88-90 of 891\n",
      "Prediction frames: 90-92 of 891\n",
      "Prediction frames: 92-94 of 891\n",
      "Prediction frames: 94-96 of 891\n",
      "Prediction frames: 96-98 of 891\n",
      "Prediction frames: 98-100 of 891\n",
      "Prediction frames: 100-102 of 891\n",
      "Prediction frames: 102-104 of 891\n",
      "Prediction frames: 104-106 of 891\n",
      "Prediction frames: 106-108 of 891\n",
      "Prediction frames: 108-110 of 891\n",
      "Prediction frames: 110-112 of 891\n",
      "Prediction frames: 112-114 of 891\n",
      "Prediction frames: 114-116 of 891\n",
      "Prediction frames: 116-118 of 891\n",
      "Prediction frames: 118-120 of 891\n",
      "Prediction frames: 120-122 of 891\n",
      "Prediction frames: 122-124 of 891\n",
      "Prediction frames: 124-126 of 891\n",
      "Prediction frames: 126-128 of 891\n",
      "Prediction frames: 128-130 of 891\n",
      "Prediction frames: 130-132 of 891\n",
      "Prediction frames: 132-134 of 891\n",
      "Prediction frames: 134-136 of 891\n",
      "Prediction frames: 136-138 of 891\n",
      "Prediction frames: 138-140 of 891\n",
      "Prediction frames: 140-142 of 891\n",
      "Prediction frames: 142-144 of 891\n",
      "Prediction frames: 144-146 of 891\n",
      "Prediction frames: 146-148 of 891\n",
      "Prediction frames: 148-150 of 891\n",
      "Prediction frames: 150-152 of 891\n",
      "Prediction frames: 152-154 of 891\n",
      "Prediction frames: 154-156 of 891\n",
      "Prediction frames: 156-158 of 891\n",
      "Prediction frames: 158-160 of 891\n",
      "Prediction frames: 160-162 of 891\n",
      "Prediction frames: 162-164 of 891\n",
      "Prediction frames: 164-166 of 891\n",
      "Prediction frames: 166-168 of 891\n",
      "Prediction frames: 168-170 of 891\n",
      "Prediction frames: 170-172 of 891\n",
      "Prediction frames: 172-174 of 891\n",
      "Prediction frames: 174-176 of 891\n",
      "Prediction frames: 176-178 of 891\n",
      "Prediction frames: 178-180 of 891\n",
      "Prediction frames: 180-182 of 891\n",
      "Prediction frames: 182-184 of 891\n",
      "Prediction frames: 184-186 of 891\n",
      "Prediction frames: 186-188 of 891\n",
      "Prediction frames: 188-190 of 891\n",
      "Prediction frames: 190-192 of 891\n",
      "Prediction frames: 192-194 of 891\n",
      "Prediction frames: 194-196 of 891\n",
      "Prediction frames: 196-198 of 891\n",
      "Prediction frames: 198-200 of 891\n",
      "Prediction frames: 200-202 of 891\n",
      "Prediction frames: 202-204 of 891\n",
      "Prediction frames: 204-206 of 891\n",
      "Prediction frames: 206-208 of 891\n",
      "Prediction frames: 208-210 of 891\n",
      "Prediction frames: 210-212 of 891\n",
      "Prediction frames: 212-214 of 891\n",
      "Prediction frames: 214-216 of 891\n",
      "Prediction frames: 216-218 of 891\n",
      "Prediction frames: 218-220 of 891\n",
      "Prediction frames: 220-222 of 891\n",
      "Prediction frames: 222-224 of 891\n",
      "Prediction frames: 224-226 of 891\n",
      "Prediction frames: 226-228 of 891\n",
      "Prediction frames: 228-230 of 891\n",
      "Prediction frames: 230-232 of 891\n",
      "Prediction frames: 232-234 of 891\n",
      "Prediction frames: 234-236 of 891\n",
      "Prediction frames: 236-238 of 891\n",
      "Prediction frames: 238-240 of 891\n",
      "Prediction frames: 240-242 of 891\n",
      "Prediction frames: 242-244 of 891\n",
      "Prediction frames: 244-246 of 891\n",
      "Prediction frames: 246-248 of 891\n",
      "Prediction frames: 248-250 of 891\n",
      "Prediction frames: 250-252 of 891\n",
      "Prediction frames: 252-254 of 891\n",
      "Prediction frames: 254-256 of 891\n",
      "Prediction frames: 256-258 of 891\n",
      "Prediction frames: 258-260 of 891\n",
      "Prediction frames: 260-262 of 891\n",
      "Prediction frames: 262-264 of 891\n",
      "Prediction frames: 264-266 of 891\n",
      "Prediction frames: 266-268 of 891\n",
      "Prediction frames: 268-270 of 891\n",
      "Prediction frames: 270-272 of 891\n",
      "Prediction frames: 272-274 of 891\n",
      "Prediction frames: 274-276 of 891\n",
      "Prediction frames: 276-278 of 891\n",
      "Prediction frames: 278-280 of 891\n",
      "Prediction frames: 280-282 of 891\n",
      "Prediction frames: 282-284 of 891\n",
      "Prediction frames: 284-286 of 891\n",
      "Prediction frames: 286-288 of 891\n",
      "Prediction frames: 288-290 of 891\n",
      "Prediction frames: 290-292 of 891\n",
      "Prediction frames: 292-294 of 891\n",
      "Prediction frames: 294-296 of 891\n",
      "Prediction frames: 296-298 of 891\n",
      "Prediction frames: 298-300 of 891\n",
      "Prediction frames: 300-302 of 891\n",
      "Prediction frames: 302-304 of 891\n",
      "Prediction frames: 304-306 of 891\n",
      "Prediction frames: 306-308 of 891\n",
      "Prediction frames: 308-310 of 891\n",
      "Prediction frames: 310-312 of 891\n",
      "Prediction frames: 312-314 of 891\n",
      "Prediction frames: 314-316 of 891\n",
      "Prediction frames: 316-318 of 891\n",
      "Prediction frames: 318-320 of 891\n",
      "Prediction frames: 320-322 of 891\n",
      "Prediction frames: 322-324 of 891\n",
      "Prediction frames: 324-326 of 891\n",
      "Prediction frames: 326-328 of 891\n",
      "Prediction frames: 328-330 of 891\n",
      "Prediction frames: 330-332 of 891\n",
      "Prediction frames: 332-334 of 891\n",
      "Prediction frames: 334-336 of 891\n",
      "Prediction frames: 336-338 of 891\n",
      "Prediction frames: 338-340 of 891\n",
      "Prediction frames: 340-342 of 891\n",
      "Prediction frames: 342-344 of 891\n",
      "Prediction frames: 344-346 of 891\n",
      "Prediction frames: 346-348 of 891\n",
      "Prediction frames: 348-350 of 891\n",
      "Prediction frames: 350-352 of 891\n",
      "Prediction frames: 352-354 of 891\n",
      "Prediction frames: 354-356 of 891\n",
      "Prediction frames: 356-358 of 891\n",
      "Prediction frames: 358-360 of 891\n",
      "Prediction frames: 360-362 of 891\n",
      "Prediction frames: 362-364 of 891\n",
      "Prediction frames: 364-366 of 891\n",
      "Prediction frames: 366-368 of 891\n",
      "Prediction frames: 368-370 of 891\n",
      "Prediction frames: 370-372 of 891\n",
      "Prediction frames: 372-374 of 891\n",
      "Prediction frames: 374-376 of 891\n",
      "Prediction frames: 376-378 of 891\n",
      "Prediction frames: 378-380 of 891\n",
      "Prediction frames: 380-382 of 891\n",
      "Prediction frames: 382-384 of 891\n",
      "Prediction frames: 384-386 of 891\n",
      "Prediction frames: 386-388 of 891\n",
      "Prediction frames: 388-390 of 891\n",
      "Prediction frames: 390-392 of 891\n",
      "Prediction frames: 392-394 of 891\n",
      "Prediction frames: 394-396 of 891\n",
      "Prediction frames: 396-398 of 891\n",
      "Prediction frames: 398-400 of 891\n",
      "Prediction frames: 400-402 of 891\n",
      "Prediction frames: 402-404 of 891\n",
      "Prediction frames: 404-406 of 891\n",
      "Prediction frames: 406-408 of 891\n",
      "Prediction frames: 408-410 of 891\n",
      "Prediction frames: 410-412 of 891\n",
      "Prediction frames: 412-414 of 891\n",
      "Prediction frames: 414-416 of 891\n",
      "Prediction frames: 416-418 of 891\n",
      "Prediction frames: 418-420 of 891\n",
      "Prediction frames: 420-422 of 891\n",
      "Prediction frames: 422-424 of 891\n",
      "Prediction frames: 424-426 of 891\n",
      "Prediction frames: 426-428 of 891\n",
      "Prediction frames: 428-430 of 891\n",
      "Prediction frames: 430-432 of 891\n",
      "Prediction frames: 432-434 of 891\n",
      "Prediction frames: 434-436 of 891\n",
      "Prediction frames: 436-438 of 891\n",
      "Prediction frames: 438-440 of 891\n",
      "Prediction frames: 440-442 of 891\n",
      "Prediction frames: 442-444 of 891\n",
      "Prediction frames: 444-446 of 891\n",
      "Prediction frames: 446-448 of 891\n",
      "Prediction frames: 448-450 of 891\n",
      "Prediction frames: 450-452 of 891\n",
      "Prediction frames: 452-454 of 891\n",
      "Prediction frames: 454-456 of 891\n",
      "Prediction frames: 456-458 of 891\n",
      "Prediction frames: 458-460 of 891\n",
      "Prediction frames: 460-462 of 891\n",
      "Prediction frames: 462-464 of 891\n",
      "Prediction frames: 464-466 of 891\n",
      "Prediction frames: 466-468 of 891\n",
      "Prediction frames: 468-470 of 891\n",
      "Prediction frames: 470-472 of 891\n",
      "Prediction frames: 472-474 of 891\n",
      "Prediction frames: 474-476 of 891\n",
      "Prediction frames: 476-478 of 891\n",
      "Prediction frames: 478-480 of 891\n",
      "Prediction frames: 480-482 of 891\n",
      "Prediction frames: 482-484 of 891\n",
      "Prediction frames: 484-486 of 891\n",
      "Prediction frames: 486-488 of 891\n",
      "Prediction frames: 488-490 of 891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction frames: 490-492 of 891\n",
      "Prediction frames: 492-494 of 891\n",
      "Prediction frames: 494-496 of 891\n",
      "Prediction frames: 496-498 of 891\n",
      "Prediction frames: 498-500 of 891\n",
      "Prediction frames: 500-502 of 891\n",
      "Prediction frames: 502-504 of 891\n",
      "Prediction frames: 504-506 of 891\n",
      "Prediction frames: 506-508 of 891\n",
      "Prediction frames: 508-510 of 891\n",
      "Prediction frames: 510-512 of 891\n",
      "Prediction frames: 512-514 of 891\n",
      "Prediction frames: 514-516 of 891\n",
      "Prediction frames: 516-518 of 891\n",
      "Prediction frames: 518-520 of 891\n",
      "Prediction frames: 520-522 of 891\n",
      "Prediction frames: 522-524 of 891\n",
      "Prediction frames: 524-526 of 891\n",
      "Prediction frames: 526-528 of 891\n",
      "Prediction frames: 528-530 of 891\n",
      "Prediction frames: 530-532 of 891\n",
      "Prediction frames: 532-534 of 891\n",
      "Prediction frames: 534-536 of 891\n",
      "Prediction frames: 536-538 of 891\n",
      "Prediction frames: 538-540 of 891\n",
      "Prediction frames: 540-542 of 891\n",
      "Prediction frames: 542-544 of 891\n",
      "Prediction frames: 544-546 of 891\n",
      "Prediction frames: 546-548 of 891\n",
      "Prediction frames: 548-550 of 891\n",
      "Prediction frames: 550-552 of 891\n",
      "Prediction frames: 552-554 of 891\n",
      "Prediction frames: 554-556 of 891\n",
      "Prediction frames: 556-558 of 891\n",
      "Prediction frames: 558-560 of 891\n",
      "Prediction frames: 560-562 of 891\n",
      "Prediction frames: 562-564 of 891\n",
      "Prediction frames: 564-566 of 891\n",
      "Prediction frames: 566-568 of 891\n",
      "Prediction frames: 568-570 of 891\n",
      "Prediction frames: 570-572 of 891\n",
      "Prediction frames: 572-574 of 891\n",
      "Prediction frames: 574-576 of 891\n",
      "Prediction frames: 576-578 of 891\n",
      "Prediction frames: 578-580 of 891\n",
      "Prediction frames: 580-582 of 891\n",
      "Prediction frames: 582-584 of 891\n",
      "Prediction frames: 584-586 of 891\n",
      "Prediction frames: 586-588 of 891\n",
      "Prediction frames: 588-590 of 891\n",
      "Prediction frames: 590-592 of 891\n",
      "Prediction frames: 592-594 of 891\n",
      "Prediction frames: 594-596 of 891\n",
      "Prediction frames: 596-598 of 891\n",
      "Prediction frames: 598-600 of 891\n",
      "Prediction frames: 600-602 of 891\n",
      "Prediction frames: 602-604 of 891\n",
      "Prediction frames: 604-606 of 891\n",
      "Prediction frames: 606-608 of 891\n",
      "Prediction frames: 608-610 of 891\n",
      "Prediction frames: 610-612 of 891\n",
      "Prediction frames: 612-614 of 891\n",
      "Prediction frames: 614-616 of 891\n",
      "Prediction frames: 616-618 of 891\n",
      "Prediction frames: 618-620 of 891\n",
      "Prediction frames: 620-622 of 891\n",
      "Prediction frames: 622-624 of 891\n",
      "Prediction frames: 624-626 of 891\n",
      "Prediction frames: 626-628 of 891\n",
      "Prediction frames: 628-630 of 891\n",
      "Prediction frames: 630-632 of 891\n",
      "Prediction frames: 632-634 of 891\n",
      "Prediction frames: 634-636 of 891\n",
      "Prediction frames: 636-638 of 891\n",
      "Prediction frames: 638-640 of 891\n",
      "Prediction frames: 640-642 of 891\n",
      "Prediction frames: 642-644 of 891\n",
      "Prediction frames: 644-646 of 891\n",
      "Prediction frames: 646-648 of 891\n",
      "Prediction frames: 648-650 of 891\n",
      "Prediction frames: 650-652 of 891\n",
      "Prediction frames: 652-654 of 891\n",
      "Prediction frames: 654-656 of 891\n",
      "Prediction frames: 656-658 of 891\n",
      "Prediction frames: 658-660 of 891\n",
      "Prediction frames: 660-662 of 891\n",
      "Prediction frames: 662-664 of 891\n",
      "Prediction frames: 664-666 of 891\n",
      "Prediction frames: 666-668 of 891\n",
      "Prediction frames: 668-670 of 891\n",
      "Prediction frames: 670-672 of 891\n",
      "Prediction frames: 672-674 of 891\n",
      "Prediction frames: 674-676 of 891\n",
      "Prediction frames: 676-678 of 891\n",
      "Prediction frames: 678-680 of 891\n",
      "Prediction frames: 680-682 of 891\n",
      "Prediction frames: 682-684 of 891\n",
      "Prediction frames: 684-686 of 891\n",
      "Prediction frames: 686-688 of 891\n",
      "Prediction frames: 688-690 of 891\n",
      "Prediction frames: 690-692 of 891\n",
      "Prediction frames: 692-694 of 891\n",
      "Prediction frames: 694-696 of 891\n",
      "Prediction frames: 696-698 of 891\n",
      "Prediction frames: 698-700 of 891\n",
      "Prediction frames: 700-702 of 891\n",
      "Prediction frames: 702-704 of 891\n",
      "Prediction frames: 704-706 of 891\n",
      "Prediction frames: 706-708 of 891\n",
      "Prediction frames: 708-710 of 891\n",
      "Prediction frames: 710-712 of 891\n",
      "Prediction frames: 712-714 of 891\n",
      "Prediction frames: 714-716 of 891\n",
      "Prediction frames: 716-718 of 891\n",
      "Prediction frames: 718-720 of 891\n",
      "Prediction frames: 720-722 of 891\n",
      "Prediction frames: 722-724 of 891\n",
      "Prediction frames: 724-726 of 891\n",
      "Prediction frames: 726-728 of 891\n",
      "Prediction frames: 728-730 of 891\n",
      "Prediction frames: 730-732 of 891\n",
      "Prediction frames: 732-734 of 891\n",
      "Prediction frames: 734-736 of 891\n",
      "Prediction frames: 736-738 of 891\n",
      "Prediction frames: 738-740 of 891\n",
      "Prediction frames: 740-742 of 891\n",
      "Prediction frames: 742-744 of 891\n",
      "Prediction frames: 744-746 of 891\n",
      "Prediction frames: 746-748 of 891\n",
      "Prediction frames: 748-750 of 891\n",
      "Prediction frames: 750-752 of 891\n",
      "Prediction frames: 752-754 of 891\n",
      "Prediction frames: 754-756 of 891\n",
      "Prediction frames: 756-758 of 891\n",
      "Prediction frames: 758-760 of 891\n",
      "Prediction frames: 760-762 of 891\n",
      "Prediction frames: 762-764 of 891\n",
      "Prediction frames: 764-766 of 891\n",
      "Prediction frames: 766-768 of 891\n",
      "Prediction frames: 768-770 of 891\n",
      "Prediction frames: 770-772 of 891\n",
      "Prediction frames: 772-774 of 891\n",
      "Prediction frames: 774-776 of 891\n",
      "Prediction frames: 776-778 of 891\n",
      "Prediction frames: 778-780 of 891\n",
      "Prediction frames: 780-782 of 891\n",
      "Prediction frames: 782-784 of 891\n",
      "Prediction frames: 784-786 of 891\n",
      "Prediction frames: 786-788 of 891\n",
      "Prediction frames: 788-790 of 891\n",
      "Prediction frames: 790-792 of 891\n",
      "Prediction frames: 792-794 of 891\n",
      "Prediction frames: 794-796 of 891\n",
      "Prediction frames: 796-798 of 891\n",
      "Prediction frames: 798-800 of 891\n",
      "Prediction frames: 800-802 of 891\n",
      "Prediction frames: 802-804 of 891\n",
      "Prediction frames: 804-806 of 891\n",
      "Prediction frames: 806-808 of 891\n",
      "Prediction frames: 808-810 of 891\n",
      "Prediction frames: 810-812 of 891\n",
      "Prediction frames: 812-814 of 891\n",
      "Prediction frames: 814-816 of 891\n",
      "Prediction frames: 816-818 of 891\n",
      "Prediction frames: 818-820 of 891\n",
      "Prediction frames: 820-822 of 891\n",
      "Prediction frames: 822-824 of 891\n",
      "Prediction frames: 824-826 of 891\n",
      "Prediction frames: 826-828 of 891\n",
      "Prediction frames: 828-830 of 891\n",
      "Prediction frames: 830-832 of 891\n",
      "Prediction frames: 832-834 of 891\n",
      "Prediction frames: 834-836 of 891\n",
      "Prediction frames: 836-838 of 891\n",
      "Prediction frames: 838-840 of 891\n",
      "Prediction frames: 840-842 of 891\n",
      "Prediction frames: 842-844 of 891\n",
      "Prediction frames: 844-846 of 891\n",
      "Prediction frames: 846-848 of 891\n",
      "Prediction frames: 848-850 of 891\n",
      "Prediction frames: 850-852 of 891\n",
      "Prediction frames: 852-854 of 891\n",
      "Prediction frames: 854-856 of 891\n",
      "Prediction frames: 856-858 of 891\n",
      "Prediction frames: 858-860 of 891\n",
      "Prediction frames: 860-862 of 891\n",
      "Prediction frames: 862-864 of 891\n",
      "Prediction frames: 864-866 of 891\n",
      "Prediction frames: 866-868 of 891\n",
      "Prediction frames: 868-870 of 891\n",
      "Prediction frames: 870-872 of 891\n",
      "Prediction frames: 872-874 of 891\n",
      "Prediction frames: 874-876 of 891\n",
      "Prediction frames: 876-878 of 891\n",
      "Prediction frames: 878-880 of 891\n",
      "Prediction frames: 880-882 of 891\n",
      "Prediction frames: 882-884 of 891\n",
      "Prediction frames: 884-886 of 891\n",
      "Prediction frames: 886-888 of 891\n",
      "Prediction frames: 888-890 of 891\n",
      "Prediction frames: 890-892 of 891\n",
      "BT0403_229.tif (13, 2592, 2592) (11, 1, 2304, 2304) (11, 1, 2304, 2304)\n",
      "Prediction frames: 0-2 of 405\n",
      "Prediction frames: 2-4 of 405\n",
      "Prediction frames: 4-6 of 405\n",
      "Prediction frames: 6-8 of 405\n",
      "Prediction frames: 8-10 of 405\n",
      "Prediction frames: 10-12 of 405\n",
      "Prediction frames: 12-14 of 405\n",
      "Prediction frames: 14-16 of 405\n",
      "Prediction frames: 16-18 of 405\n",
      "Prediction frames: 18-20 of 405\n",
      "Prediction frames: 20-22 of 405\n",
      "Prediction frames: 22-24 of 405\n",
      "Prediction frames: 24-26 of 405\n",
      "Prediction frames: 26-28 of 405\n",
      "Prediction frames: 28-30 of 405\n",
      "Prediction frames: 30-32 of 405\n",
      "Prediction frames: 32-34 of 405\n",
      "Prediction frames: 34-36 of 405\n",
      "Prediction frames: 36-38 of 405\n",
      "Prediction frames: 38-40 of 405\n",
      "Prediction frames: 40-42 of 405\n",
      "Prediction frames: 42-44 of 405\n",
      "Prediction frames: 44-46 of 405\n",
      "Prediction frames: 46-48 of 405\n",
      "Prediction frames: 48-50 of 405\n",
      "Prediction frames: 50-52 of 405\n",
      "Prediction frames: 52-54 of 405\n",
      "Prediction frames: 54-56 of 405\n",
      "Prediction frames: 56-58 of 405\n",
      "Prediction frames: 58-60 of 405\n",
      "Prediction frames: 60-62 of 405\n",
      "Prediction frames: 62-64 of 405\n",
      "Prediction frames: 64-66 of 405\n",
      "Prediction frames: 66-68 of 405\n",
      "Prediction frames: 68-70 of 405\n",
      "Prediction frames: 70-72 of 405\n",
      "Prediction frames: 72-74 of 405\n",
      "Prediction frames: 74-76 of 405\n",
      "Prediction frames: 76-78 of 405\n",
      "Prediction frames: 78-80 of 405\n",
      "Prediction frames: 80-82 of 405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction frames: 82-84 of 405\n",
      "Prediction frames: 84-86 of 405\n",
      "Prediction frames: 86-88 of 405\n",
      "Prediction frames: 88-90 of 405\n",
      "Prediction frames: 90-92 of 405\n",
      "Prediction frames: 92-94 of 405\n",
      "Prediction frames: 94-96 of 405\n",
      "Prediction frames: 96-98 of 405\n",
      "Prediction frames: 98-100 of 405\n",
      "Prediction frames: 100-102 of 405\n",
      "Prediction frames: 102-104 of 405\n",
      "Prediction frames: 104-106 of 405\n",
      "Prediction frames: 106-108 of 405\n",
      "Prediction frames: 108-110 of 405\n",
      "Prediction frames: 110-112 of 405\n",
      "Prediction frames: 112-114 of 405\n",
      "Prediction frames: 114-116 of 405\n",
      "Prediction frames: 116-118 of 405\n",
      "Prediction frames: 118-120 of 405\n",
      "Prediction frames: 120-122 of 405\n",
      "Prediction frames: 122-124 of 405\n",
      "Prediction frames: 124-126 of 405\n",
      "Prediction frames: 126-128 of 405\n",
      "Prediction frames: 128-130 of 405\n",
      "Prediction frames: 130-132 of 405\n",
      "Prediction frames: 132-134 of 405\n",
      "Prediction frames: 134-136 of 405\n",
      "Prediction frames: 136-138 of 405\n",
      "Prediction frames: 138-140 of 405\n",
      "Prediction frames: 140-142 of 405\n",
      "Prediction frames: 142-144 of 405\n",
      "Prediction frames: 144-146 of 405\n",
      "Prediction frames: 146-148 of 405\n",
      "Prediction frames: 148-150 of 405\n",
      "Prediction frames: 150-152 of 405\n",
      "Prediction frames: 152-154 of 405\n",
      "Prediction frames: 154-156 of 405\n",
      "Prediction frames: 156-158 of 405\n",
      "Prediction frames: 158-160 of 405\n",
      "Prediction frames: 160-162 of 405\n",
      "Prediction frames: 162-164 of 405\n",
      "Prediction frames: 164-166 of 405\n",
      "Prediction frames: 166-168 of 405\n",
      "Prediction frames: 168-170 of 405\n",
      "Prediction frames: 170-172 of 405\n",
      "Prediction frames: 172-174 of 405\n",
      "Prediction frames: 174-176 of 405\n",
      "Prediction frames: 176-178 of 405\n",
      "Prediction frames: 178-180 of 405\n",
      "Prediction frames: 180-182 of 405\n",
      "Prediction frames: 182-184 of 405\n",
      "Prediction frames: 184-186 of 405\n",
      "Prediction frames: 186-188 of 405\n",
      "Prediction frames: 188-190 of 405\n",
      "Prediction frames: 190-192 of 405\n",
      "Prediction frames: 192-194 of 405\n",
      "Prediction frames: 194-196 of 405\n",
      "Prediction frames: 196-198 of 405\n",
      "Prediction frames: 198-200 of 405\n",
      "Prediction frames: 200-202 of 405\n",
      "Prediction frames: 202-204 of 405\n",
      "Prediction frames: 204-206 of 405\n",
      "Prediction frames: 206-208 of 405\n",
      "Prediction frames: 208-210 of 405\n",
      "Prediction frames: 210-212 of 405\n",
      "Prediction frames: 212-214 of 405\n",
      "Prediction frames: 214-216 of 405\n",
      "Prediction frames: 216-218 of 405\n",
      "Prediction frames: 218-220 of 405\n",
      "Prediction frames: 220-222 of 405\n",
      "Prediction frames: 222-224 of 405\n",
      "Prediction frames: 224-226 of 405\n",
      "Prediction frames: 226-228 of 405\n",
      "Prediction frames: 228-230 of 405\n",
      "Prediction frames: 230-232 of 405\n",
      "Prediction frames: 232-234 of 405\n",
      "Prediction frames: 234-236 of 405\n",
      "Prediction frames: 236-238 of 405\n",
      "Prediction frames: 238-240 of 405\n",
      "Prediction frames: 240-242 of 405\n",
      "Prediction frames: 242-244 of 405\n",
      "Prediction frames: 244-246 of 405\n",
      "Prediction frames: 246-248 of 405\n",
      "Prediction frames: 248-250 of 405\n",
      "Prediction frames: 250-252 of 405\n",
      "Prediction frames: 252-254 of 405\n",
      "Prediction frames: 254-256 of 405\n",
      "Prediction frames: 256-258 of 405\n",
      "Prediction frames: 258-260 of 405\n",
      "Prediction frames: 260-262 of 405\n",
      "Prediction frames: 262-264 of 405\n",
      "Prediction frames: 264-266 of 405\n",
      "Prediction frames: 266-268 of 405\n",
      "Prediction frames: 268-270 of 405\n",
      "Prediction frames: 270-272 of 405\n",
      "Prediction frames: 272-274 of 405\n",
      "Prediction frames: 274-276 of 405\n",
      "Prediction frames: 276-278 of 405\n",
      "Prediction frames: 278-280 of 405\n",
      "Prediction frames: 280-282 of 405\n",
      "Prediction frames: 282-284 of 405\n",
      "Prediction frames: 284-286 of 405\n",
      "Prediction frames: 286-288 of 405\n",
      "Prediction frames: 288-290 of 405\n",
      "Prediction frames: 290-292 of 405\n",
      "Prediction frames: 292-294 of 405\n",
      "Prediction frames: 294-296 of 405\n",
      "Prediction frames: 296-298 of 405\n",
      "Prediction frames: 298-300 of 405\n",
      "Prediction frames: 300-302 of 405\n",
      "Prediction frames: 302-304 of 405\n",
      "Prediction frames: 304-306 of 405\n",
      "Prediction frames: 306-308 of 405\n",
      "Prediction frames: 308-310 of 405\n",
      "Prediction frames: 310-312 of 405\n",
      "Prediction frames: 312-314 of 405\n",
      "Prediction frames: 314-316 of 405\n",
      "Prediction frames: 316-318 of 405\n",
      "Prediction frames: 318-320 of 405\n",
      "Prediction frames: 320-322 of 405\n",
      "Prediction frames: 322-324 of 405\n",
      "Prediction frames: 324-326 of 405\n",
      "Prediction frames: 326-328 of 405\n",
      "Prediction frames: 328-330 of 405\n",
      "Prediction frames: 330-332 of 405\n",
      "Prediction frames: 332-334 of 405\n",
      "Prediction frames: 334-336 of 405\n",
      "Prediction frames: 336-338 of 405\n",
      "Prediction frames: 338-340 of 405\n",
      "Prediction frames: 340-342 of 405\n",
      "Prediction frames: 342-344 of 405\n",
      "Prediction frames: 344-346 of 405\n",
      "Prediction frames: 346-348 of 405\n",
      "Prediction frames: 348-350 of 405\n",
      "Prediction frames: 350-352 of 405\n",
      "Prediction frames: 352-354 of 405\n",
      "Prediction frames: 354-356 of 405\n",
      "Prediction frames: 356-358 of 405\n",
      "Prediction frames: 358-360 of 405\n",
      "Prediction frames: 360-362 of 405\n",
      "Prediction frames: 362-364 of 405\n",
      "Prediction frames: 364-366 of 405\n",
      "Prediction frames: 366-368 of 405\n",
      "Prediction frames: 368-370 of 405\n",
      "Prediction frames: 370-372 of 405\n",
      "Prediction frames: 372-374 of 405\n",
      "Prediction frames: 374-376 of 405\n",
      "Prediction frames: 376-378 of 405\n",
      "Prediction frames: 378-380 of 405\n",
      "Prediction frames: 380-382 of 405\n",
      "Prediction frames: 382-384 of 405\n",
      "Prediction frames: 384-386 of 405\n",
      "Prediction frames: 386-388 of 405\n",
      "Prediction frames: 388-390 of 405\n",
      "Prediction frames: 390-392 of 405\n",
      "Prediction frames: 392-394 of 405\n",
      "Prediction frames: 394-396 of 405\n",
      "Prediction frames: 396-398 of 405\n",
      "Prediction frames: 398-400 of 405\n",
      "Prediction frames: 400-402 of 405\n",
      "Prediction frames: 402-404 of 405\n",
      "Prediction frames: 404-406 of 405\n",
      "BT0407_110.tif (7, 2592, 2592) (5, 1, 2304, 2304) (16, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import pad_stack, crop_stack, predict_stack\n",
    "\n",
    "\n",
    "def crop_stack(arr, SIZE):\n",
    "    \"\"\"\n",
    "    Undoes the padding from pad_stack, crops out the center, removing a 1/2 SIZE broder from around the stack\n",
    "    \"\"\"\n",
    "    pad_SIZE = int(SIZE / 2)\n",
    "\n",
    "    if len(arr.shape) == 3:\n",
    "        t, y, x = arr.shape\n",
    "        stopY = y - pad_SIZE\n",
    "        stopX = x - pad_SIZE\n",
    "        return arr[:, pad_SIZE:stopY, pad_SIZE:stopX]\n",
    "\n",
    "    if len(arr.shape) == 4:\n",
    "        t, c, y, x = arr.shape\n",
    "        stopY = y - pad_SIZE\n",
    "        stopX = x - pad_SIZE\n",
    "        return arr[:, :, pad_SIZE:stopY, pad_SIZE:stopX]\n",
    "\n",
    "#Lets enlarge and see if patch edge regions are affecting the results\n",
    "\n",
    "source_path = r\"Bactnet/Training data/stacks/validation_source\"\n",
    "stacks = os.listdir(os.path.join(source_path))\n",
    "        \n",
    "\n",
    "ypred_2 = None\n",
    "    \n",
    "for i, image_name in enumerate(stacks):  # Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = tiff.imread(os.path.join(source_path, image_name))\n",
    "        image = normalizePercentile(image, 0.1, 99.9, clip=True)\n",
    "        expanded_image = pad_stack(image, SIZE)\n",
    "        expanded_patch = patch_stack(expanded_image, SIZE)\n",
    "        pred = predict_stack(expanded_patch, 2, model)\n",
    "        pred = unpatch_stack(pred, 9, 9, 1)\n",
    "        pred = crop_stack(pred, SIZE)\n",
    "        if ypred_2 is None:\n",
    "            ypred_2 = pred \n",
    "        else:\n",
    "            ypred_2 = np.concatenate((ypred_2, pred))\n",
    "\n",
    "        print(image_name, expanded_image.shape, pred.shape, ypred_2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cce9eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 2304, 2304) (44, 1, 2304, 2304) (16, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "print(y_tru.shape, y_pre.shape, ypred_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "236917c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of each dataset\n",
    "l_BT0398_210 = 11\n",
    "l_BT402_168 = 3\n",
    "l_BT403_000 = 11\n",
    "l_BT403_228 = 11\n",
    "l_BT404_199 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0aa3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dataset = unpatch_stack(image_dataset[:,1,:,:], 8, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb3228e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 1, 2304, 2304) (37, 1, 2304, 2304) (37, 1, 2304, 2304)\n",
      "(37, 4, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset.shape, y_pre.shape, y_tru.shape)\n",
    "saveme = np.concatenate((image_dataset, y_tru, y_pre, ypred_2), axis=1)\n",
    "saveme = saveme * 65535\n",
    "saveme = saveme.astype('uint16')\n",
    "print(saveme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5abebc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = r\"_results\"\n",
    "tiff.imwrite(os.path.join(results_folder, \"all_masked_stacks_V3b.tif\"), saveme, imagej=True, resolution=(1./2.6755, 1./2.6755),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c521a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['210218_murine-ML-hydrogel_60k-cells_A_2_inf_1_MMStack_Default.ome.tif']\n",
      "(100, 2304, 2304) (6272, 3, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "#Viktors data\n",
    "source_path = r\"Bactnet/viktor\"\n",
    "stacks = os.listdir(os.path.join(source_path))\n",
    "print(stacks)\n",
    "vikt = None\n",
    "\n",
    "def predict_stack(arr, batch_size, model):\n",
    "    \"\"\"\n",
    "    Performs prediction on all images in arr using model in increments of batch_size\n",
    "    Assumes patches of a ahpe where N is 0th axis.\n",
    "    \"\"\"\n",
    "    keras.backend.clear_session()\n",
    "    y_pred = None\n",
    "    for i in range(0, len(arr), batch_size):\n",
    "        subset = arr[i:i + batch_size]\n",
    "        \n",
    "        pred = model.predict(subset)\n",
    "        if y_pred is not None:\n",
    "            y_pred = np.concatenate((y_pred, pred))\n",
    "\n",
    "        else:\n",
    "            y_pred = pred\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "for i, image_name in enumerate(stacks):  # Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[-1] == 'tif'):\n",
    "        image = tiff.imread(os.path.join(source_path, image_name))\n",
    "        image = image[0:100]\n",
    "        image = normalizePercentile(image, 0.1, 99.9, clip=True)\n",
    "        patch = patch_stack(image, SIZE)\n",
    "        print(image.shape, patch.shape)\n",
    "        pred = predict_stack(patch, 2, model)\n",
    "        pred = unpatch_stack(pred, 8, 8, 1)\n",
    "        \n",
    "        if vikt is None:\n",
    "            vikt = pred \n",
    "        else:\n",
    "            vikt = np.concatenate((vikt, pred))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f46baa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1, 2304, 2304) (98, 1, 2304, 2304)\n",
      "(98, 2, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "saveme = vikt * 65535\n",
    "saveme = saveme.astype('uint16')\n",
    "img = np.expand_dims(image[0:-2], axis = 1)\n",
    "img = img * 65535\n",
    "img = img.astype('uint16')\n",
    "print(saveme.shape, img.shape)\n",
    "saveme = np.concatenate((img,saveme), axis = 1)\n",
    "print(saveme.shape)\n",
    "tiff.imwrite(os.path.join(source_path, \"pred.tif\"), saveme, imagej=True, resolution=(1./0.109, 1./0.109),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec7f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4637761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0398_210.tif (11, 2304, 2304) (576, 3, 288, 288) (576, 1, 288, 288)\n",
      "(576, 2, 288, 288)\n",
      "BT403_013.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n",
      "BT403_216.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n",
      "BT404_001.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load unseen data\n",
    "\n",
    "validation_image_directory = r\"C:\\Users\\analyst\\Documents\\Python Scripts\\BactUnet\\Bactnet\\Training data\\stacks\\predict\"\n",
    "result_folder = r\"C:\\Users\\analyst\\Documents\\Python Scripts\\BactUnet\\_results\"\n",
    "\n",
    "val_image_dataset = []\n",
    "val_mask_dataset = []\n",
    "pred_mask_dataset = []\n",
    "\n",
    "images = os.listdir(validation_image_directory)\n",
    "\n",
    "for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        \n",
    "        image = tiff.imread(os.path.join(validation_image_directory, image_name))\n",
    "        original_shape = image.shape\n",
    "        patch = patch_stack(image, SIZE)\n",
    "        \n",
    "        patch = normalizePercentile(patch, 0.1, 99.9, clip=True)\n",
    "        pred_mask_patch = model.predict(patch)\n",
    "        print(image_name, original_shape, patch.shape, pred_mask_patch.shape)\n",
    "        #pred_mask_patch = pred_mask_patch[:, 0, :,:]\n",
    "        image = np.expand_dims(patch[:, 1, :,:], axis=1)\n",
    "        patch = np.concatenate((image, pred_mask_patch), axis=1)\n",
    "        unpatched = unpatcher(patch, 8, 8, 2)\n",
    "        print(patch.shape)\n",
    "        tiff.imwrite(os.path.join(result_folder, image_name), unpatched, imagej=True, resolution=(1./2.6755, 1./2.6755),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})\n",
    "        \n",
    "        #pred_mask = unpatch_stack(pred_mask_patch, original_shape)\n",
    "        #tiff.imsave(os.path.join(result_folder, image_name), pred_mask_patch)\n",
    "        #val_image_dataset.append(image)\n",
    "        #pred_mask_dataset.append(pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7a69bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_mask_dataset)):\n",
    "    img = val_image_dataset[i][3]\n",
    "    msk = pred_mask_dataset[i][3]\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(121)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(122)\n",
    "    plt.title('Prediction on test image')\n",
    "    plt.imshow(msk)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c2554c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 conv2d (3, 3, 3, 64)\n",
      "4 conv2d_1 (3, 3, 64, 64)\n",
      "8 conv2d_2 (3, 3, 64, 128)\n",
      "11 conv2d_3 (3, 3, 128, 128)\n",
      "15 conv2d_4 (3, 3, 128, 256)\n",
      "18 conv2d_5 (3, 3, 256, 256)\n",
      "22 conv2d_6 (3, 3, 256, 512)\n",
      "25 conv2d_7 (3, 3, 512, 512)\n",
      "29 conv2d_8 (3, 3, 512, 1024)\n",
      "32 conv2d_9 (3, 3, 1024, 1024)\n",
      "35 conv2d_transpose (2, 2, 512, 1024)\n",
      "37 conv2d_10 (3, 3, 1024, 512)\n",
      "40 conv2d_11 (3, 3, 512, 512)\n",
      "43 conv2d_transpose_1 (2, 2, 256, 512)\n",
      "45 conv2d_12 (3, 3, 512, 256)\n",
      "48 conv2d_13 (3, 3, 256, 256)\n",
      "51 conv2d_transpose_2 (2, 2, 128, 256)\n",
      "53 conv2d_14 (3, 3, 256, 128)\n",
      "56 conv2d_15 (3, 3, 128, 128)\n",
      "59 conv2d_transpose_3 (2, 2, 64, 128)\n",
      "61 conv2d_16 (3, 3, 128, 64)\n",
      "64 conv2d_17 (3, 3, 64, 64)\n",
      "67 conv2d_18 (1, 1, 64, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11188/590165685.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mn_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_filters\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mfig1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mfig1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#Turn off axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 2 with size 3"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAABXCAYAAADve0ugAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAClklEQVR4nO3dsUpbYRjH4f8pdYhITpbGLFLwDoROegNeguAFCO6u4hUIbt6At6CrLm5egC7SxaVFHARFkK/TESwVmng+StvnWZPv5eWc8EuyJE0pJcD/7cOfXgD484QAEAJACIAIARAhAJJ8nObJ8/PzZTQaVVmkbdsqczs3NzdV5j48POTp6amZ9XzbtmUymfS50ouFhYUqcztXV1fVZt/f338vpXya9fxgMCjD4bDPlV4sLS1Vmdu5uLioNruU8svX6lQhGI1G2dra6mejn6yvr1eZ29nb26sy9/z8/F3nJ5NJDg8Pe9rmtdXV1SpzOzXv2enp6df3nB8Oh9nY2OhrnVcODg6qzO00zczvKzPz1QAQAkAIgAgBECEAIgRAhACIEAARAiBCAEQIgAgBECEAIgRAhACIEAARAiBCAEQIgAgBkCl/vHQ8Hmd7e7vKIicnJ1XmdsbjcZW5c3Nz7zp/e3ubo6OjnrZ5bXl5ucrczuXlZdX57/H8/Jy7u7sqs3d2dqrM7QwGgypzHx8f33zMJwJACAAhACIEQIQAiBAAEQIgQgBECIAIARAhACIEQIQAiBAAEQIgQgBECIAIARAhACIEQIQAiBAAEQIgSVNK+e0nLy4uls3NzSqL7O/vV5nbaZqm2uxSyszD27Yta2trfa7z4vj4uMrcTs1rmuSilPJl1sMrKyvl7Oysz31e1JrbqfV/DLu7u7m+vv7lTfOJABACQAiACAEQIQAiBECEAIgQABECIEIARAiACAEQIQAiBECEAIgQABECIEIARAiACAEQIQAiBECm/Dnzpmm+Jflab52/0udSyqdZD7umb3Jd+/fmNZ0qBMC/yVcDQAgAIQAiBECEAIgQABECIEIARAiAJD8Af8R5HAwU3/AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_weights = []\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "  if \"onv\" in layer.name:\n",
    "    all_weights.append\n",
    "    print(i, layer.name, model.layers[i].get_weights()[0].shape)\n",
    "\n",
    "weights, biases =  model.layers[1].get_weights()\n",
    "fig1=plt.figure(figsize=(12, 12))\n",
    "\n",
    "\n",
    "columns = 8 \n",
    "rows = 8 \n",
    "n_filters = columns*rows\n",
    "for i in range(1, n_filters +1):\n",
    "    f = weights[:, :, (i-1), 0]\n",
    "    fig1 =plt.subplot(rows, columns, i)\n",
    "    fig1.set_xticks([])  #Turn off axis\n",
    "    fig1.set_yticks([])\n",
    "\n",
    "    #plt.imshow(f[i%3, :, :], cmap='gray')\n",
    "    plt.imshow(f[:, :], cmap='gray')\n",
    "    #plt.imshow(f[2, :, :], cmap='gray') #Show only the filters from 0th channel (R)\n",
    "    #ix += 1\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
