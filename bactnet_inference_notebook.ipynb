{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b37971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jens\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have GPU access\n",
      "Thu Oct 13 09:52:33 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.72       Driver Version: 512.72       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   60C    P0    15W /  N/A |    168MiB /  4096MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      5624      C   ...nvs\\tensorflow\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "TensorFlow 2.6.0; Keras 2.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if tf.test.gpu_device_name()=='':\n",
    "    print('You do not have GPU access.')\n",
    "    !nvidia-smi\n",
    "\n",
    "else:\n",
    "  print('You have GPU access')\n",
    "  !nvidia-smi\n",
    "\n",
    "\n",
    "# print the tensorflow version\n",
    "print('TensorFlow {}; Keras {}'.format(tf.__version__, keras.__version__))\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac04cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uses 3.56 GB of memory at a batch size of 6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from preprocessing import get_model_memory_usage unpatch_stack\n",
    "\n",
    "#load pretrained model\n",
    "\n",
    "model = load_model(\"models/bactunet_noEmpty_final_alldata.hdf5\", compile=False)\n",
    "\n",
    "batch_size = 6\n",
    "print(\"Model uses {} GB of memory at a batch size of {}\".format(get_model_memory_usage(batch_size, model), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04714372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 288, 288) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 288, 288) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 288, 288) 1152        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 288, 288) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 288, 288) 36928       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 288, 288) 1152        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 288, 288) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 144, 144) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 144, 144 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 144, 144 576         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 144, 144 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 144, 144 147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 144, 144 576         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 144, 144 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 72, 72)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 72, 72)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 72, 72)  288         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 72, 72)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 72, 72)  590080      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 72, 72)  288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 72, 72)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 256, 36, 36)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 36, 36)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512, 36, 36)  144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512, 36, 36)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 36, 36)  2359808     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512, 36, 36)  144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512, 36, 36)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 512, 18, 18)  0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1024, 18, 18) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1024, 18, 18) 72          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024, 18, 18) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1024, 18, 18) 9438208     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1024, 18, 18) 72          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024, 18, 18) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 512, 36, 36)  2097664     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024, 36, 36) 0           conv2d_transpose[0][0]           \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 512, 36, 36)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 512, 36, 36)  144         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 512, 36, 36)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 512, 36, 36)  2359808     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 512, 36, 36)  144         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 512, 36, 36)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 72, 72)  524544      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512, 72, 72)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 72, 72)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256, 72, 72)  288         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256, 72, 72)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 72, 72)  590080      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256, 72, 72)  288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256, 72, 72)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 144, 144 131200      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 144, 144 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 144, 144 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 144, 144 576         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128, 144, 144 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 144, 144 147584      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 144, 144 576         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128, 144, 144 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 288, 288) 32832       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 288, 288 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 288, 288) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 288, 288) 1152        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64, 288, 288) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 288, 288) 36928       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 288, 288) 1152        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 64, 288, 288) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1, 288, 288)  65          dropout_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,040,529\n",
      "Trainable params: 31,036,137\n",
      "Non-trainable params: 4,392\n",
      "__________________________________________________________________________________________________\n",
      "conv2d/kernel:0 (3, 3, 3, 64)\n",
      "conv2d/bias:0 (64,)\n",
      "batch_normalization/gamma:0 (288,)\n",
      "batch_normalization/beta:0 (288,)\n",
      "batch_normalization/moving_mean:0 (288,)\n",
      "batch_normalization/moving_variance:0 (288,)\n",
      "conv2d_1/kernel:0 (3, 3, 64, 64)\n",
      "conv2d_1/bias:0 (64,)\n",
      "batch_normalization_1/gamma:0 (288,)\n",
      "batch_normalization_1/beta:0 (288,)\n",
      "batch_normalization_1/moving_mean:0 (288,)\n",
      "batch_normalization_1/moving_variance:0 (288,)\n",
      "conv2d_2/kernel:0 (3, 3, 64, 128)\n",
      "conv2d_2/bias:0 (128,)\n",
      "batch_normalization_2/gamma:0 (144,)\n",
      "batch_normalization_2/beta:0 (144,)\n",
      "batch_normalization_2/moving_mean:0 (144,)\n",
      "batch_normalization_2/moving_variance:0 (144,)\n",
      "conv2d_3/kernel:0 (3, 3, 128, 128)\n",
      "conv2d_3/bias:0 (128,)\n",
      "batch_normalization_3/gamma:0 (144,)\n",
      "batch_normalization_3/beta:0 (144,)\n",
      "batch_normalization_3/moving_mean:0 (144,)\n",
      "batch_normalization_3/moving_variance:0 (144,)\n",
      "conv2d_4/kernel:0 (3, 3, 128, 256)\n",
      "conv2d_4/bias:0 (256,)\n",
      "batch_normalization_4/gamma:0 (72,)\n",
      "batch_normalization_4/beta:0 (72,)\n",
      "batch_normalization_4/moving_mean:0 (72,)\n",
      "batch_normalization_4/moving_variance:0 (72,)\n",
      "conv2d_5/kernel:0 (3, 3, 256, 256)\n",
      "conv2d_5/bias:0 (256,)\n",
      "batch_normalization_5/gamma:0 (72,)\n",
      "batch_normalization_5/beta:0 (72,)\n",
      "batch_normalization_5/moving_mean:0 (72,)\n",
      "batch_normalization_5/moving_variance:0 (72,)\n",
      "conv2d_6/kernel:0 (3, 3, 256, 512)\n",
      "conv2d_6/bias:0 (512,)\n",
      "batch_normalization_6/gamma:0 (36,)\n",
      "batch_normalization_6/beta:0 (36,)\n",
      "batch_normalization_6/moving_mean:0 (36,)\n",
      "batch_normalization_6/moving_variance:0 (36,)\n",
      "conv2d_7/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_7/bias:0 (512,)\n",
      "batch_normalization_7/gamma:0 (36,)\n",
      "batch_normalization_7/beta:0 (36,)\n",
      "batch_normalization_7/moving_mean:0 (36,)\n",
      "batch_normalization_7/moving_variance:0 (36,)\n",
      "conv2d_8/kernel:0 (3, 3, 512, 1024)\n",
      "conv2d_8/bias:0 (1024,)\n",
      "batch_normalization_8/gamma:0 (18,)\n",
      "batch_normalization_8/beta:0 (18,)\n",
      "batch_normalization_8/moving_mean:0 (18,)\n",
      "batch_normalization_8/moving_variance:0 (18,)\n",
      "conv2d_9/kernel:0 (3, 3, 1024, 1024)\n",
      "conv2d_9/bias:0 (1024,)\n",
      "batch_normalization_9/gamma:0 (18,)\n",
      "batch_normalization_9/beta:0 (18,)\n",
      "batch_normalization_9/moving_mean:0 (18,)\n",
      "batch_normalization_9/moving_variance:0 (18,)\n",
      "conv2d_transpose/kernel:0 (2, 2, 512, 1024)\n",
      "conv2d_transpose/bias:0 (512,)\n",
      "conv2d_10/kernel:0 (3, 3, 1024, 512)\n",
      "conv2d_10/bias:0 (512,)\n",
      "batch_normalization_10/gamma:0 (36,)\n",
      "batch_normalization_10/beta:0 (36,)\n",
      "batch_normalization_10/moving_mean:0 (36,)\n",
      "batch_normalization_10/moving_variance:0 (36,)\n",
      "conv2d_11/kernel:0 (3, 3, 512, 512)\n",
      "conv2d_11/bias:0 (512,)\n",
      "batch_normalization_11/gamma:0 (36,)\n",
      "batch_normalization_11/beta:0 (36,)\n",
      "batch_normalization_11/moving_mean:0 (36,)\n",
      "batch_normalization_11/moving_variance:0 (36,)\n",
      "conv2d_transpose_1/kernel:0 (2, 2, 256, 512)\n",
      "conv2d_transpose_1/bias:0 (256,)\n",
      "conv2d_12/kernel:0 (3, 3, 512, 256)\n",
      "conv2d_12/bias:0 (256,)\n",
      "batch_normalization_12/gamma:0 (72,)\n",
      "batch_normalization_12/beta:0 (72,)\n",
      "batch_normalization_12/moving_mean:0 (72,)\n",
      "batch_normalization_12/moving_variance:0 (72,)\n",
      "conv2d_13/kernel:0 (3, 3, 256, 256)\n",
      "conv2d_13/bias:0 (256,)\n",
      "batch_normalization_13/gamma:0 (72,)\n",
      "batch_normalization_13/beta:0 (72,)\n",
      "batch_normalization_13/moving_mean:0 (72,)\n",
      "batch_normalization_13/moving_variance:0 (72,)\n",
      "conv2d_transpose_2/kernel:0 (2, 2, 128, 256)\n",
      "conv2d_transpose_2/bias:0 (128,)\n",
      "conv2d_14/kernel:0 (3, 3, 256, 128)\n",
      "conv2d_14/bias:0 (128,)\n",
      "batch_normalization_14/gamma:0 (144,)\n",
      "batch_normalization_14/beta:0 (144,)\n",
      "batch_normalization_14/moving_mean:0 (144,)\n",
      "batch_normalization_14/moving_variance:0 (144,)\n",
      "conv2d_15/kernel:0 (3, 3, 128, 128)\n",
      "conv2d_15/bias:0 (128,)\n",
      "batch_normalization_15/gamma:0 (144,)\n",
      "batch_normalization_15/beta:0 (144,)\n",
      "batch_normalization_15/moving_mean:0 (144,)\n",
      "batch_normalization_15/moving_variance:0 (144,)\n",
      "conv2d_transpose_3/kernel:0 (2, 2, 64, 128)\n",
      "conv2d_transpose_3/bias:0 (64,)\n",
      "conv2d_16/kernel:0 (3, 3, 128, 64)\n",
      "conv2d_16/bias:0 (64,)\n",
      "batch_normalization_16/gamma:0 (288,)\n",
      "batch_normalization_16/beta:0 (288,)\n",
      "batch_normalization_16/moving_mean:0 (288,)\n",
      "batch_normalization_16/moving_variance:0 (288,)\n",
      "conv2d_17/kernel:0 (3, 3, 64, 64)\n",
      "conv2d_17/bias:0 (64,)\n",
      "batch_normalization_17/gamma:0 (288,)\n",
      "batch_normalization_17/beta:0 (288,)\n",
      "batch_normalization_17/moving_mean:0 (288,)\n",
      "batch_normalization_17/moving_variance:0 (288,)\n",
      "conv2d_18/kernel:0 (1, 1, 64, 1)\n",
      "conv2d_18/bias:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "for l in model.weights:\n",
    "    print(l.name, l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7566fae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0407_110.tif (7, 2304, 2304) (5, 2304, 2304)\n",
      "BT0407_110.tif (320, 3, 288, 288) (320, 1, 288, 288)\n",
      "BT403_228.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT403_228.tif (704, 3, 288, 288) (704, 1, 288, 288)\n",
      "BT0398_210.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT0398_210.tif (704, 3, 288, 288) (704, 1, 288, 288)\n",
      "BT402_168.tif (5, 2304, 2304) (3, 2304, 2304)\n",
      "BT402_168.tif (192, 3, 288, 288) (192, 1, 288, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffPage 0 @87452> imagej_metadata failed with IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT403_000.tif (13, 2304, 2304) (11, 2304, 2304)\n",
      "BT403_000.tif (704, 3, 288, 288) (704, 1, 288, 288)\n",
      "BT404_199.tif (5, 2304, 2304) (3, 2304, 2304)\n",
      "BT404_199.tif (192, 3, 288, 288) (192, 1, 288, 288)\n",
      "dict_keys(['BT0407_110.tif', 'BT403_228.tif', 'BT0398_210.tif', 'BT402_168.tif', 'BT403_000.tif', 'BT404_199.tif'])\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import patch_image, patch_stack, normalizePercentile, normalizeMinMax\n",
    "from patchify import patchify\n",
    "\n",
    "source_path = r\"Bactnet/Training data/stacks/\"\n",
    "SIZE = 288\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(source_path, PATCH_SIZE, validation=True):\n",
    "    pred_dict = {}\n",
    "    if validation:\n",
    "        prefix = \"validation\"\n",
    "    else:\n",
    "        prefix = \"training\"\n",
    "    stacks = os.listdir(os.path.join(source_path, prefix+\"_source\"))\n",
    "    image_dataset = None\n",
    "    mask_dataset = None\n",
    "    for stack in stacks:\n",
    "        if (stack.split(\".\")[-1]==\"tif\"):\n",
    "            pred_dict[stack]={}\n",
    "            img = tiff.imread(os.path.join(source_path, prefix+\"_source\",stack))\n",
    "            pred_dict[stack][\"image\"]=img\n",
    "            mask = tiff.imread(os.path.join(source_path, prefix+\"_target\", stack))\n",
    "            pred_dict[stack][\"y_true\"]=mask\n",
    "            print(stack, img.shape, mask.shape)\n",
    "            \n",
    "            img_patch = patch_stack(img, PATCH_SIZE)\n",
    "            if len(mask.shape)==2:\n",
    "                mask_patch = patch_image(mask, PATCH_SIZE)\n",
    "            else:    \n",
    "                mask_patch = patch_stack(mask, SIZE=PATCH_SIZE, DEPTH=1)\n",
    "            \n",
    "            print(stack, img_patch.shape, mask_patch.shape)\n",
    "            mask_patch = normalizeMinMax(mask_patch)\n",
    "            img_patch = normalizePercentile(img_patch, 0.1, 99.9, clip=True)\n",
    "            pred_dict[stack][\"image_patch\"] = img_patch\n",
    "            pred_dict[stack][\"mask_patch\"] = mask_patch\n",
    "\n",
    "\n",
    "            #print(image_dataset.shape, mask_dataset.shape)\n",
    "\n",
    "    return pred_dict\n",
    "\n",
    "#pred_dict[file]=[image_stack, mask, patch, y_true, y_pred]\n",
    "image_dict = prepare_data(source_path, SIZE, validation=True)\n",
    "image_dict.update(prepare_data(source_path, SIZE, validation=False))\n",
    "print(image_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed33048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0407_110.tif (320, 1, 288, 288) (5, 1, 2304, 2304)\n",
      "BT403_228.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT0398_210.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT402_168.tif (192, 1, 288, 288) (3, 1, 2304, 2304)\n",
      "BT403_000.tif (704, 1, 288, 288) (11, 1, 2304, 2304)\n",
      "BT404_199.tif (192, 1, 288, 288) (3, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "stride = 2\n",
    "\n",
    "# #IOU\n",
    "for stack in image_dict.keys():\n",
    "    y_pred = None\n",
    "    img_stack = image_dict[stack]\n",
    "    for i in range(0, len(img_stack[\"image_patch\"]), stride):\n",
    "        pred = model.predict(img_stack[\"image_patch\"][i:i+stride])\n",
    "        if y_pred is not None:\n",
    "            y_pred = np.concatenate((y_pred, pred))\n",
    "\n",
    "        if y_pred is None:\n",
    "            y_pred = pred\n",
    "    \n",
    "    image_dict[stack][\"y_pred\"] = unpatch_stack(y_pred, 8, 8, 1)\n",
    "    print(stack, y_pred.shape, image_dict[stack][\"y_pred\"].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6c8ddc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1, 2304, 2304) 1.0\n",
      "(11, 1, 2304, 2304) 1.0\n",
      "(11, 1, 2304, 2304) 1.0\n",
      "(3, 1, 2304, 2304) 1.0\n",
      "(11, 1, 2304, 2304) 1.0\n",
      "(3, 1, 2304, 2304) 1.0\n"
     ]
    }
   ],
   "source": [
    "for stack in image_dict.keys():\n",
    "    saveme = np.concatenate(((image_dict[stack][\"y_pred\"]>0.5)*255, np.expand_dims(image_dict[stack][\"y_true\"],axis=1)), axis=1)\n",
    "    saveme = saveme.astype('uint8')\n",
    "    \n",
    "    dic = unpatch_stack(image_dict[stack][\"image_patch\"], 8, 8, 3)\n",
    "    dic = dic[:,1,:,:] * 255\n",
    "    dic = np.expand_dims(dic, axis=1).astype('uint8')\n",
    "    print(dic.shape, image_dict[stack][\"image_patch\"].max())\n",
    "    saveme = np.concatenate((dic, saveme), axis=1)\n",
    "    tiff.imwrite(os.path.join(r\"C:\\Users\\Jens\\Documents\\Code\\BactUnet\\Bactnet\\Training data\\stacks\\predict\", stack), saveme, imagej=True,\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc652211",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tru = None\n",
    "y_pre = None\n",
    "\n",
    "for stack in image_dict.keys():\n",
    "    if y_tru is None:\n",
    "        y_tru = image_dict[stack][\"y_true\"]\n",
    "        y_pre = image_dict[stack][\"y_pred\"]\n",
    "    else:\n",
    "        y_tru = np.concatenate((y_tru, image_dict[stack][\"y_true\"]))\n",
    "        y_pre = np.concatenate((y_pre, image_dict[stack][\"y_pred\"]))\n",
    "        \n",
    "dices = []\n",
    "IOUs = []\n",
    "frames = []\n",
    "threshold = 0.5\n",
    "\n",
    "y_pred_thresholded = (y_pre > threshold) * 255\n",
    "y_pred_thresholded = y_pred_thresholded.astype('uint8')\n",
    "\n",
    "for i in range(len(y_tru)):\n",
    "    intersection = np.logical_and(y_tru[i], y_pred_thresholded[i])\n",
    "    union = np.logical_or(y_tru[i], y_pred_thresholded[i])\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    IOUs.append(iou_score)\n",
    "\n",
    "frames =  list(range(len(y_tru)))\n",
    "\n",
    "    \n",
    "#plt.plot(frames, dices)\n",
    "plt.plot(frames, IOUs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "997b4301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxYklEQVR4nO3deXyc5XXo8d+Z0YxmtFmLtRjvGGNjGxzA2AaTYCCATVJIQkggkBuy0dBwm7bpbaG5JS00bbY27Q2kCWmSkiYECCTBCQY7AbOE1Tar5R0DtowtydLII2k0mu25f8yMPJa1vLNpZl6d7+fjjzWjV9KjsXV8fN7nnEeMMSillCp9jkIvQCmlVG5oQFdKKZvQgK6UUjahAV0ppWxCA7pSStmEBnSllLIJSwFdRNaIyC4R2Ssit4zw/u+IyKuJX7tFpCfnK1VKKTUmGW8fuog4gd3AJUAbsBm41hizfZTr/zdwpjHmMzleq1JKqTGUWbhmObDXGLMPQETuA64ERgzowLXAV8f7pFOnTjVz5syxuEyllFIAW7duPWKMaRzpfVYC+nTgQMrjNmDFSBeKyGxgLvDEeJ90zpw5bNmyxcKXV0oplSQi74z2vlzfFL0GeNAYEx1lITeKyBYR2dLZ2ZnjL62UUpOblYB+EJiZ8nhG4rmRXAP8YrRPZIy52xizzBizrLFxxP8xKKWUypCVgL4ZmC8ic0XETTxorxt+kYgsBOqA53O7RKWUUlaMG9CNMRHgZmADsAN4wBjTKiK3i8gVKZdeA9xndHyjUkoVhJWbohhj1gPrhz1327DH/5C7ZSmllEqXdooqpZRNaEBXSimb0IBeZMLRGA+/epBtB48WeilKqRJjqYau8i8UifGrl9u4c9Ne2nwDzG+qYuNfvg8RKfTSlFIlQgN6nnT4g9y5aS/lZQ6Wz21g+Zx6plS4TrguFInx0Mtt3PnEXg72DLB0Zi0XLWzip8+/w0tvdbPi5IYCrF4pVYo0oOeYMYZfbm3jn363nWA4BsAPn3kLEVjQXM2KufWsOLmBM2fVsmlnJ3dtigfy98ys5WsfXsIFpzYSDMf4zSsH+dmL+zWgqyHvdPXzjcd28o2rzqDac2JyoJQG9Bw60B3g7379Bs/sOcLyOfV8/arTOanWy2sHenjxrW5eequbB7a0cc/zx0YxpAbyZHnF63Zy1dkz+NkL79DZu4jG6vJCfUuqiDyz5wjr3zjMJYua+fCZMwq9HFWENKDnQDRm+Onzb/OtDbsQ4I4PLeG65bNwOOIBesXJDUOZdjgaY9vBo2x9x8epzdW8d/7UEevk162YzU+efZsHthzgixeeMpHfjipSHb2DAGxsbdeArkakAT1Lezt6+duH3mDrOz5WL2jkax8+nem13lGvdzkdnDmrjjNn1Y35eU9pquLckxv4xUv7+cIF83A6xr852vruUTp7B1m9oCnt70MVvw5/EICndncSDEfxuJwFXpEqNrptMQvBcJSr/vN53uzs4zsfX8pPbjhnzGCerutXzqbNN8DTu8efTHl0IMwNP9nMDT/ZzNce2U40phMY7Kajd5AyhxAIRfnjniOFXo4qQhrQs3Ckb5CjA2FuXbuQD585I+dbDC9d3ExjdTk/e2HU8cdDvvHYTrr6BvngGdP44TNv8Zn/3szRgXBO16MKq90f5Nx5DVR7yti4/XChl6OKkAb0LPQGIwDU5GnHgcvp4JpzZvLErg7afIFRr9v6Tjf3vrifT6+ay52fOIt//vDpPLv3CB++61ne7OzLy9rUxGv3DzKjzstFC5v4w44O/V+YOoEG9CwkA3o+t5Bds3wWAtz30oER3x+KxLj1V28wvdbLX11yKgCfWDGLez+/kqMDYT5057Ns2tWRt/WpiRGJxujqH6Sp2sOli1ro7g+x9R1foZeliowG9Cz0BuMljWpP/u4tT6+NZ2T3bT5AKBI74f0/fGYfu9v7uP3KxVSWH1vH8rn1PHzzKmbWV/CZ/97MD556E51sXLqO9IUwBppqyrlgQSNup4MNrVp2UcfTgJ4FfyKg13jz2+Rx3crZHOkbPKFu+vaRfv7j8T1cfnoLF5/WfMLHzair4MGbzmXtkhb+5dGd/N2vt+V1nSp/OnrjO1yaqz1UlZex6pQGNm4/rP9Iq+NoQM/CsZJLfnd/XjC/kZn13uNujhpj+Mpv3qDc6eCrf7J41I+tcJdx1yfO4tOr5vCLl/bz6oGevK5V5Ue7P74Hvakm3mR22eIWDnQPsPNwbyGXpYqMBvQsTFRAdziETyyfzQv7utnbEf8B/s2rB3l2bxd/s2YBzTWeMT9eRPjypQuorXDx3cf35HWtKj/aE3vQk3/WF5/WjEi8yUipJA3oWfAPhCkvc1Belv8Gj6uXzcDlFH7+4n58/SHu+N0OzpxVy3UrZlv6+KryMj67ai6P7+zQ0bwlqKN3EIdAQ6UbgMbqcs6eVafbF9VxNKBnwR+MTNiQpKlV5axdMo0Ht7bx1XWt+AfC/MtHTh8aL2DFp1bNodpTxnefyH+WHosZDvYM5P3rTBYd/iANVeWUOY/9yF66uJnWd/0c6B59S6uaXDSgZ6E3GKYmz+WWVNevnE1vMMK6197lc+89mYUtNWl9fI3HxadXzWVDazs7D/vzssZIND4p8tJ/f5pVX3+CPe1a482Fdn+Q5prjh7RduqgFgN9v17KLitOAnoXeYCTv9fNU58ypY2FLNbPqK/jSxfMz+hyfWTWHSreT7z6xN6drC0ViPLD5AO//t6f4i/tfpS9xf2G/Zo850dEb34Oeas7UShY0V2vZRQ2xFNBFZI2I7BKRvSJyyyjXfExEtotIq4jcm9tlFid/MJz3LYupRISffnY5D950Ll53ZnX72go3/+u8Oax/49DQDdZsBMNR/ueFd7jw20/yNw+9TpWnjO9ffzYP/Om5AHT1h7L+Giq+y2V4hg7xsstLb3XjG+d1jkRP7GFQ9jNuQBcRJ3AXsBZYBFwrIouGXTMfuBVYZYxZDPxF7pdafCY6QwdoqvackKml63Pnz8VT5uSuTW9m9Xme2NnOBd/axN//ZhtNNeX85IZz+O3N57NmSQsNVfGbd90a0LOW2iU63GWLW4gZ+MOOkcsuxhjuee5tFn91Ay/v185Su7OSoS8H9hpj9hljQsB9wJXDrvk8cJcxxgdgjJkUvea9wTDV5aV3ckxDVTnXr5zFw68e5K0j/Wl/vDGGO5/Yw2fv2UJ9ZTk//9wKfnXTeVy4sGloQFmF20l5mUMDeg6kdokOt/ikGk6a4mHjCHX0cDTGV36zja+ua2UwEqPNpzep7c5KQJ8OpA4SaUs8l+pU4FQReVZEXhCRNblaYDErRIaeK59/38m4nA6+tym9Wnr/YIQ/+/nLfHvjbq5YehK/uuk8Vp1y4iEdIkJDpZuuPg3o2Rragz5Chi4iXLq4hWf2dDIQig497+sP8ckfvci9L+7nI2fFf1yDKe9X9pSrm6JlwHxgNXAt8EMRqR1+kYjcKCJbRGRLZ+f4M76LWTgaIxCKTmgNPZeaqj1cu3wWv3rloOVtb+909fOR7z3HhtbDfOXy0/j3j79nzFp+XaWb7v7BXC150kqeVDRShg5w6aJmguEYT++J/0ztbu/lyrue5eX9PXzn40v5yuWnARAIRSZmwapgrAT0g8DMlMczEs+lagPWGWPCxpi3gN3EA/xxjDF3G2OWGWOWNTY2ZrrmotA3QV2i+fSFC+bhFOF7T45fS396dydX3Pksh/1B7vnMcj7/vpPHnf9eX+mmO6Az2bM1vEt0uOVz65nidbGxtZ0ndrbzke89RyAU5b4bV/LhM2dQ4Y7/HR0I641Ru7MS0DcD80Vkroi4gWuAdcOu+Q3x7BwRmUq8BLMvd8ssPhMxOjffWqZ4+Ng5M3hw6wHeHaUJKBKNcffTb3LDT15i2hQPv735fN4739o/xg2aoedEhz94XJfocGVOBxef1sTvXn+Xz96zhdkNFay7eRVnJY45LC+L/5gPhLXkYnfjppfGmIiI3AxsAJzAj40xrSJyO7DFGLMu8b5LRWQ7EAX+jzGmK58LL7ShSYslnKED3LT6FO7ffICvPbKDlfMaeLdnIOVXkMP+INGY4fLTW/jWR5ceN6J3PPWV5XRrDT1rHb2DJ3SJDveB06fxq5cPcvnpLXz76qVDWTnEZwF5XA6CGtBtz9JPpzFmPbB+2HO3pbxtgL9K/JoU/EOz0Es3Q4f4vPWPnj2TX7y0n0feOESZQ5hW6+GkKV5WzK3npFovC6dV84HTp6V9xF5DlZv+UFQPNM7SSF2iw118WjMb//J9nNJYNeI4CK/LedxNU2VPpZ1eFtBETVqcCF/9k0Vcc85MWqZ4mFpVjjON+TBjqas4thf9pBwenj3ZdPQOjjtRE+DU5upR3+d1ObXkMglo63+G8n2e6ETyuJwsnVlLc40nZ8Ec4jdFQZuLsjVal2g6PG7N0CcDDegZ8g8kTysq/Qw9X7RbNHtjdYmmo8KtGfpkoAE9Q8kMvSqNm4STjWbo2RurSzQdWkOfHDSgZ6g3GKbC7Rxz58Fkl9xmpwO6MjdWl2g6PFpDnxQ0GmWolNv+J0qNx4XTIboXPQvjdYla5XU5ddviJKABPUP+YNgWN0TzyeEQ6ipcdPdrt2imxusStcqrNfRJQQN6hjRDt6Zeu0WzMl6XqFVel5OA1tBtTwN6hnqD4ZJvKpoI8YCuNfRMWekStcLrduq0xUlAA3qG/JqhW9JQWa43RbNgpUvUCm0smhw0oGeod4KPnytVdZUuzdCz0O7Pfg86xAN6JGYI61F0tqYBPUOaoVtTX1nO0YGwnmmZoXjbfw4y9MTces3S7U0DegaC4SihSEx3uVjQUOnGGOgZ0J0u6cpVlygwNBxN6+j2pgE9A8fmuGiGPh7tFs1crrpEIV5yAXSni81pQM9Ar01G506EoW5RnYuetlx1iUJ8lgtoycXuNKBnwE6jc/OtTjP0jCUDei4ydI8G9ElBA3oG7HD83ERpGAro2lyUrmTbf7ZdonCs5KI1dHvTgJ6BoePndHTuuI5l6HpTNF256hKFYwFdM3R704CeAa2hW+dyOqjxlGmGnoF2f266REG3LU4WGtAzoDX09DRUabdoJjp6c9MlCrrLZbKwFNBFZI2I7BKRvSJyywjvv0FEOkXk1cSvz+V+qcXDPxBGBKrcGtCt0HkumclVlygcy9B1hK69jRvQRcQJ3AWsBRYB14rIohEuvd8Y857Er//K8TqLij8Yoaq8bMTT1dWJ6io0oGciV12ikFJD1wzd1qxk6MuBvcaYfcaYEHAfcGV+l1XceoMR7RJNQ4Nm6GkL57BLFI51imoN3d6sBPTpwIGUx22J54a7SkReF5EHRWRmTlZXpOKjc7XcYlV9lRtfIIQxptBLKRlH+gZz1iUK4HQI7jKHBnSby9VN0d8Cc4wxZwC/B+4Z6SIRuVFEtojIls7Ozhx96Ynn14CeloZKN+GowZ+4mazG1+FP7EHPUYYOiWPotORia1YC+kEgNeOekXhuiDGmyxiT3Jf2X8DZI30iY8zdxphlxphljY2Nmay3KGjJJT06zyV9uewSTdJTi+zPSkDfDMwXkbki4gauAdalXiAi01IeXgHsyN0Si48eP5eeOu0WTVsuu0STKvRcUdsbNyoZYyIicjOwAXACPzbGtIrI7cAWY8w64M9F5AogAnQDN+RxzQWnx8+lp0G7RdOWyy7RJI/LqdsWbc5SmmmMWQ+sH/bcbSlv3wrcmtulFSdj4rVgbfu3rl4z9LTlsks0yasZuu1pp2iaBsJRojGjGXoaGirjdWDtFrUul12iSV6XU/eh25wG9DRp23/6vG4nXpeTbp2Jblkuu0STPC4nA2E9CtDONKCnyT+gg7kyoe3/6clLhu52MhDSraN2pgE9TX49fi4j9ZVuugMa0K2Id4mGcp6hV7i0hm53GtDTpKNzM6MZunW57hJNimfoGtDtTAN6mvSA6Mw0VLptd65o32CEjt5gzj9vPrpEIbltUWvodqYBPU1+zdAzYrcMPRCK8NH/fI6Lvv0Uz7/ZldPPnY8uUYjvcglFY0SiGtTtSgN6moYydN2Hnpa6SjcD4agt/stvjOFvH3qDXe291FW6+NRPXuL329tz9vnb89AlCuB1x3/cgxEN6HalAT1NvcEwTocMzZdW1iQ7Hrts0Fz042ff5revvctfX7qAdV88n9Om1fCFn23loa1tOfn8nXnoEoXUU4t0p4tdaUBPU3KOi4gebpGOZLeor8Tb/1/Y18U/r9/BZYub+bPV86irdHPv51aw8uR6vvzL1/jRH9/K+mvko0sUwJs4YSsY0gzdrjSgp8k/oKNzM9FQVfoZ+qGjA9x878vMbqjg21cvHfpHvbK8jB/fcA5rFrdwx++2868bd2U1+709D3vQIeXUIt26aFsa0NOko3MzU59o/y/VG6ODkSg3/exlBkJR7v7k2SfcFC8vc3LXdWfx8WUz+e4Te7nt4VZiscyCekceukThWA1dA7p9aaqZJh2dm5n6itKeif6Pv93Oqwd6+P71Z3FKU/WI1zgdwtevOp3aShc/eGofvkCIb1+9dOj4N6s6eoMsnTklF8s+jkfPFbU9jUxp8gfDzKyvKPQySk6Nt4wyh5TkgK77N+/n3hf3c9PqeaxZMm3Ma0WEW9eeRn2Fm395dCcHfAP88JNn02Rxx0q+ukThWMlFR+jal5Zc0qQll8yICHWVbnwlFtBfb+vh7x9u5fxTpvLXly6w/HF/esE8vn/92exp7+VP7vwjr7f1WPq4fHWJQrxTFNBTi2xMA3qa9DzRzDVUuksqQ9/6jo9P/fglGqvK+X/XnonTkd7OpjVLWnjopvMoczi4+vvPs+61d8f9mPY8dYkCVLjif2+1hm5fGtDTEIsZ+gYj2vafoVLqFt3YephP/PAFpnhd/PxzK4a2XabrtGk1rLt5FUtn1PLnv3iFb23YOebN0o48dYkCePSmqO1pZEpDXyiCMdr2n6m6Sjfb3/UXehnj+p8X3uGrD2/j9Bm1/PhTy2ioyi64NlSV87PPreC2h7dx16Y32d3ex3c+/h5CkRi723vZ097L7vY+drf3svNwLwAtOe4ShZQaupZcbEsDehq07T878QFdme9Dj0RjfOn+V6mvcLP29BaWz6nPafONMYZvbtjFfz75JhcvbOK7nziTCndu/qzdZQ7+5SOns7Clmjse2cHZd/yewZQW/KryMk5trmLtkhaWzam3fBM1HR7dh257GpnSoKNzs1Nf6cYfjBCOxnBlEIhf3t/DI68fwiHxLLqh0s1lS1q4fMk0Vp6cXXAPRWL87UOv8+tXDnLt8lncceXinHdqigg3rJrLqS3VPPL6IeY0VDK/uYpTm6uZNsWT9+5jl9OByyka0G3MUkAXkTXAfwBO4L+MMV8f5bqrgAeBc4wxW3K2yiKhx89lJzmbxBfIbFvepl0dlDmEZ2+5iC1v+1i/7RC/fvkg9764n7oKF5cuauFDZ05n5cn1aQXH3mCYm372Mn/ce4QvX3IqN190Sl6D63nzpnLevKl5+/xj0XNF7W3cyCQiTuAu4BKgDdgsIuuMMduHXVcNfAl4MR8LLQZ6/Fx2UrtFMwnoT+7q5OzZdTTXePjAGdP4wBnTGAhFeWp3J49uO8TvXn+X+7ccYE5DBR87ZyYfPXvGqF8nGjO89FY3j207xKPbDtPdH+JbHz2Dq5fNzOp7LHZ6yIW9WUk1lwN7jTH7AETkPuBKYPuw6+4AvgH8n5yusIjo4RbZqauM/0OYyWHRh48G2XHIzy1rFx73vNftZM2SFtYsaWEgFGX9G4e4f/MBvvnYLv51424uXtjENctn8r75jcQMPL+vi8e2HWJjaztd/SHKyxysXtDIp1fNZeXJDTn5PouZV4+hy7vu/hB/9vOt3HHlEuY3j9xVnC9WItN04EDK4zZgReoFInIWMNMY84iI2Diga4aejYZEhp7JXvSndncAsHpB46jXeN1Orjp7BledPYM3O/t4YPMBHtzaxsbt7TTXlDMQiuIPRqh0O7notGbWLmlh9YLGnN34LAUeDeh5t/6NQ7ywr5sHt7Zx6+WnTejXzvpvsog4gH8DbrBw7Y3AjQCzZs3K9ktPOL/W0LOS3MudyV70J3d10lLjYYHFjGdeYxW3Xn4aX750AU/sbOdXLx+kylPG2iXTeO/8qWnPV7ELr9uprf959ti2wwA8sbOjKAP6QSC1sDgj8VxSNbAEeDJxI6kFWCciVwy/MWqMuRu4G2DZsmWZzxctEH8wjLvMMWmDQbbqKhIllzQDejga4497jvDBpdPSvlnpLnOwZsm0cWewTBZ6UzS/egIhnt/XxdSqcvZ09HGgOzChs5+s7MvaDMwXkbki4gauAdYl32mMOWqMmWqMmWOMmQO8AJwQzO0gPsdFs/NMlTkd1Fa40g7oW9/x0TsY4YJTm/K0ssmjwu3UWS559IcdHURjhr//YDwz37SrY0K//rgB3RgTAW4GNgA7gAeMMa0icruIXJHvBRaT+OhcrZ9no74i/fb/J3d1UuYQVp1i/5uW+eZxacklnx7bdoiTpni4YulJzGmo4ImdExvQLaWbxpj1wPphz902yrWrs19WcdLTirJXX+lO+9SiJ3d1cM6cev3HNAd0l0v+9A1GeHrPEa5bMQsR4cKFTdz74n4GQtGhSZf5psO50tAbDOvo3CylO6Dr0NEBdh7uHXN3i7LO69aAni9P7uogFImxZnELABcvbGYwEuO5N49M2Bo0oKdBTyvKXkOVm+40Dop+alcnABcu1Pp5LuhN0fx5dNthpla5WTanHoDlc+updDsntOyiAT0NGtCzV1/pxhcIWT5vc9OuDk6a4mF+U1WeVzY5eFxOBiOxjM87VSMLhqNs2tnBJYtahubmu8scnD9/Kpt2dmR1aHg6NKCnIX64hZZcslFfWU40ZvAHx8/SQ5EYz+7t4oIFTXkfXDVZVLh14mI+PLPnCIFQlDVLWo57/qKFTbx7NDg0FjnfNKBbFInGCISiWkPPUn2i/d9Kt+iWd7rpG4xwodbPc8arAT0vHtt2mBpPGecOGx9x4YJ4qXCiyi4a0C3qG9Qu0VxIHdA1nqd2deJyCuedUpjJhHY0NBNd6+g5E47G+MOOdt5/WjPusuNDalONhyXTa9ikAb24+Ac0oOdCQxrt/0/u6uScOfVUletrnitDpxZphp4zL+zr4uhAmMuGlVuSLlrQxMv7fRNyQLoGdIv8OpgrJ6zOc3m3Z4Bd7b1D/2VVueHVU4ty7rFth/G6nFxw6silwQsXNhEz8PSezryvRQO6RXr8XG5YDehPJrYr6v7z3BqqoWvJJSeiMcOG1nYuXNg46oynpTNqaah0T0gdXQO6RcnRuXpTNDsel5MKt5OucWaiP7mrg+m1Xk7R7Yo5lQzoAc3Qc+Ll/T6O9A1y2eKRyy0ADoewekETT+3uJJrn7aIa0C3S0bm5E+8WHb39P75d8QirFzTqdsUcG6qha4aeE49tO4zb6eCicRrfLlrYRE8gzCv7fXldjwZ0izRDz52GSjfdgdH3oW95u5v+UJTVWj/POa2h544xhse2Heb8+VPHvbf23lOnUuaQvJddNKBblKyhV2mGnrXxMvQnd3fidjo4b55OV8w13YeeO9sO+jnYMzA0u2UsNR4Xy+bUaUAvFv6BMF6XE5dTX7Js1VeWj3mu6KadHfE5GLpdMed0H3ruPNZ6CKdDeP+iZkvXX7SwiZ2HeznYM5C3NU2a6BQIRfjh0/sIRWIZfbzOccmd+koXXf2hE+ZbHOkb5Cu/foM9HX26uyVPdB967jy27TAr5tYP7dwaT7LOns8mo0kT0J/c1cnX1u9g4/bDGX1872CYGq/Wz3OhvrKcwUhs6OScYDjK957cy+pvPcl9mw/wqXNnc/3K2QVepT25yxyUOURPLcrSm519vNnZf8LslrHMa6xiZr03rwF90qScydkhG1vb+eAZJ6X98Zqh506yW7SrL8QfdrTzzcd2cbBngPef1sytly9kXqNuVcwnPeQie28f6QfgjBm1lj9GRLhoQRP3bzlAMBzNy9nEkyZCJWu2m3bGh9APn7kwHv9AmCkV1v5rpcaW/C/qdT96gQPdAyw+qYZvXX0G583TmS0TwePWY+iy5Uvs0koefG7VhQubuOf5d3h+X1deuqAnTUD3BeIBvXcwwnNvHkl7S1xvMMKMCTy9286m1XoACEcM3756KR85czoOh+43nyh6yEX2ehLxpDbNJG/lyQ0sPqmGwXBm9/LGM2kCeld/iGlTPPgHwmzc3p52QPcHI7oHPUcWnzSFB/70XJZMr6HCPWn+ChYNLblkzxcI4XQINWmWYT0uJ4/8+XvztKpJdFPU1x+iZYqH1Qua+P329rRPbImfJ6rBJ1eWz63XYF4gHreTgTxliJNFTyBMrddVdJ3MlgK6iKwRkV0isldEbhnh/V8QkTdE5FUR+aOILMr9UrPT1R+iodLNpYub6ewd5JUD1ltwByNRBiMxvSmqbKHC5WQgFCn0MkpaTyBMbZr184kwbkAXESdwF7AWWARcO0LAvtcYc7ox5j3AN4F/y/VCs+XrD1FX4ebChU24nMLG1nbLH9s7NMel+P4AlUqX160ll2z5AvF4UmysZOjLgb3GmH3GmBBwH3Bl6gXGGH/Kw0qgqE6gNcbQHQhRX+WmxuPi3HlT2dB62PLBrTo6V9mJ3hTNnq9UM3RgOnAg5XFb4rnjiMgXReRN4hn6n+dmebnRH4oSisSG9j9ftriZt7sC7G7vs/Tx/oHE4RblxfcHqFS6PC4nQa2hZ6UnEEp7h8tEyNlNUWPMXcaYecDfAv93pGtE5EYR2SIiWzo78396R1Ly6Kfkf5EuWdSMCGxstdY12qujc5WNeN0OLblkKV5yKb4Ez0pAPwjMTHk8I/HcaO4DPjTSO4wxdxtjlhljljU2TtysjmSXaENVPKA3VXs4c2YtGyyOARganaut/8oGtOSSnWA4SjAcK9kMfTMwX0TmiogbuAZYl3qBiMxPefgBYE/ulpi94Rk6wGWLW9h20E+bLzDux2uGruzE6y5jIBxNe+uuiusZ6hItwYBujIkANwMbgB3AA8aYVhG5XUSuSFx2s4i0isirwF8Bn8rXgjMxlKFXlg89d2lihvHvt4+/20UPiFZ2kpy4OJjh5NHJzjfUJVp88cBSymmMWQ+sH/bcbSlvfynH68qpoQy98tgfwNyplZzaXMWG1sN8etXcMT8+efxclc7nVjbgdcXzuIFwdOjAC2VdMQf0SdEp2tUfwu10nBCQL1vcwktvdY97An1vMEx1eRlOnTeibEBPLcpOSZdc7MDXH6Ku8sQ23csWtxAz8PiOscsuOjpX2YmeWpSdZIauAb1AuvpD1KfUz5MWn1TD9FovG8bpGvUPhLV+rmxDTy3KTjJD15JLgfgCIeorT3zxRYRLFjXzzJ5OAmPMttAMXdlJciianlqUmZ5ACK/LmZcDKrI1KQJ69ygZOsTLLoORGE/vHr3RSY+fU3bidR+7KarSV6xt/zCZAvoofwDnzKmjrsI1ZtnFP6AZurIPraFnp1jb/mESBPRwNMbRgfCoGXqZ08HFpzXz+I52wtGR9+X2BsMa0JVtaA09O75AuCjb/mESBPTkDYyRauhJaxa34A9G+PD3nuWnz789dLwUxCc1xmvoxfkHqFS6dNtidop1dC5MgoCe3GM+WoYOcPFpTdzxoSVEY3Dbw60s/9rjfPHel9m0q4P+UJRIzOjxc8o2vFpyycrRIq6h276O0D1Cl+hwIsInV87mkytns+3gUR7c2sbDrx7kkdcPDY3c1ZKLsgvN0DNnjKFnIFy0Gbrto1T3CHNcxrJk+hSWTJ/CrZcv5IkdHfxyaxt/3HOE+U1V+VymUhPG7XTgEM3QM+EPRojGjGbohdIdGD9DH0l5mZO1p09j7enTMMYU3WGwSmVKROIjdDVDT1vP0ByX4szQ7V9D78u+TVeDubIbPVc0M76hOS7FmaHbPqD7AiFqPGW4nLb/VpWyzONyEtSSS9o0Qy+wrv4QDVXW6udKTRZacslMj2boheXrL86z/5QqpAq3U2e5ZMCnGXphjTZpUanJzKMZekZ8gTAiMKVIZzvZPqD7+keetKjUZOZ1O7X1PwM9gRA1HlfRHnZj64BujBlz0qJSk5XX5dR96Bko5jkuYPOA3h+KEorGNENXahi9KZqZYp60CBYDuoisEZFdIrJXRG4Z4f1/JSLbReR1EXlcRGbnfqnpS+5B1wxdqeN5tOSSkZ5Sz9BFxAncBawFFgHXisiiYZe9AiwzxpwBPAh8M9cLzUSyS1QzdKWOV+HSXS6Z8NkgQ18O7DXG7DPGhID7gCtTLzDGbDLGBBIPXwBm5HaZmenuHwQ0Q1dquGSnqDGm0EspKT1FPGkRrAX06cCBlMdtiedG81ng0WwWlSvd/YlZ6EX8L6pSheBxOTEGBiMjH+qiThSKxOgbjBTtpEXI8XAuEbkeWAZcMMr7bwRuBJg1a1Yuv/SIhjL0quL9A1CqEFJPLSrGw46LUc9Aci5UaWfoB4GZKY9nJJ47joi8H/gKcIUxZnCkT2SMudsYs8wYs6yxsTGT9aaluz+M2+mg0q1/YZVKpTPR03c00fZf6jX0zcB8EZkrIm7gGmBd6gUicibwA+LBvCP3y8xMd/8g9ZVunZao1DB6alH6fEMBvYQzdGNMBLgZ2ADsAB4wxrSKyO0ickXism8BVcAvReRVEVk3yqebUN39Yeoqi/dfU6UKJZmh604X65JzXEq+hm6MWQ+sH/bcbSlvvz/H68qJ7v7BoSPklFLHpNbQlTXHRueWcIZeynwBzdCVGonW0NN37HCL4o0ptg7oXX2aoSs1Eq2hp68nEN9kUVHEmyxsG9DD0Rj+YHHvGVWqUJJbFTVDty4+x8VV1JssbBvQkzcwdA+6UidKlly0hm6dLxHQi5l9A7p2iSo1qgqX7nJJly8QLuo96GDjgN41NMeluP8AlCoEvSmavp5A8R9naduAPpSha0BX6gTlZfEf/aBm6JbFD7co7nhi24DerRm6UqMSET3kIg3GGI5qyaVwkpMWi/0mhlKFkhyhq8YXSJx+piWXAunuH2SK14XLadtvUamsxM8V1fG5VvhKoEsU7BzQA2Ettyg1hniGHin0MkpCTwlMWgQ7B/TEpEWl1MjiGbqWXKwohcFcYOuAXvx3pJUqJL0pat2xOS5acikInbSo1Ng8bicDYa2hW3F0qIZe3DHFlgHdGINPZ6ErNSavy6H70C1KZuhTvJqhT7i+wQihaEwzdKXGoCUX63yBEFXlZbjLijtkFvfqMpTsEtUMXanRed1lOsvFop5AuOi3LIJNA3pyjotm6EqNzuty6rRFi3yBUElssrBlQB/aYqQBXalRed0OBsJRjDGFXkrR82mGXjhdffGArhm6UqPzupxEY4ZwVAP6eI5qhl44mqErNT49tcg6W2XoIrJGRHaJyF4RuWWE979PRF4WkYiIfDT3y0xPV38Id5mDyiI++0+pQtNTi6yJxgz+YPFPWgQLAV1EnMBdwFpgEXCtiCwadtl+4Abg3lwvMBO+/hD1Fe6iPvtPqUJLHnasO13GdnQgjDHF3yUKUGbhmuXAXmPMPgARuQ+4EtievMAY83bifUXRdtbdH9I5LkqNw5ssuWhAH1OpzHEBayWX6cCBlMdtieeKlgZ0pcanNXRrjk1aLP4MfUJviorIjSKyRUS2dHZ25u3raEBXanzJDF1r6GPrKZE5LmAtoB8EZqY8npF4Lm3GmLuNMcuMMcsaGxsz+RSWaEBXanxDB0VryWVMpTJpEawF9M3AfBGZKyJu4BpgXX6XlblwNIY/GNGArtQ4kjdFteQyNltl6MaYCHAzsAHYATxgjGkVkdtF5AoAETlHRNqAq4EfiEhrPhc9Ft2DrpQ1Hr0paokvEMLpEGo8VvaQFJalFRpj1gPrhz13W8rbm4mXYgquu1+7RJWywqs3RS3xBcLUel0lsQ3adp2iyYBeCluMlCokr5ZcLDlaIl2iYOOA3lClAV2psXjKtORihS8QKon6OdgwoPs0Q1fKEodDKC9z6LbFcfgC4ZLY4QI2DOhdQwG9NP4AlCqkCreeWjSeHs3QC8fXH2KK10WZ03bfmlI553U5dZbLOOKHW5RGgmi7qNfVH9IdLkpZ5NEMfUzBcJRgOKYZeqH4AiHdg66URV6Xk6Bm6KMqpTkuUIIBfW9HL/+wrpVwdOTBjl192vavlFVel2boYymlSYtQggH96d1H+O/n3ubGn24hEIqc8H5fID4LXSk1Pq+WXMbkG2r71ww9Lz5z/lz+6UNLeGp3J5/44YtD+84BjDHxwVy6B10pS7wup+5DH0PP0GCu0ogpJRfQAa5fOZvvXXc22w/5+ej3n6PNFwCgbzBCOGo0Q1fKIs3Qx6YllwmyZkkLP/vsCo70DvKR7z3HjkP+oWxda+hKWaMZ+tj0pugEWj63nl9+4TwcInzsB8/z6LbDgAZ0pazy6E3RMfUEQnhcjqHJlMWupAM6wIKWah76s/NorvHw9Ud3AhrQlbLK63Zq6/8Y4m3/pRNPSj6gA0yv9fLgF87lrFm1ADTXeAq7IKVKhNflJBw1o24DnuxKqe0fLM5DLwW1FW7u/fxKth/y0zJFA7pSViRPLQqGo7h0XMYJSmkwF9gkQ0/yuJycNauu0MtQqmToqUVji89xKZ0M3VYBXSmVHj21aGyldLgFaEBXalLTU4tGZ4yhZ0ADulKqRHi15DIqfzBCNGbsV3IRkTUisktE9orILSO8v1xE7k+8/0URmZPzlSqlcs6jJZdR9QzNcSmdgD7uLhcRcQJ3AZcAbcBmEVlnjNmectlnAZ8x5hQRuQb4BvDxfCxYKZU7qbtcrDLG0B+KcqR3kHZ/kMP+IIePBjl0NEi7/9jvtRVuls6YwhkzajljxhQWtFQX3U6acDRG/2CEqvKyEw7F8Q3NcSmdkouVbYvLgb3GmH0AInIfcCWQGtCvBP4h8faDwJ0iIsYYk8O1KqVyLFlDD4SiDEaidPYO0tE7SIc/mPh9kCN98V+dfSGO9A7S1T9IMHzivvWq8jJapnhoqfFw8rwGOnsHeXTbYe7bfAAAd5mDRdNqWDpjCnOnVlJX6aa2wk1dhYu6Cje1FS6qyssQkTHXHI7GONIXX9vQenuD9AUjOJ1CmUNwOhyJ3+OPIzGT+D7i30Nn4ntKtvYDVHvKqK1wUet1M8XrIpTYm2+rDB2YDhxIedwGrBjtGmNMRESOAg3AkVwsUimVH8ka+pcfeI3ByIlB2iFQX1nO1Co3jdXlnDy1kqlVbqZWldNQVU5LjYeWKeU013io9pyYyRpj2N8d4LW2o7zR1sNrbUf55da2UY+9czkFr8uJ0yE4RBARHAKOxO/BSOy4CaupKtxOojFDNGaIxE7MJSvdTqZWl9NYVc4pjVWsPLmeqVXlVHtc9AbD9ATCHB0I0xMI0TMQ5mggzClNVcxrrEznJS2oCW0sEpEbgRsBZs2aNZFfWik1gum1Xj6zai6haJSmag9N1eU01ZTH364pp6GyHKdj7Ix5LCLC7IZKZjdUcsXSkwCIxgxHB8J094foCYTwBcL4AsfeHghFiRmT+BX/RyEWg5gxuMscNFV7aKwup6m6PP57TTlTq8qPK+eYxMdGYjGiMYNDpGTmsWTDSkA/CMxMeTwj8dxI17SJSBkwBega/omMMXcDdwMsW7ZMyzFKFZjDIdz2J4sm9Gs6HUJ9pTuvM5dEBKeA02H/IJ7Kyh2KzcB8EZkrIm7gGmDdsGvWAZ9KvP1R4Amtnyul1MQaN0NP1MRvBjYATuDHxphWEbkd2GKMWQf8CPgfEdkLdBMP+koppSaQpRq6MWY9sH7Yc7elvB0Ers7t0pRSSqWjuDaFKqWUypgGdKWUsgkN6EopZRMa0JVSyiY0oCullE1IobaLi0gn8E6GHz4VHSswGn1tRqevzej0tRlZMb4us40xjSO9o2ABPRsissUYs6zQ6yhG+tqMTl+b0elrM7JSe1205KKUUjahAV0ppWyiVAP63YVeQBHT12Z0+tqMTl+bkZXU61KSNXSllFInKtUMXSml1DAlF9DHO7B6MhGRH4tIh4hsS3muXkR+LyJ7Er/XFXKNhSAiM0Vkk4hsF5FWEflS4nl9bUQ8IvKSiLyWeG3+MfH83MQB73sTB76XzrlrOSYiThF5RUR+l3hcMq9NSQX0lAOr1wKLgGtFZGKn8xeX/wbWDHvuFuBxY8x84PHE48kmAnzZGLMIWAl8MfH3RF8bGAQuMsYsBd4DrBGRlcQPdv+OMeYUwEf84PfJ6kvAjpTHJfPalFRAJ+XAamNMCEgeWD0pGWOeJj5/PtWVwD2Jt+8BPjSRayoGxphDxpiXE2/3Ev/hnI6+Npi4vsRDV+KXAS4ifsA7TNLXBkBEZgAfAP4r8Vgoodem1AL6SAdWTy/QWopVszHmUOLtw0BzIRdTaCIyBzgTeBF9bYChksKrQAfwe+BNoMcYE0lcMpl/rv4d+BsgeWJ2AyX02pRaQFdpSBwDOGm3MYlIFfAQ8BfGGH/q+ybza2OMiRpj3kP8fODlwMLCrqg4iMgHgQ5jzNZCryVTlk4sKiJWDqye7NpFZJox5pCITCOehU06IuIiHsx/boz5VeJpfW1SGGN6RGQTcC5QKyJliUx0sv5crQKuEJHLAQ9QA/wHJfTalFqGbuXA6sku9cDuTwEPF3AtBZGoe/4I2GGM+beUd+lrI9IoIrWJt73AJcTvMWwifsA7TNLXxhhzqzFmhjFmDvHY8oQx5jpK6LUpucaixL+e/86xA6u/VtgVFY6I/AJYTXwiXDvwVeA3wAPALOLTLD9mjBl+49TWROR84BngDY7VQv+OeB19sr82ZxC/seckntA9YIy5XUROJr7JoB54BbjeGDNYuJUWloisBv7aGPPBUnptSi6gK6WUGlmplVyUUkqNQgO6UkrZhAZ0pZSyCQ3oSillExrQlVLKJjSgK6WUTWhAV0opm9CArpRSNvH/AdirZVAaOYC4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dice_score(mask1, mask2):\n",
    "    intersect = np.sum(mask1*mask2)\n",
    "    fsum = np.sum(mask1)\n",
    "    ssum = np.sum(mask2)\n",
    "    dice = (2 * intersect ) / (fsum + ssum)\n",
    "    dice = np.mean(dice)\n",
    "    dice = round(dice, 3) # for easy reading\n",
    "    return dice    \n",
    "\n",
    "def iou_score(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask1)\n",
    "    union = np.logical_or(mask1, mask2)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "\n",
    "for stack in image_dict.keys():\n",
    "    image_dict[stack]\n",
    "    image_dict[stack]['y_pred']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebd59a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0398_210.tif (13, 2592, 2592) (11, 1, 2304, 2304) (11, 1, 2304, 2304)\n",
      "BT402_168.tif (5, 2592, 2592) (3, 1, 2304, 2304) (14, 1, 2304, 2304)\n",
      "BT403_000.tif (13, 2592, 2592) (11, 1, 2304, 2304) (25, 1, 2304, 2304)\n",
      "BT403_228.tif (13, 2592, 2592) (11, 1, 2304, 2304) (36, 1, 2304, 2304)\n",
      "BT404_199.tif (3, 2592, 2592) (1, 1, 2304, 2304) (37, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import pad_stack, crop_stack, predict_stack\n",
    "\n",
    "\n",
    "def crop_stack(arr, SIZE):\n",
    "    \"\"\"\n",
    "    Undoes the padding from pad_stack, crops out the center, removing a 1/2 SIZE broder from around the stack\n",
    "    \"\"\"\n",
    "    pad_SIZE = int(SIZE / 2)\n",
    "\n",
    "    if len(arr.shape) == 3:\n",
    "        t, y, x = arr.shape\n",
    "        stopY = y - pad_SIZE\n",
    "        stopX = x - pad_SIZE\n",
    "        return arr[:, pad_SIZE:stopY, pad_SIZE:stopX]\n",
    "\n",
    "    if len(arr.shape) == 4:\n",
    "        t, c, y, x = arr.shape\n",
    "        stopY = y - pad_SIZE\n",
    "        stopX = x - pad_SIZE\n",
    "        return arr[:, :, pad_SIZE:stopY, pad_SIZE:stopX]\n",
    "\n",
    "#Lets enlarge and see if patch edge regions are affecting the results\n",
    "\n",
    "source_path = r\"Bactnet/Training data/stacks/validation_source\"\n",
    "stacks = os.listdir(os.path.join(source_path))\n",
    "        \n",
    "\n",
    "ypred_2 = None\n",
    "    \n",
    "for i, image_name in enumerate(stacks):  # Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = tiff.imread(os.path.join(source_path, image_name))\n",
    "        image = normalizePercentile(image, 0.1, 99.9, clip=True)\n",
    "        expanded_image = pad_stack(image, SIZE)\n",
    "        expanded_patch = patch_stack(expanded_image, SIZE)\n",
    "        pred = predict_stack(expanded_patch, 2, model)\n",
    "        pred = unpatch_stack(pred, 9, 9, 1)\n",
    "        pred = crop_stack(pred, SIZE)\n",
    "        if ypred_2 is None:\n",
    "            ypred_2 = pred \n",
    "        else:\n",
    "            ypred_2 = np.concatenate((ypred_2, pred))\n",
    "\n",
    "        print(image_name, expanded_image.shape, pred.shape, ypred_2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cce9eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 1, 2304, 2304) (37, 1, 2304, 2304) (37, 1, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "print(y_tru.shape, y_pre.shape, ypred_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "236917c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of each dataset\n",
    "l_BT0398_210 = 11\n",
    "l_BT402_168 = 3\n",
    "l_BT403_000 = 11\n",
    "l_BT403_228 = 11\n",
    "l_BT404_199 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0aa3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dataset = unpatch_stack(image_dataset[:,1,:,:], 8, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb3228e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 1, 2304, 2304) (37, 1, 2304, 2304) (37, 1, 2304, 2304)\n",
      "(37, 4, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset.shape, y_pre.shape, y_tru.shape)\n",
    "saveme = np.concatenate((image_dataset, y_tru, y_pre, ypred_2), axis=1)\n",
    "saveme = saveme * 65535\n",
    "saveme = saveme.astype('uint16')\n",
    "print(saveme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5abebc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = r\"_results\"\n",
    "tiff.imwrite(os.path.join(results_folder, \"all_masked_stacks_V3b.tif\"), saveme, imagej=True, resolution=(1./2.6755, 1./2.6755),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c521a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['210218_murine-ML-hydrogel_60k-cells_A_2_inf_1_MMStack_Default.ome.tif']\n",
      "(100, 2304, 2304) (6272, 3, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "#Viktors data\n",
    "source_path = r\"Bactnet/viktor\"\n",
    "stacks = os.listdir(os.path.join(source_path))\n",
    "print(stacks)\n",
    "vikt = None\n",
    "\n",
    "def predict_stack(arr, batch_size, model):\n",
    "    \"\"\"\n",
    "    Performs prediction on all images in arr using model in increments of batch_size\n",
    "    Assumes patches of a ahpe where N is 0th axis.\n",
    "    \"\"\"\n",
    "    keras.backend.clear_session()\n",
    "    y_pred = None\n",
    "    for i in range(0, len(arr), batch_size):\n",
    "        subset = arr[i:i + batch_size]\n",
    "        \n",
    "        pred = model.predict(subset)\n",
    "        if y_pred is not None:\n",
    "            y_pred = np.concatenate((y_pred, pred))\n",
    "\n",
    "        else:\n",
    "            y_pred = pred\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "for i, image_name in enumerate(stacks):  # Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[-1] == 'tif'):\n",
    "        image = tiff.imread(os.path.join(source_path, image_name))\n",
    "        image = image[0:100]\n",
    "        image = normalizePercentile(image, 0.1, 99.9, clip=True)\n",
    "        patch = patch_stack(image, SIZE)\n",
    "        print(image.shape, patch.shape)\n",
    "        pred = predict_stack(patch, 2, model)\n",
    "        pred = unpatch_stack(pred, 8, 8, 1)\n",
    "        \n",
    "        if vikt is None:\n",
    "            vikt = pred \n",
    "        else:\n",
    "            vikt = np.concatenate((vikt, pred))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f46baa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1, 2304, 2304) (98, 1, 2304, 2304)\n",
      "(98, 2, 2304, 2304)\n"
     ]
    }
   ],
   "source": [
    "saveme = vikt * 65535\n",
    "saveme = saveme.astype('uint16')\n",
    "img = np.expand_dims(image[0:-2], axis = 1)\n",
    "img = img * 65535\n",
    "img = img.astype('uint16')\n",
    "print(saveme.shape, img.shape)\n",
    "saveme = np.concatenate((img,saveme), axis = 1)\n",
    "print(saveme.shape)\n",
    "tiff.imwrite(os.path.join(source_path, \"pred.tif\"), saveme, imagej=True, resolution=(1./0.109, 1./0.109),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec7f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4637761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT0398_210.tif (11, 2304, 2304) (576, 3, 288, 288) (576, 1, 288, 288)\n",
      "(576, 2, 288, 288)\n",
      "BT403_013.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n",
      "BT403_216.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n",
      "BT404_001.tif (12, 2304, 2304) (640, 3, 288, 288) (640, 1, 288, 288)\n",
      "(640, 2, 288, 288)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load unseen data\n",
    "\n",
    "validation_image_directory = r\"C:\\Users\\analyst\\Documents\\Python Scripts\\BactUnet\\Bactnet\\Training data\\stacks\\predict\"\n",
    "result_folder = r\"C:\\Users\\analyst\\Documents\\Python Scripts\\BactUnet\\_results\"\n",
    "\n",
    "val_image_dataset = []\n",
    "val_mask_dataset = []\n",
    "pred_mask_dataset = []\n",
    "\n",
    "images = os.listdir(validation_image_directory)\n",
    "\n",
    "for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        \n",
    "        image = tiff.imread(os.path.join(validation_image_directory, image_name))\n",
    "        original_shape = image.shape\n",
    "        patch = patch_stack(image, SIZE)\n",
    "        \n",
    "        patch = normalizePercentile(patch, 0.1, 99.9, clip=True)\n",
    "        pred_mask_patch = model.predict(patch)\n",
    "        print(image_name, original_shape, patch.shape, pred_mask_patch.shape)\n",
    "        #pred_mask_patch = pred_mask_patch[:, 0, :,:]\n",
    "        image = np.expand_dims(patch[:, 1, :,:], axis=1)\n",
    "        patch = np.concatenate((image, pred_mask_patch), axis=1)\n",
    "        unpatched = unpatcher(patch, 8, 8, 2)\n",
    "        print(patch.shape)\n",
    "        tiff.imwrite(os.path.join(result_folder, image_name), unpatched, imagej=True, resolution=(1./2.6755, 1./2.6755),\n",
    "                      metadata={'unit': 'um', 'finterval': 15,\n",
    "                                'axes': 'TCYX'})\n",
    "        \n",
    "        #pred_mask = unpatch_stack(pred_mask_patch, original_shape)\n",
    "        #tiff.imsave(os.path.join(result_folder, image_name), pred_mask_patch)\n",
    "        #val_image_dataset.append(image)\n",
    "        #pred_mask_dataset.append(pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7a69bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_mask_dataset)):\n",
    "    img = val_image_dataset[i][3]\n",
    "    msk = pred_mask_dataset[i][3]\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(121)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(122)\n",
    "    plt.title('Prediction on test image')\n",
    "    plt.imshow(msk)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c2554c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 conv2d (3, 3, 3, 64)\n",
      "4 conv2d_1 (3, 3, 64, 64)\n",
      "8 conv2d_2 (3, 3, 64, 128)\n",
      "11 conv2d_3 (3, 3, 128, 128)\n",
      "15 conv2d_4 (3, 3, 128, 256)\n",
      "18 conv2d_5 (3, 3, 256, 256)\n",
      "22 conv2d_6 (3, 3, 256, 512)\n",
      "25 conv2d_7 (3, 3, 512, 512)\n",
      "29 conv2d_8 (3, 3, 512, 1024)\n",
      "32 conv2d_9 (3, 3, 1024, 1024)\n",
      "35 conv2d_transpose (2, 2, 512, 1024)\n",
      "37 conv2d_10 (3, 3, 1024, 512)\n",
      "40 conv2d_11 (3, 3, 512, 512)\n",
      "43 conv2d_transpose_1 (2, 2, 256, 512)\n",
      "45 conv2d_12 (3, 3, 512, 256)\n",
      "48 conv2d_13 (3, 3, 256, 256)\n",
      "51 conv2d_transpose_2 (2, 2, 128, 256)\n",
      "53 conv2d_14 (3, 3, 256, 128)\n",
      "56 conv2d_15 (3, 3, 128, 128)\n",
      "59 conv2d_transpose_3 (2, 2, 64, 128)\n",
      "61 conv2d_16 (3, 3, 128, 64)\n",
      "64 conv2d_17 (3, 3, 64, 64)\n",
      "67 conv2d_18 (1, 1, 64, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11188/590165685.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mn_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_filters\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mfig1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mfig1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#Turn off axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 2 with size 3"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAABXCAYAAADve0ugAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAClklEQVR4nO3dsUpbYRjH4f8pdYhITpbGLFLwDoROegNeguAFCO6u4hUIbt6At6CrLm5egC7SxaVFHARFkK/TESwVmng+StvnWZPv5eWc8EuyJE0pJcD/7cOfXgD484QAEAJACIAIARAhAJJ8nObJ8/PzZTQaVVmkbdsqczs3NzdV5j48POTp6amZ9XzbtmUymfS50ouFhYUqcztXV1fVZt/f338vpXya9fxgMCjD4bDPlV4sLS1Vmdu5uLioNruU8svX6lQhGI1G2dra6mejn6yvr1eZ29nb26sy9/z8/F3nJ5NJDg8Pe9rmtdXV1SpzOzXv2enp6df3nB8Oh9nY2OhrnVcODg6qzO00zczvKzPz1QAQAkAIgAgBECEAIgRAhACIEAARAiBCAEQIgAgBECEAIgRAhACIEAARAiBCAEQIgAgBkCl/vHQ8Hmd7e7vKIicnJ1XmdsbjcZW5c3Nz7zp/e3ubo6OjnrZ5bXl5ucrczuXlZdX57/H8/Jy7u7sqs3d2dqrM7QwGgypzHx8f33zMJwJACAAhACIEQIQAiBAAEQIgQgBECIAIARAhACIEQIQAiBAAEQIgQgBECIAIARAhACIEQIQAiBAAEQIgSVNK+e0nLy4uls3NzSqL7O/vV5nbaZqm2uxSyszD27Yta2trfa7z4vj4uMrcTs1rmuSilPJl1sMrKyvl7Oysz31e1JrbqfV/DLu7u7m+vv7lTfOJABACQAiACAEQIQAiBECEAIgQABECIEIARAiACAEQIQAiBECEAIgQABECIEIARAiACAEQIQAiBECm/Dnzpmm+Jflab52/0udSyqdZD7umb3Jd+/fmNZ0qBMC/yVcDQAgAIQAiBECEAIgQABECIEIARAiAJD8Af8R5HAwU3/AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_weights = []\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "  if \"onv\" in layer.name:\n",
    "    all_weights.append\n",
    "    print(i, layer.name, model.layers[i].get_weights()[0].shape)\n",
    "\n",
    "weights, biases =  model.layers[1].get_weights()\n",
    "fig1=plt.figure(figsize=(12, 12))\n",
    "\n",
    "\n",
    "columns = 8 \n",
    "rows = 8 \n",
    "n_filters = columns*rows\n",
    "for i in range(1, n_filters +1):\n",
    "    f = weights[:, :, (i-1), 0]\n",
    "    fig1 =plt.subplot(rows, columns, i)\n",
    "    fig1.set_xticks([])  #Turn off axis\n",
    "    fig1.set_yticks([])\n",
    "\n",
    "    #plt.imshow(f[i%3, :, :], cmap='gray')\n",
    "    plt.imshow(f[:, :], cmap='gray')\n",
    "    #plt.imshow(f[2, :, :], cmap='gray') #Show only the filters from 0th channel (R)\n",
    "    #ix += 1\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
